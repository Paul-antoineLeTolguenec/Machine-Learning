{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seafloorClassification_startercode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paul-antoineLeTolguenec/Machine-Learning/blob/master/seafloorClassification_startercode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZiULAOAv6AZ"
      },
      "source": [
        "# Machine Learning Programming Exercise 6: <ins>Supervised classification</ins>\n",
        "\n",
        "\n",
        "## Objectifs\n",
        "\n",
        "\n",
        "Nous allons dans ce TP classer automatiquement des patchs extraits d'images sonar (cf. figure ci-dessous) en types de fond marin (roches, sables, vases, rides de sable verticales et à 45°, [Posidonie](https://fr.wikipedia.org/wiki/Posidonia_oceanica)).\n",
        "\n",
        "Quelques exemples de patchs d'image sonar de fond marin:\n",
        "<img src=\"imgs/screenshot001.png\" />\n",
        "\n",
        "\n",
        "L'objectif est d'écrire des scripts permettant de mettre en \\oe uvre un système basé sur différentes approches supervisées de machine learning. Ces scripts devront ainsi suivre la chaîne générale décrite en cours (à l'exception de la phase de captation; cf. figure ci-dessous ) :\n",
        "* prétraitements\n",
        "* extraction des descripteurs\n",
        "* apprentissage d'un modèle de classement\n",
        "* classement des pixels\n",
        "* évaluation du classifieur appris\n",
        "\n",
        "<img src=\"imgs/screenshot002.png\" />\n",
        "\n",
        "Le TP est globalement organisé de la manière suivante\n",
        "* **Données**\n",
        " 1. tout d'abord apprendre les modèles de classement (classifieurs) sur les données brutes (descripteurs=features=valeurs des pixels) \n",
        " 2. puis dans un second temps sur des descripteurs extraits à partir d'un algorithme appelé [scattering operator](https://www.di.ens.fr/data/scattering) (le fonctionnement exact n'est pas au programme mais il s'apparente à une banque de filtres mise en cascade). \n",
        "\n",
        "* **Prétraitements** Aucun prétraitement ne sera réalisé. \n",
        "\n",
        "* **Ensembles de données**\n",
        " 1. Les ensembles de données seront composés de 1/3 de la base totale d'images. \n",
        " 2. Dans un second temps, nous procéderons par [validation croisée](https://scikit-learn.org/stable/modules/cross_validation.html) car la base d'images est de taille réduite.\n",
        "* **Algorithmes** \n",
        "    Concernant les algorithmes supervisés de machine learning, l'objectif est d'utiliser les deux algorithmes de regression logistique et de réseaux de neurones que vous avez développés aux TP précédents et de découvrir le package python [scikit-learn](http://scikit-learn.org/stable/user_guide.html) qui vous permettra d'utiliser les algorithmes de [régression logistique](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), [réseaux de neurones](https://scikit-learn.org/stable/modules/neural_networks_supervised.html), [random forests](https://scikit-learn.org/stable/modules/ensemble.html#forest) et [svm](https://scikit-learn.org/stable/modules/svm.html#svm-classification).\n",
        "\n",
        "* Pour commencer avec cette séance, vous aurez besoin de **télécharger** le _starter code_  disponible sur le lien Moodle du cours.\n",
        "\n",
        "<span style='color:red'>**Dans cet exercice, il vous est demandé de fournir un rapport regroupant les réponses aux questions, vos analyses et vos codes. Ce rapport pourra prendre la forme d'un pdf ou d'un jupyter notebook. Il est de plus conseillé de faire tourner les codes sur google colab si votre machine manque de puissance (dans ce cas un jupyter notebook est nécessaire).**</span>\n",
        "\n",
        "\n",
        "## Fichiers inclus dans le starter code pour cette séance\n",
        "* **pythonTools.py** - fonctions utiles pour l'affichage, le chargement des données et l'évaluation des performances\n",
        "* **usefulCmds.py** - quelques commandes pour faciliter l'import des patchs\n",
        "* **dataSet** - répertoire avec les images et les labels correspondants\n",
        "* **dataSet\\imdb_200x200_SmallSonarTex_db_6classes_scatValOnly.mat** - fichier matlab contenant les descripteurs extraits des images par le scattering operator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD6h-dhkQyme",
        "outputId": "1e1edadc-14f4-4733-dd62-73ff4ac89e3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "WA4nIV8QQ-kR",
        "outputId": "26619218-a787-4184-8445-e6fc67de6d91"
      },
      "source": [
        "import os\n",
        "print(!pwd)\n",
        "os.chdir('./drive/MyDrive/SEABED/Machine-Learning/')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-b39f574a08f5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print(!pwd)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSf9rv8xRiFm"
      },
      "source": [
        "!git add seafloorClassification_startercode.ipynb"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ForL3Y19St1F"
      },
      "source": [
        "!git config --global user.email \"gwendal.priser@ensta-bretagne.org\"\n",
        "!git config --global user.name \"gwendalp\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ22qvTdSOE1",
        "outputId": "f762d472-b3c4-4e9a-f631-46e213c00f89"
      },
      "source": [
        "!git commit -m \"add an interface between Colab & GitHub\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 664024c] add an interface between Colab & GitHub\n",
            " 1 file changed, 1 insertion(+), 3408 deletions(-)\n",
            " rewrite seafloorClassification_startercode.ipynb (96%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50PuJaXbTmd-",
        "outputId": "fbf48f20-44bd-4099-842b-2354b8da41f6"
      },
      "source": [
        "!git remote add origin https://gwendalp:croanu97@github.com/Paul-antoineLeTolguenec/Machine-Learning.git"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: remote origin already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_01ofksSGaG",
        "outputId": "6ab7275b-9575-4701-e970-1d6918bbc617"
      },
      "source": [
        "!git push origin master"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-Y6TWZBv6Ab"
      },
      "source": [
        "# Part 0: intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsF0iPYhv6Ae"
      },
      "source": [
        "## 0.1 imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9vExjoNv6Af"
      },
      "source": [
        "_Your commented code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "vQhXCVuAv6Ag",
        "outputId": "e52b044d-8b30-4414-9a24-3a1bab9807f0"
      },
      "source": [
        "from pythonTools import *\n",
        "from usefulCmds import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEAis_r1v6Ar"
      },
      "source": [
        "## 0.2 Examen des données\n",
        "\n",
        "Écrire des lignes de code permettant:\n",
        "* de charger les données comprises dans le fichier _labels.csv_,\n",
        "* de mettre en matrice les descripteurs de l'ensemble de la base d'images\n",
        "* d'afficher les images avec la fonction _plot\\_batch()_ du fichier \\_pythonTools.py_,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5dDA5Kiv6Ar"
      },
      "source": [
        "_Your commented code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "xGqVIrCxv6At",
        "scrolled": false,
        "outputId": "d4af001f-86e6-4ebf-d9f5-72269c8ec4fe"
      },
      "source": [
        "# Charger le fichier CSV\n",
        "DATASET_PATH = r'./dataset/imgs/'\n",
        "LABEL_PATH = r'./dataset/labels/labels.csv'\n",
        "dataset_df = pd.read_csv(LABEL_PATH)\n",
        "\n",
        "\n",
        "print(\"----------------------------------------Data information--------------------------------------------\")\n",
        "#print nombre de données\n",
        "print(\"Dimensions du dataset:\",dataset_df.shape)\n",
        "\n",
        "#Nombre de classes:\n",
        "print(pd.unique(dataset_df['seafloor']).tolist())\n",
        "#Nombre d'images par classes\n",
        "print(dataset_df.groupby('seafloor').nunique())\n",
        "\n",
        "#Ploting batch\n",
        "print(\"----------------------------------------Batch--------------------------------------------\")\n",
        "#getting 5 random data\n",
        "batch=load_batch(dataset_df,5)\n",
        "print(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------Data information--------------------------------------------\n",
            "Dimensions du dataset: (360, 2)\n",
            "['Posidonia', 'Ripple 45°', 'Rock', 'Sand', 'Silt', 'Ripple vertical']\n",
            "                 id\n",
            "seafloor           \n",
            "Posidonia        60\n",
            "Ripple 45°       60\n",
            "Ripple vertical  60\n",
            "Rock             60\n",
            "Sand             60\n",
            "Silt             60\n",
            "----------------------------------------Batch--------------------------------------------\n",
            "                                 id         seafloor\n",
            "278             Silt_Sure.02691.png             Silt\n",
            "103       Ripple 45°_Sure.00101.png       Ripple 45°\n",
            "306  Ripple vertical_Sure.00027.png  Ripple vertical\n",
            "289             Silt_Sure.03581.png             Silt\n",
            "207             Sand_Sure.00073.png             Sand\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbI5IPb4v6Az"
      },
      "source": [
        "**Question: Quels sont le nombre de données et le nombre de descripteurs?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ2JIo5Jv6A0"
      },
      "source": [
        "Il y a 360 données. C'est données sont réparties en 6 classes. \n",
        "Il y a 60 images par classes.\n",
        "\n",
        "Il y a 40000 descipteurs par images.(voir plus bas)\n",
        "\n",
        "Posidonia        60         \n",
        "Ripple 45°       60         \n",
        "Ripple vertical  60         \n",
        "Rock             60     \n",
        "Sand             60       \n",
        "Silt             60         "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV1nRYDQQujT"
      },
      "source": [
        "# We add another column to the labels dataset to identify image path\n",
        "dataset_df['image_path'] = dataset_df.apply( lambda row: (DATASET_PATH + row[\"id\"] ), axis=1)\n",
        "\n",
        "# Chargement des images\n",
        "feature_values = np.array([plt.imread(img).reshape(40000,) for img in dataset_df['image_path'].values.tolist()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCk7ykINv6A1"
      },
      "source": [
        "## 0.3 prétraitements des labels\n",
        "\n",
        "Écrire des lignes de code, un script ou une fonction _preprocessing()_ permettant:\n",
        "* de disposer des labels dans différents [codages](https://scikit-learn.org/stable/modules/preprocessing_targets.html) (noms, indices, one-hot-encoding, etc.) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1GzYnP5v6A3"
      },
      "source": [
        "_Your commented code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW41N-eHv6A3"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Récupération des labels\n",
        "label_names = dataset_df['seafloor']\n",
        "label_names_unique = label_names.unique()\n",
        "\n",
        "#  transformation des labels selon différents codages\n",
        "# indices\n",
        "\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(label_names_unique)\n",
        "label_indices = le.transform(label_names_unique)\n",
        "\n",
        "# one-hot-encoding\n",
        "label_ohe = pd.get_dummies(label_names.reset_index(drop=True)).values\n",
        "\n",
        "# Getting labels for our dataset\n",
        "y = le.transform(label_names)\n",
        "#y = tf.keras.utils.to_categorical(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tu9u9Oqv6A8"
      },
      "source": [
        "## 0.4 Séparation des données en ensembles \n",
        "\n",
        "Écrire des lignes de code, un script ou une fonction _preprocessing()_ permettant:\n",
        "* de [normaliser](https://scikit-learn.org/stable/modules/preprocessing.html) les données si besoin \n",
        "* de [créer deux ensembles](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) un pour l'apprentissage et un pour le test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1p9-v4cv6A9"
      },
      "source": [
        "_Your commented code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ziGWKoQujT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "xjAfwumev6A-",
        "outputId": "2337cfe2-b29f-4769-d502-7ef858fc7505"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_values, y, test_size = 0.25, random_state = 0)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(270, 40000) (270,) (90, 40000) (90,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcDIy1Nmv6BD"
      },
      "source": [
        "<strong>Question:</strong> Pour <ins>chaque ensemble de données</ins> et <ins>pour chaque classe</ins>, quels sont le nombre de données et le nombre de descripteurs? Est-ce important? Pourquoi?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nCFuRy2v6BE"
      },
      "source": [
        "Il y a 75 pourcents des données dans Xtrain et 25 pourcents des données dans Xtest.\n",
        "\n",
        "X_train= 270 examples\n",
        "\n",
        "X_test= 90 examples\n",
        "\n",
        "Pour chaques images il y a 40000 descripteurs (200*200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxTChVG1QujT"
      },
      "source": [
        "_Your commented code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcAN-a-2QujT"
      },
      "source": [
        "#Lets create a validation set\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
        "#print(X_train.shape, y_train.shape, X_test.shape, y_test.shape,X_val.shape, y_val.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6nioyvrv6BE"
      },
      "source": [
        "# Part 1 approches supervisées sur données brutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtkGMAtqv6BF"
      },
      "source": [
        "<strong><ins>Question</ins>: Y-a-t-il besoin de normaliser les descripteurs? Si oui, que faut-il conserver comme information et pourquoi?</strong> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbFeb9jAv6BG"
      },
      "source": [
        "Il est necessaire de normaliser les descripteurs. En effet de cette façon le modèle converge plus rapidement.On associe à chaque descripteurs la même importance dans la prédiction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ly2nTOXQujT"
      },
      "source": [
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "#X_val = sc.transform(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01PQN1yev6Bl"
      },
      "source": [
        "**<ins>Question</ins>: Nous allons apprendre les modèles suivants:\n",
        "* régression logistique régularisée et réseaux de neurones développés dans les tps précédents,\n",
        "* régression logistique, réseaux de neurones (solver=lbfgs), svm et random forest en utilisant les fonctions du package scikit-learn\n",
        "\n",
        "Faire la liste des hyper-paramètres (paramètre uniquement lié à l'algorithme d'apprentissage) de chaque algorithme. Comment fixe-t-on leurs valeurs?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxHG8upGv6BO"
      },
      "source": [
        "# Pour la regression logistique regularisée les hyper-paramètres du modèle sont :\n",
        "\n",
        "-le taux d'apprendtissage\n",
        "\n",
        "-le paramètre de régularisation\n",
        "\n",
        "# Pour le réseau de neurones:\n",
        "\n",
        "-le taux d'apprentissage\n",
        "\n",
        "-le nombre d'hidden layer\n",
        "\n",
        "# Pour le random forest:\n",
        "\n",
        "-la pronfondeur des arbres\n",
        "\n",
        "-le nombre d'arbres dans la forêt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE40sCAMv6BG"
      },
      "source": [
        "<strong><ins>Question</ins>: Fixez au mieux les valeurs des hyperparamètres, réalisez l'apprentissage des modèles suivants: \n",
        "* régression logistique régularisée et réseaux de neurones développés dans les tps précédents,\n",
        "* régression logistique, réseaux de neurones, svm et random forest en utilisant les fonctions du package scikit-learn\n",
        "</strong>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRvvdn-Ev6BH"
      },
      "source": [
        "_Your code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAH-qWBaQujU",
        "outputId": "9da01521-38f0-44c3-b09d-56392dae1697"
      },
      "source": [
        "#-------------------REGRESSION LOGISTIQUE REGULARISEE---------------------\n",
        "from linearRegCostFunction import linearRegCostFunction\n",
        "from trainLinearReg import trainLinearReg\n",
        "from learningCurve import learningCurve\n",
        "from polyFeatures import polyFeatures\n",
        "from featureNormalize import featureNormalize\n",
        "from plotFit import plotFit\n",
        "from validationCurve import validationCurve\n",
        "import numpy as np\n",
        "from nnCostFunction import nnCostFunction\n",
        "import scipy.io\n",
        "from scipy.optimize import minimize, fmin_cg, fmin_l_bfgs_b\n",
        "import numpy as np\n",
        "#-------------------NEURAL NETWORK-----\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def randInitializeWeights(L_in, L_out):\n",
        "    E = 0.12\n",
        "    W = np.random.rand(L_out, 1+L_in) * 2 * E - E\n",
        "    return W\n",
        "\n",
        "\n",
        "input_layer_size  = 40000\n",
        "hidden_layer_size = 25 \n",
        "num_labels = 6    \n",
        "\n",
        "\n",
        "\n",
        "print('\\n -------------------------- \\n')\n",
        "print('Initializing Neural Network Parameters ...')\n",
        "\n",
        "\n",
        "initial_theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
        "initial_theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
        "\n",
        "\n",
        "print(initial_theta1.T.ravel().shape)\n",
        "print(initial_theta2.T.ravel().shape)\n",
        "\n",
        "initial_nn_params = np.hstack((initial_theta1.T.ravel(), initial_theta2.T.ravel()))\n",
        "\n",
        "\n",
        "print(initial_nn_params.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " -------------------------- \n",
            "\n",
            "Initializing Neural Network Parameters ...\n",
            "(1000025,)\n",
            "(156,)\n",
            "(1000181,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qoOtsY9QujU",
        "outputId": "18bf008d-98fd-4205-f4b7-47ee0e7ec5f8"
      },
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(270,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZb9pYP9QujU",
        "outputId": "5d7ae220-b7a7-4779-d906-50e3b875115e"
      },
      "source": [
        "print('\\n -------------------------- \\n')\n",
        "print('Training Neural Network... ')\n",
        "\n",
        "Lambda = 1\n",
        "costFunc = lambda p: nnCostFunction(p, input_layer_size, hidden_layer_size, num_labels, X_train, y_train, Lambda)[0]\n",
        "gradFunc = lambda p: nnCostFunction(p, input_layer_size, hidden_layer_size, num_labels, X_train, y_train, Lambda)[1]\n",
        "\n",
        "result = fmin_cg(costFunc, fprime=gradFunc, x0=initial_nn_params, maxiter=100, disp=True,full_output=True)\n",
        "\n",
        "nn_params = result[0]\n",
        "cost = result[1]\n",
        "theta1 = nn_params[0:(hidden_layer_size*(input_layer_size+1))].reshape((input_layer_size+1),hidden_layer_size).T\n",
        "theta2 = nn_params[(hidden_layer_size*(input_layer_size+1)):].reshape((hidden_layer_size+1),num_labels).T\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " -------------------------- \n",
            "\n",
            "Training Neural Network... \n",
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 9.487272\n",
            "         Iterations: 100\n",
            "         Function evaluations: 159\n",
            "         Gradient evaluations: 159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Lqb8n1QujU"
      },
      "source": [
        "def predictNeuralNetwork(Theta1, Theta2, X):\n",
        "  \"\"\" outputs the predicted label of X given the\n",
        "  trained weights of a neural network (Theta1, Theta2)\n",
        "  \"\"\"\n",
        "  m, _ = X.shape\n",
        "  num_labels, _ = Theta2.shape\n",
        "  probas = sigmoid(Theta2 @ (np.vstack((np.ones((1, m)), sigmoid(Theta1 @ X.T)))))\n",
        "  p = np.argmax(probas, axis=0).reshape((m, 1))\n",
        "  return p.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL5Iu1kpQujU",
        "outputId": "7bb89419-a9b0-43bf-c26a-d65df8f35fc5"
      },
      "source": [
        "m, _ = X_test.shape\n",
        "Xp = np.column_stack((np.ones((m, 1)), X_test))\n",
        "\n",
        "y_pred = predictNeuralNetwork(theta1, theta2, Xp)\n",
        "\n",
        "accuracy = np.mean(np.double(y_pred == y_test.flatten())) * 100\n",
        "print('Training Set Accuracy: %f\\n'% accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Accuracy: 42.222222\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyFdivOgQujU",
        "outputId": "4a9d05e5-774e-4f1b-f74a-4ced4b293112"
      },
      "source": [
        "plot_confusion_matrix(y_test, y_pred, label_names_unique,\n",
        "                          normalize=True,\n",
        "                          title=\"Matrix Confusion\",\n",
        "                          cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized confusion matrix\n",
            "[[0.46666667 0.         0.26666667 0.         0.2        0.06666667]\n",
            " [0.23529412 0.11764706 0.         0.         0.47058824 0.17647059]\n",
            " [0.1        0.         0.1        0.1        0.3        0.4       ]\n",
            " [0.0625     0.         0.25       0.125      0.125      0.4375    ]\n",
            " [0.         0.         0.         0.         1.         0.        ]\n",
            " [0.25       0.         0.0625     0.         0.0625     0.625     ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Matrix Confusion'}, xlabel='Predicted label', ylabel='True label'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEYCAYAAAA+mm/EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABeNUlEQVR4nO2dd3yUxdaAnwMhFAVCT6OEIoHQO0jvJSAKCIIIYu9e671eFcRPBWxYsKAiiiBIkSpNECnKpUmRoiA9Cb0LJiQ53x/zJtnUXcimwTz83h/7zntmzsxm9+zUc0RVsVgsFktq8uV0BSwWiyW3Yg2kxWKxpIM1kBaLxZIO1kBaLBZLOlgDabFYLOlgDaTFYrGkgzWQllyDiAwSkSU5XY+UiEg5EVkpIudF5O1MlPOCiHzuzbpZshax+yAtGSEi+4FAIFBVT7ik/wbUA0JUdb+bMioB+4ACqhqbRfUU4DHgfiAEOA38CoxU1W2ZLPsloD7QR+0X5rrC9iAtnrAPuCPhRkRqA0W8qUBEfDJZxHvAE8DjQEngJmA20COT5QJUBHZY43j9YQ2kxRMmAXe53A8BvnYVEJEeIvKbiJwTkUMiMsLl8Urn/zMickFEmovIUBFZIyLvishJYISTttopr4WInBCR8s59XRE5LSKhKSsnItWAR4A7VHW5qkar6kVVnayqoxyZ4iLytYgcF5EDIvKiiORzng0VkdUi8pajY5+IdHOeTXTa+5xT944iMlFE/s9Ff1sROexy/7yIRDhD8j9EpIOTPkJEvnGR6yUi20XkjIisEJEaLs/2i8gzIrJVRM6KyDQRKeTZn8viLayBtHjCWqCYiNQQkfzAAOCbFDJ/Y4yoH6bX9pCI9HaetXb+91PVG1X1V+e+KbAXKAe85lqYqv4CfAp8JSKFHX0vqequNOrXATisqusyaMMHQHGgMtDGqevdLs+bAn8ApYExwBciIqo6FJgMjHHq/mMGOhCR6sCjQGNVLQp0AfanIXcT8C3wJFAG+AGYJyK+LmK3A10xUwZ1gKEZ6bZ4H2sgLZ6S0IvsBOwEIlwfquoKVd2mqvGquhXz5W/jpsxIVf1AVWNV9VIaz0dgjNo6R9+4dMopBUSlp8TFqP9HVc87c6ZvA4NdxA6o6meqGgd8BQRgDPeVEgcUBGqKSAFV3a+qf6Uh1x9YoKpLVfUy8BZQGGjhIvO+qkaq6ilgHmbO15KNWANp8ZRJwEBML+brlA9FpKmI/OQMYc8CD2J6YxlxKKOHjuGYCNQC3s5gDvAkxqClR2mgAHDAJe0AEORyf8RF70Xn5Y0Z1S8tVHUPplc4AjgmIlNFJDAN0UDX+qhqPOb9SLNOwMWrqY8lc1gDafEIVT2AWazpDsxKQ2QKMBcor6rFgU8AScieXrEZ6RSRIGA48CXwtogUTEd0GRAsIo3SeX4CuIxZbEmgAil6wVfA3yRfpPJ3faiqU1S1paNPgdFplBHpWh9nFb58JupkyQKsgbRcCfcA7VX17zSeFQVOqeo/ItIE09tM4DgQj5n/8wjHYEwEvnD0RgGvpiWrqruBj4BvnQUTXxEpJCIDROTfzrD5O+A1ESkqIhWBp0g9j+opm4HuIlJSRPwxPcaEelcXkfaOMf8HuIRpe0q+A3qISAcRKQA8DUQDv1xlnSxZgDWQFo9R1b9UdUM6jx8GRorIeeBljAFIyHcRswizxlmxbeaBuseBspiFGcUsqNwtIq0ykP8QM095BvgLuBUzdwdmj+TfmEWh1Zge7wQP6pEWk4AtmMWXJcA0l2cFgVGYXusRpw3/SVmAqv4B3IlZPDoB9AR6qmrMVdbJkgXYjeIWi8WSDrYHabFYLOlgDaTFYrkmEJEJInJMRH5P57mIyPsissfZgN/AXZnWQFoslmuFiZiN9enRDajmXPcDH7sr0BpIi8VyTaCqK4FTGYjcAnythrWAn4hktH+WzDoIsHiZIsVLaPGyQe4FvUhgsew94nshOksc+mTIjQWz/6N+6XJau3uyDl8fcS/kZbb8tumEqpbJbDn5i1VUjU3rMFUSeun4dszWqQTGq+r4K1ATRPLDCYedtHRPYVkDmcsoXjaIoe/NzFadwztXz1Z9//srox/5rKFplZLZrnNX5Pls1RdYIvt9WZQr5nvAvZR7NPYSBavfnqHMP5vH/aOq6R0GyBKsgbRYLDmPCOTLn9VaIjCnlRIIxs3JJTsHabFYcgeSL+Mr88wF7nJWs5sBZ1U13eE12B6kxWLJFWS+Byki3wJtgdKOf87hGCclqOonGJdy3YE9GOcfd6ddUhLWQFosltyBZG6RSVXvcPNcMY6VPcYaSIvFkvNkzxzkFWMNpMViyR14Z57Rq1gDabFYcgG2B2mxWCxpI2R6DjIryH19Wksq9m5Yxfj7u/LJvZ359bv0Dw7sWrOYUT1CidptwkBv/2keEx7tnXiNCq/B0b92utW3ZPEi6oRVJyy0Km+OGZXqeXR0NHcO7E9YaFVatWjKgf37E5+9OfoNwkKrUiesOkuXLPa4jf9btYzBXZswsHMjJo8fm+r5d19+xJAezRnWqxVPDe3NkQhzIOK3tau4p3ebxKtTnUBW/bjAI53Z3c41K5bSu10DerWuy4SP3kn1fNJnH3Jbh8bc3qU5D9zRk8jDBxOfzZ0xmV5t6tGrTT3mzpjskT6A5UsX06JBGE3r1uD9d8ak2cb7hg6kad0adG13MwcPmDbOmDaF9jc3Srz8ixfk962bPdZ75Qjk88n4ygHyrIEUkTgR2Swiv4vIdBG5ojjNIhIoIjPSebYiA/f97sp9UETuci/pGfFxcSz5eCS3v/IZ9308nx0rF3Di4J5UctEXL7BhziQCq9dNTAtr15NhH85m2IezCX9mNH7lgilXpUaqvK7ExcXx5OOPMGfeQn7buoPpU79l544dyWQmTviCEn4l2L5rD4898S/++8LzAOzcsYPp06ayact25s5fxBOPPUxcXJzbNsbFxfHeyOcY/dl3fDX/F5YvmMX+PcmDF1arUZtPZyxjwtxVtOnSi0/fGgFA/Wat+GL2z3wx+2fenTibQoUL0/jmdh7pzM52xsXFMeqlp/nwq5nM/HE9i+bO4K8/k7cxNKwOk+f/zHeLf6VD91t4742XATh75hTjx45m0pzlfDP3J8aPHc25s6c9auO/n36CKTPnsWr9Fr6fMY0/diVv45Svv8TPrwT/27KTBx55nFeHvwBA3/4DWb5mA8vXbODD8V9SoWIIterUc6szU+STjK8cIM8aSOCSqtZT1VpADCZIlMc40eL6ertSqvqJqqYKanW1RP25lRKBFfALKE/+Ar7UbN2d3WuXpZJb9c37NOt7L/l9fdMoBXb+vIAarbu71bd+3TqqVKlKSOXK+Pr60q//AObPm5NMZv68OQwaPASA2/r0ZcXyZagq8+fNoV//ARQsWJBKISFUqVKV9esyisRq2LV1E0EVQggsX4kCvr60734ra5YtTCZTv1krChU2v4E16zbi+JHIVOX8vHguTVt1TJTLTe38ffMGyleqTHCFEAr4+tKlZx9WLE3e023cojWFnbrXqd+Yo1HmkMcvPy+jWat2FPcrSbHiJWjWqh1rVmQYfRaATRvWE1K5CpVCTBt797mdRQvmJZNZtGAet99hgjv27N2H1St+IqUT7e9nTKN3335u9WUKwcxBZnTlAHnZQLqyCqjqxAiZ7fh6WysidQBEpI3T29wsJrh9URGplOA3TkQKO9HndorI95jwmzjP7hCRbU5PdbRL+gUReU1Etji6yjnpI0TkGef1fSKy3pGZeaW9XIDzJ49StHSSw5Gipf05f/JoMpkje7Zz7ngUVZu0TbecnSsXUrNND7f6IiMjCA5OOo0VFBRMREREapnyRsbHx4dixYtz8uRJIiJS542MdB+D6vjRKMoEJDnoKOMfyPGj6R9wWDDjG5q07pAqffkPs2jf4za3+hLbkI3tPHYkinIBwYn35QIC0zTyCcye9jU3t+0EwPEjUZRzeX/K+gdy/EiGB0AAOBIVQWBwks7AwCCORCbXGRUVQZAj4+PjQ9FixTl16mQymTkzZ3Br3/5u9WUOyY6TNFdMnjeQIuKD8fO2DXgF+E1V6wAvkBSe9BngEVWtB7TCBFJy5SHgoqrWwOy+b+iUHYiJSNceE5O4sYj0dvLcAKxV1brASuC+NKo3S1UbOzI7McGnvIrGx7Ps81G0v/f5dGUid22hQMFClKl0k7fVZztL5n7HH9s3M+Cex5Klnzx2hL1/7qRJy/Y5VDPvsWDWVHZs+40hDzyR01Vh4/p1FC5SmBo1a2W9MtuD9CqFRWQzsAE4iIl+1xITUAlVXQ6UEpFiwBrgHRF5HPBT1ZT+tlrjRLhzgt5vddIbAytU9biTZ7IjC2ZYP995vRGolEYda4nIKhHZBgwCwtJqiIjcLyIbRGTDxRRzS0VLleP8iaTewvkTRyhaKimeffSlvzlxYDdT/n0XH93dnshdW5g58uHEhRqAHSt/oIYHvUcwvYzDh5M8QkVEHCYoKCi1zCEjExsby7mzZylVqhRBQanzBga6d91WplwAx6OSemDHj0RSplxqN30bflnBN5+8w+sfTcbXN3kE2J8WzaFVxx74FCiQK9tZ1j+Ao1GHE++PRkVSxj91uOy1q3/iiw/fYuzn0/AtaNpYxj8gcbgNcOxIJGX8M3RjCIB/QBCRh5N0RkZG4B+YXGdAQBARjkxsbCznz52lZMlSic9nz/wuG3qPmBVsd1cOkJcNZMIcZD1VfSyjaHCqOgq4FzN0XiMioV7Qf9klkH0caW+Zmgg8qqq1Mb3bNP1Rqep4VW2kqo2KFC+R7FnATbU5FXGAM0cOE3c5hh0rf6Bq06ReUqEbivLEt2t5+MvlPPzlcgJD69Ln5Y8IqFbblB0fz67VC6nZ2jMD2ahxY/bs2c3+ffuIiYlh+rSp9AjvlUymR3gvJk/6CoBZM2fQpl17RIQe4b2YPm0q0dHR7N+3jz17dtO4SRO3OqvXrs/hA3uJOnyAyzExLP/he1q075ZMZveOrbwz/Gle/2gyJUqldj+4bMFMOng4vM6JdobVbcjBfXuJOLifyzExLJ43k7adks8J7/p9C6/95wne/WIqJUsntbFFmw78unI5586e5tzZ0/y6cjkt2qSeYkhJ/YaN2Lt3Dwf2mzbOnvkdXbqHJ5Pp0j2c776dBMC82TNp2aYt4hij+Ph45n4/g959MnZD5jVyYQ/yWtsHuQrTU3tVRNoCJ1T1nIhUUdVtwDYRaQyEYmIbJ7ASE8d5uYjUAuo46euA90WkNHAauAMTptNTigJRTtzjQVxFUPh8+X3o/NBLTHvpHjQ+njqd+lCmYjVWTnqfgGq1qNYs4yHlwd/XU6x0AH4B5TOUS8DHx4d33/uQnj26EBcXx5Chw6gZFsbIES/ToGEjwnv2Yuiwexg2dDBhoVUpUaIkkyZPBaBmWBh9+t1O/To18fHxYez748if3/0H28fHhydeGs2z9/QjPj6Obn0GElItlAnvv0H1WvW4uX03Pn5zOJcu/s3wJ4cBUC4gmNc/Nttdog4f5HhUBHWb3OxRG3OinT4+Pjw/8k0evutW4uPiuOX2wVS5qQYfvf1/1KzTgLaduvPu6y9x8eLfPPewWRjyDwzmvS+mUdyvJPc9/hx39mwLwP1PPE9xP/f+LX18fHjjzbEMuLUHcXHx3DF4CKE1whj9fyOo26AhXbv3ZOBdd/Po/UNpWrcGfiVK8OmXSaHCf12zisCgYCqFeBzOPBNIrjxJk2fDvorIBVW9MUVaSUys48oYbx33q+pWEfkAaIcJ4L4dGAoEAPNVtZaIFAa+BBLmCoMwc5YbROQOzHymAAtU9fmU+kWkLxCuqkNFZARwQVXfEpGHgOeA48D/gKKqOjSjdgVUq6XWYa73sQ5zs4ZyxXw3esOJbT6/Clqw5XMZyvyz4DGv6LoS8mwPMqVxdNJOAb3TSH8sZRom6Hst5/klYEA6er4Fvs1Iv6rOAGY4r0e4pH+MB4GBLBZL7uxB5lkDabFYrjHsWWyLxWJJh1x4FtsaSIvFkvNYf5AWi8WSPmJ7kBaLxZIaEZAcckiREdZAWiyWXIDYHqTFYrGkR758dpuPxWKxpIntQVosFksaiIidg7S4x69QAXpXL+de0IscOfNPturLiWN/OcHUben7e8wKBtdz7zkpN2N7kBaLxZIOdg7SYrFY0kKcK5eR+0y2xWK57hCEfPnyZXi5LUOkq4j8ISJ7ROTfaTyvICI/OWFXtoqI2yBN1kBaLJZcgYhkeLnJmx8Yhwm/UhO4Q0RqphB7EfhOVetjvHd95K5O1kBaLJacxzlJk9HlhibAHlXd60QXmArckkJGgWLO6+KA21U0OwdpsVhyBR6sYpcWkQ0u9+NVdbzzOgg45PLsMNA0Rf4RwBIReQwTdK+jO4XWQFoslhwnYQ7SDScy6VH8DmCiqr4tIs2BSSJSS1Xj08tgh9gWiyV3IG6ujIkAXAMvBZM6BtQ9wHcAqvorJohe6YwKtQbSYrHkPEJmV7HXA9VEJEREfDGLMHNTyBwEOgCISA2MgTyeUaHWQOYBfv35R27v1Ji+7Rvw9Sfvpno+5YtxDOjSjEE9bubRwbcQFXEw2fO/z5+j581hvDXiWY/0/bxsCe2b1aFt4zA+fu/NVM//98tqwts3p6r/jfwwd1Zi+o5tW7itWxs6t2xA1zaNmf/9dI/buGTxIuqEVScstCpvjhmV6nl0dDR3DuxPWGhVWrVoyoH9+xOfvTn6DcJCq1InrDpLlyzOtTr3blzFZw905dP7OrN2+vh05f5Ys5jR4aGJsc23/zSPLx/rnXiN7lmDo3t3eqRz9U9LCW9dn2431+XzD99O9XzD2tX069qSuhX9WDJ/drJnb//fi9zSvjE92zbk9ZeeJasD/GVmFduJW/8osBgTeO87Vd0uIiNFJCGe79PAfSKyBRNnaqi6aVSeMZAiEicim0XkdxGZJyJ+TnqgiMzIRLkrROSK5zVE5GkRUSckLCLSVkTOOnXcLCIvu8gOEJFNIvLkleqJi4vjrRHP8u4X0/l20VqWzJ/Jvt27kslUr1mHibOXM3nBGtp17cWHo0cke/7p2Nep36S5x/pe/veTTJw6hyVrfmPu99PZ/UfyL2NQcHne/GA8vfokDyhfqEgR3v7wC5as3sRX0+Yw8sXnOHf2jEc6n3z8EebMW8hvW3cwfeq37NyxI5nMxAlfUMKvBNt37eGxJ/7Ff194HoCdO3YwfdpUNm3Zztz5i3jisYeJi4vLdTrj4+JY+vFI+r3yGfd+NJ8dPy/gxME9qeSiL15gw9xJBFSvm5gW1q4nd38wm7s/mE3406PxKxdMuco1PGrj/734NB9PmsXcn9bzw5wZ/PVn8s9OQFB5/u+dT+jeO3ns6982rOW3DWuZtXQts5etY/uWjaz/dbVbnZkhk6vYqOoPqnqTqlZR1dectJdVda7zeoeq3qyqdVW1nqoucVdmnjGQwCWnUbWAU8AjAKoaqap9s7MiIlIe6IzpsruyyqljPVUd6ZI+AGgMNBORVNEYM2LHlo0EV6xMUIVKFPD1pVOP21j54w/JZBo2b0WhwkUAqFWvMceOJE297Pp9M6dOHKNJy4zjZyewZdN6KlaqQoVKIfj6+tKzdz+WLpyfTCa4QkVqhNUmX4oodJWrVCOkSlUAyvkHUqpMGU6eOOFW5/p166hSpSohlSvj6+tLv/4DmD9vTjKZ+fPmMGiwiRd9W5++rFi+DFVl/rw59Os/gIIFC1IpJIQqVaqyft26XKcz6s+t+AVUwM+/PPkL+FKjdXd2r12WSm7VN+/TrO+9+BTwTbOcHT8voEZrt/ubAdi2eQMVKlWmfMUQCvj60u2WPixfkvxvGVS+ItVr1iJfCgMkIsRER3M5JoaYmGgux8ZSqkwZj/ReDe56jzl1TjsvGUhXfsUs6yMilUTkd+f1UBGZ4/QKd4vIcBeZXSIyWUR2isgMESmSslAR6Swivzq9vekZGLN3MfGuPR1zJPx1FU+mm104fjSKsgFJTgjK+gdy/GhUuvLzpk+ieZtOAMTHx/Pe6y/y+L9f9VjfkahIAoKCE+/9A4M4EpVyrts9mzet53JMDBU9CDofGRlBcHDS/HpQUDARERGpZcobGR8fH4oVL87JkyeJiEidNzLSfX2zW+f5k0cpViYg8b5oaX8unDyaTObInu2cPxFFlcZt0y1n16qF1Gjdw237AI5FReHv8tkp5x/Esaj0Pzuu1GvYlMYtWtGuYTXaNajGzW06UKVaqEd5r5bMnqTJkjrliNZM4OyY70DqCdgEmgB9gDpAP5fhc3XgI1WtAZwDHk5RbmnMTvuOqtoA2AA8lYb+W4AIVd2Shu7mIrJFRBaKSJhL+iynvA2qmiqavIjcLyIbRGTDmVPue1zpsXD2NHZu28yd95ow4DO/+ZwWbTslM7DZwbEjUTz18D28+f6nudIBQW5E4+NZ/vko2t/zfLoykX9swadgIcpUuinL63Nw31/s3f0Hy9bvYvmGP1i35mc2/m9N1irN3Cp2lpCX9kEWFpHNmJ7jTmBpOnJLVfUkgIjMAloCs4FDqprwF/4GeBx4yyVfM8wRpTVOd94X01NNxOl1voAZXqdkE1BRVS84ZzxnA9UAVPUr4Kv0GuZsdh0PUKN2/WS90jLlAjjm0oM7diSSMuUCSMm6NSuY+PE7fDxlPr4FCwKwbfN6tqz/lZmTv+DSxb+5HHOZwkVu4JHnRqRXFfwDAomKOJx4fyQyIlkvxB3nz59j2MDbeOaFEdRvlHKfbtoEBgZx+HDSHt+IiMMEBQWlljl0iODgYGJjYzl39iylSpUiKCh13sBA9/XNbp1FS5Xj3PGk3tv5E0e4sVSSW7uYS39z4uBupvznLgD+Pn2CWa8+zG0vfURAtdoA7Fz5AzXbeNZ7BCgbEJCs93/0SARlA1J/dtLix0XzqNugCUVuMIOolu06s2XjOho2vdlj/VeE5E5vPrmvRulzSVXrARUxvyePpCOXctirbtITEIxxTZhDrKmq96SQqQKEAFtEZD9mr9UmEfFX1XOqegHMZDFQIGEBJzPUqNOAQwf+IvLQAS7HxLB0wSxadeiWTOaP7VsZ/eK/ePPTKZQslTRPNPKdz5iz6ndm/7yVx/79Kt1v7Z+hcQSoU78R+/ft4dCB/cTExDBv9nQ6dvXsSxkTE8ODQ/pz2+0D6d7rNo/b2KhxY/bs2c3+ffuIiYlh+rSp9AjvlUymR3gvJk8yvzGzZs6gTbv2iAg9wnsxfdpUoqOj2b9vH3v27KZxkya5TmfATbU5HXmAM0cOE3c5hp0rf6Bq06R54YI3FOXxKWt5aMJyHpqwnMDqdZMZR42Pv6LhNUCtug05uO8vDh/cz+WYGBbOmUm7Tp7lDwgqz4a1q4mNjeXy5ctsWLuaytWqe6z7ShGcwF0ZXDlBXupBAqCqF0XkcWC2iKR12LyTiJQELgG9gWFOegURae5sEB0IpFySWwuME5GqqrpHRG4AglT1Txfd24CyCfeOkWykqidExB84qqoqIk0wPz4nM9teHx8fnhk+hifu7kN8XBzh/QZR+aYajB/7OqG16tG6Y3c+GP0yFy/+zX8fGwpAuYBg3hr/7VXre+WNd7nr9p7Ex8fR744h3BRak3dGjaR2vQZ06hrOlt828OCQ/pw9e4ZlS35g7Jj/Y8nqTSyYM5N1v67m9KlTzJj6DQBvfTCemrXrutX57nsf0rNHF+Li4hgydBg1w8IYOeJlGjRsRHjPXgwddg/Dhg4mLLQqJUqUZNLkqQDUDAujT7/bqV+nJj4+Pox9fxz587uPr5zdOvPl96HTgy/x3cv3oPHx1O7UhzIVq7Hqm/fxr1aLak0zXkQ79Pt6ipYJwM+/fIZyKdv4wqtv8cCg3sTFx3Nr/8FUrV6DD9/8P8Lq1qdd5x5s27yRJ+8dyLmzZ1ixdCHj3nmNOcvX07lHb9at+ZlbOzZFRGjZtiNtO3m2OHR1SKqFotyAZPXeJm8hIhdU9UaX+3mYXfGrgPmqWktEhmKMYnFM7+4bVX1FRCoBizDzgA2BHcBgx9iuAJ5R1Q0i0h4YDRR01LyYsEUgnTrtJ8lAPgo8BMRijPNTqvrLlbazRu36OnH2T1eaLVOUK14oW/X5+2WvvpxixOI/slVfTngUrxVcdGMmj/8BUMj/Jq045IMMZf4c09Uruq6EPNODdDWOzn1Pl9taLq8Pq2rvNIqIVdU70yi3rcvr5ZjtOJ7WqZLL6w+BDz3Na7FYkhCB/PlzXw8yzxhIi8VybZMLQ9JcWwZSVScCE9NI30/yXqbFYslNCLlyDvKaMpAWiyVvYlaxrYG0WCyWNMi544QZYQ2kxWLJFdghtsVisaRFDm4GzwhrIC0WS44j2B6kxWKxpIudg7S4pYBPPoJKFs5WnaWLFnQv5EVOnI/OVn05RZtKJbJV30/7M4wekLux23wsFoslbRKcVeQ2rIG0WCy5gNzprMIaSIvFkiuwc5AWi8WSBmLnIC0WiyV9bA/SYrFY0iFP9SBF5AMyiNqnqo9nSY0sFsv1Rx48SbMh22phsViuaySvrWI7kfgSEZEiqnox66tksViuR/JlsgspIl2B94D8wOeqOioNmduBEZjR8RZVHZhhnTxQ2lxEdgC7nPu66QTLslgslqsiYRU7oyvj/JIfGAd0w4RvvkNEaqaQqQb8B7hZVcOAJ93Vy5Owr2OBLjgR+lR1C9Dag3wWL/HTj0to06Q2LRvWZNzYN1M9X/vLKrq1bUalMjewYM6sZM+mfzuJVo3CaNUojOnfTvJI35LFi6gTVp2w0Kq8OSbVjzDR0dHcObA/YaFVadWiKQf270989uboNwgLrUqdsOosXbI417YxJ3RuWL2c+8JbcE+3pnz3+fupni+Y9hUP3dqGR/u055nBPTn4V1LQr2mfvcc93ZpyX3gLNq7xPKjbjrU/8+odHXilfzuWTPo4XbnNKxbyWMvKHNy1NTFtyaSPeKV/O169owM7/7fSY51XSz7J+HJDE2CPqu5V1RhgKnBLCpn7gHGqehpAVY+5rZMnFVfVQymS4jzJl5cRkTgR2Swiv4vIPBHxu4oy2orI/MzUIy4ujhefe4Kvv5vD8l83M2fmd/y5a2cymaDg8rwz7jN69+2fLP306VOMHfMac5euYt6Pqxk75jXOnDntVt+Tjz/CnHkL+W3rDqZP/ZadO3Ykk5k44QtK+JVg+649PPbEv/jvC88DsHPHDqZPm8qmLduZO38RTzz2MHFx7j8q2d3GnNAZFxfHR//3b0Z+PIVP5q7i5x++T2YAAdr1uI2Pv/+ZD2cup++wR/hszHAADv71BysXzuaTOSt59ZNvGffq8x69r/FxcUx/ZzgPvfUl//1mMRt/nEfUvt2p5P65eIEV0ydSqWa9xLSofbvZ+ON8Xpi0iIfensh3b79MvAc6M4MHPcjSIrLB5brfJXsQ4GqnDjtprtwE3CQia0RkrTMkz7hOHtT7kIi0AFRECojIM8BOd5muAS6paj1VrQWcAh7JiUps3rieSiFVqFipMr6+vvS6rR9LFs5LJlO+QiVqhNVG8iX/c/68fCmt2nagRImS+PmVoFXbDqxYtiRDfevXraNKlaqEVDb6+vUfwPx5c5LJzJ83h0GDhwBwW5++rFi+DFVl/rw59Os/gIIFC1IpJIQqVaqyft26XNfGnND557ZNBFYIIaB8JQoU8KV1t978unxRMpkiNxZNfP3PpYuJy7q/Ll9E6269KeBbEP/gigRWCOHPbZvctvHAzi2UDq5I6aAK+BTwpWHHcLatXppKbsFn79Bx0AP4+CY5Ldm2eikNO4ZTwLcgpQPLUzq4Igd2bnGr82oRzEJNRv+AE6rayOUaf4VqfIBqQFvgDuAzdx0fTwzkgxjjEAREAvXIIWORg/yK82skIvWcX5+tIvK9iJRw0quKyI8iskVENolIFdcCRKSxiPyWMt0dR6IiCQwKTrwPCAziSFSkZ3kjIwlwyesfGMSRyIzzRkZGEBycFJw+KCiYiIiI1DLljYyPjw/Fihfn5MmTRESkzhsZmTxvmvXM5jbmhM6Tx45Q2j8w8b50uUBOHjuSSm7etxMY1rUJE95+lQf/81pi3jL+QS55A9LMm5Izx49QomxA4r1fmQDOHD+aTObQH79z+lgUtVq0T5H3KCXKBrrk9efMcfc6rxoR8ufL+HJDBFDe5T7YSXPlMDBXVS+r6j7gT4zBTBe3BlJVT6jqIFUtp6plVPVOVT3pLt+1gjP52wGY6yR9DTyvqnWAbcBwJ30yZn6jLtACiHIpowXwCXCLqv6Vho77E4YNp07kYZdVlkzT845hTFi0jrufepGpn76bpbri4+OZ9cFr3Prof7NUj6eIZHy5YT1QTURCRMQXGEDSdzaB2ZjeIyJSGjPk3ptRoZ6sYld25uCOi8gxEZkjIpXdVjfvU1hENgNHgHLAUhEpDvip6s+OzFdAaxEpCgSp6vcAqvqPy5aoGsB4oKeqHkxLkaqOTxg2lCxdJtkz/4BAIiMOJ95HRUbgHxCYsog08Q8MJMol75HICPwDM84bGBjE4cNJUzkREYcJCgpKLXPIyMTGxnLu7FlKlSpFUFDqvIGBKaeB0qhnNrcxJ3SWKuvPiSNJvcwTRyMpVdY/Xfk23W7l1+ULE/MeP5LUGTpxNCrDvAn4lfHn9LHE32nOHI/Cr0y5xPvoixeI2vcn7z92B8P7tmL/jt/49Pn7ObhrK35lynH6WKRL3iP4lXGv82oRyFQPUlVjgUeBxZgpwO9UdbuIjBSRXo7YYuCksyvnJ+BZd509T4bYU4DvgAAgEJgOfOtBvrzOJVWtB1TE/P2udlohCvgHqH81mes2aMT+vXs4eGAfMTExzJ01nU5dwz3K26Z9J1b+9CNnzpzmzJnTrPzpR9q075RhnkaNG7Nnz2727zP6pk+bSo/wXslkeoT3YvIks0121swZtGnXHhGhR3gvpk+bSnR0NPv37WPPnt00btIk17UxJ3TeVKs+kQf3cuTwAS5fjmHlwtk0a9clmUzEgaTOzPqVSwmsYPohzdp1YeXC2VyOiebI4QNEHtzLTbUbuK1nhdA6HD+0nxORh4i9HMPGH+dT++aOic8L31iMUQs28sqMVbwyYxWVatbngdHjqRBah9o3d2Tjj/O5HBPNichDHD+0n4o16nr0/lwtIpLh5Q5V/UFVb1LVKqr6mpP2sqrOdV6rqj6lqjVVtbaqTnVXpidnsYuoqus+hm9E5FkP8l0TqOpFEXkc0z3/CDgtIq1UdRUwGPhZVc+LyGER6a2qs0WkIGazKsAZ4B5MD/RvVV1xJfp9fHx4dcxY7uzbk7i4OPoPGkL1GjV56/VXqFO/IZ27hbN50wbuG9yfs2dP8+OiH3hn1Kss+/U3SpQoyePP/IfwDjcD8MSzL1CiREm3+t5970N69uhCXFwcQ4YOo2ZYGCNHvEyDho0I79mLocPuYdjQwYSFVqVEiZJMmmw+ZzXDwujT73bq16mJj48PY98fR/78+TPUlxNtzAmd+X18eOiFN3jxgQHEx8XR+dY7qFg1lEkfjqZaWF2atevKvClfsHntKnx8fLixWHGeft1sBapYNZRWXXrxQK9Wppz/jvLofc3v40O/p0bw0VND0Ph4mvXoR0Dlm1jw+btUCK1N7ZYd080bUPkmGrTvwet3diFf/vz0e+oV8nmg82oRwZN5xmxHVNM+bi0iCX/x54HTmH1FCvQHSqjqf7KlhjmEiFxQ1Rtd7udhetLbMPOJRTDzF3er6mlnE+qnQGngMtAPqAA8o6rhIlIBWAgMU9X/pae3Tv2G+sPyX7KqWWliQy5kDdsiz2arvr/O/J2t+gAea1l5o6o2ymw5JUNqaucRkzOUmTa0gVd0XQkZ9SA3Ygxigll/wOWZYnakX7O4GkfnvqfLbbM05HcD7VMk7wVWOM8PAmHeraXFcm2QMAeZ28joLHZIdlbEYrFcx3g4z5jdeOQPUkRqYc43FkpIU9Wvs6pSFovl+iNPefNJQESGY/YO1QR+wBwGX43ZD2ixWCyZRvDovHW248k2n76YjdJHVPVuoC5QPEtrZbFYrjvyiWR45QSeDLEvqWq8iMSKSDHgGMmP9FgsFkumEMm8P8iswBMDucE50P0ZZmX7AuZsssVisXiNPDkHqaoPOy8/EZFFQDFV3ZpRHovFYrlScmEHMsOgXemeZRKRBqrq3t+SxWKxeICIRx57sp2MepBvZ/BMSb0p2uIF8gkU9PHIj3Ge5eCJ7A9t5O9XyL2Ql6letqh7IS+yMepcturzNnlqH6SqtsvOilgslusXAfLnJQNpsVgs2UkuHGFbA2mxWHKe3OrNxxpIi8WSK8iF9tEjj+IiIneKyMvOfQURce8F1WKxWDwksx7FswpPlks/AppjooABnMcE6LZYLBavkc/NlRN4MsRuqqoNROQ3AMc5rG8W18tisVxH5MV9kAlcdiL7KYCIlAHis7RWFovluiMX7vLxyEC+D3wPlBWR1zDefV7M0lpZLJbrCgF8cmEP0pO42JOB54A3MBH6eqvq9KyumCWJ5UsX07xBGE3q1uD9d8akeh4dHc19QwfSpG4Nura7mYMH9ic+2/77Vrp1aEWrJnVp06w+//zzj1t9SxYvok5YdcJCq/LmmFFp6rtzYH/CQqvSqkVTDuxP0vfm6DcIC61KnbDqLF2y2OM2rl35IwO6NOH2jg2Z9OnYVM+nThjHoG7NuKtnSx6/qzdHIpLCy7YKLc2QXq0Z0qs1zz040GOdPy9fQsfmdWnXpBafvP9Wqufrfl1Nrw7NuSmgKAvnfZ+YvmPbFvp2a0vXVg3p3qYJ82fPyJX6AHavX8nYuzvz7pAOrJz6abpy21ct4qVO1Yj4Y1uy9DPHInm1Z11WT//cY51XSybjYmcJnjjMrQBcBOa5pqUX4/laQET+CwwE4jDTCQ9kFGjLwzJXYAJ4bbiSfHFxcTz/9BNMn/MDgUHBdG7bnC7dw6keWjNRZvLXX1LcrwTrtuzk+xnTeHX4C3w2cQqxsbE8fN9Qxo3/klq163Lq5EkKFCjgVt+Tjz/CgoVLCQoOpmWzxoSH96JGzSR9Eyd8QQm/EmzftYfvpk3lvy88zzdTprFzxw6mT5vKpi3biYqMpHvXjmzb8afbCHxxcXG8/cpzjP1yFmX9A7m3TwdaduhKSNXQRJlqNevwxazlFCpchO+nTGDcmOG8+t4EAAoWKsxXc1deydtKXFwcI57/F19Nn49/YBC3dm5Fhy49qFa9RqJMYFB5xrw/ns8+ei9Z3sJFivDmuM8JqVyVo0ciuaXjzbRu15Fixf1yjT6A+Lg45n0wgqGjJ1KstD+fPNqH0ObtKVuxWjK56IsX+PX7rwgOTR3WdeEnr1OtcesM9XgFyZ0naTxZHFoAzHf+X4YJRLUwKyuVk4hIcyAcaKCqdYCOwKGMc2UdmzasJ6RyFSqFVMbX15db+9zOogXzksksWjCP/ncMBqBn7z6sWvETqsqKZUupGVabWrXNB79kqVJujdX6deuoUqUqIZWNvn79BzB/3pxkMvPnzWHQ4CEA3NanLyuWL0NVmT9vDv36D6BgwYJUCgmhSpWqrF+3zm0bd27dSHDFEIIqVKKAry8detzGqh+Tf8QaNmtFocJFAAir14jjRyPTKspjtmzaQMWQKlSoFIKvry/ht/blx0Xzk8kEV6hIaFht8uVL/jUJqVKNkMpVASjnH0ip0mU5efJErtIHcPiPrZQKrEjJgAr4FPCldtse7PxlWSq5ZRPH0qr//fj4Jo9uuWPNUkr4B1O2UrVUebxNgkfxjK6cwJMhdm1VreP8Xw1owrXtDzIAOKGq0QCqekJVI0XkZRFZLyK/i8h4cU7Wi8gKERktIutE5E8RaeWkFxaRqSKyU0S+BwpfTWWOREUQFBycVLnAIKIiI9OV8fHxoWix4pw6dZK/9uxGRLi9dw86tGrCB2NTD+tSEhkZQXBwkj/koKBgIiIiUsuUL5+or1jx4pw8eZKIiNR5IyOT502L40ejKOsflHhf1j+Q40ej0pWfN/0bmrVOiukcE/0Pw25rz339OrFy6QK3+gCOHokkIChJp39AEEejrtzobtm0nsuXY6hYqXKu0gdw7sQRipcJSLwvXtqf8yeOJpOJ3L2ds8ejqN40ueuF6Et/s3raeNoNfuyK63i15NV9kMlw3Jw1zYK65BaWAOUdY/eRiLRx0j9U1caqWgtj7MJd8vioahPgSWC4k/YQcFFVazhpDdNTKCL3i8gGEdlw8oT7noGnxMbFsm7tL3z8xVfMW7yCH+bNYeWK5V4rPydYPOc7dv3+GwPvTfrizvxpCxNmLWfE25/x3usvcPjgvmypy7GjUTz9yL2Mfu/TVL2+vKAvPj6ehZ+8TtcHUkdw/unrD2je524KFr4h03o8wRs9SBHpKiJ/iMgeEfl3BnJ9RERFxG2MbU/mIJ9yuc0HNAAyN77JxajqBRFpCLQC2gHTnDf7vIg8BxQBSgLbSZqXneX8vxGo5LxujdkBgKpuFZF0nQyr6nhgPEC9Bg3V9Zl/QBARhw8n3kdFRhAQGEhaMoFBwcTGxnL+3FlKlixFYGAQzVq0pFSp0gB07NyVrVt+o3Xb9D3VBQYGcfhw0oxCRMRhglx6Pokyhw4RHGz0nTt7llKlShEUlDpvYGDyvGlRplwAx44k9TSPHYmkTLmAVHLr16zgq4/fZtzk+fi6DAfL+Jv3I6hCJeo3acnuHVsJrpBx1OJy/oFEufSMj0RFUC4gMIMcyTl//hz3DryNp18YQf1G7g+WZbc+gGKl/Tl7PKknfvbEEYqWLpd4H3Ppb47t382EZ+4E4MKp40x++UEGjfyEw7u2sH3VIpZ8NoZ/LpxD8uXDp0BBmvUe7HGdr4hMnsV2tiKOAzoBh4H1IjJXVXekkCsKPAF4tKbgyc9QUZerIGYu8hbPq573UNU4VV2hqsOBR4FBmBNFfVW1Nib8hKuDwWjn/zi8fL69fsNG7N27hwP79xETE8P3M7+jS/fwZDJduocz7dtJAMybPZOWbdoiIrTr0JmdO37n4sWLxMbG8suaVVR3WRRIi0aNG7Nnz2727zP6pk+bSo/wXslkeoT3YvKkrwCYNXMGbdq1R0ToEd6L6dOmEh0dzf59+9izZzeNm7j/MofWbsDh/XuJPHSAyzExLFswi5YduiaT+XPHVsa8/BSjP5lCiVJlEtPPnT1DTIx5+8+cOsm2Tf+jUtXqbnXWqd+Q/Xv3cOjAfmJiYpj//Qw6dOnhNh9ATEwMDw0dwK23D6Jbz1s9ypPd+gCCqtfmZMR+TkcdIvZyDNtWLCC0eYfE54VuKMp/Zq7j6W9W8PQ3KwiuUY9BIz8hqHpt7n3328T05rcNpfUdD2adccQrPcgmwB5V3auqMcBU0rZTrwKjAffbOXDzZXasclFVfcaTwq4FRKQ6EK+qu52kesAfQB3ghIjciNkL6m6vxUrMSvhyJ654naupj4+PD6PeHEv/W3sQFxfPwMFDCK0Rxqj/G0G9Bg3p2r0ng+66m0fuH0qTujUoUaIEn375DQB+JUrw4CNP0KVtc0SEDp270qlrd7f63n3vQ3r26EJcXBxDhg6jZlgYI0e8TIOGjQjv2Yuhw+5h2NDBhIVWpUSJkkyaPBWAmmFh9Ol3O/Xr1MTHx4ex749zuyiUoPNfL4/hqXv6EhcXR3jfQVSuVoPP3nud0Fr1adWhG+NGD+fSxb958fG7ASgXGMyYT6Zw4K8/GPPyU+STfMRrPHfe/0Sy1e+MdA4f9Q5D+/ciPi6OvgPv4qbQmrw7aiS16zWgY9dwtv62gYeGDuDs2TMsX/ID7435Pxat2sgPc2ay/tfVnDl1kplTzQ/TmPfHU7N26lXgnNIHkD+/D+GPDuer/wwjPj6OBl36Uq5SNZZNHEvgTbWp0aJDhvmzF/FkFbu0iLjuAhnvjL4Agki+mHqYFFOBTpSE8qq6QESe9ahWqpr2AxEfVY0VkV9VtbknhV0LOMPrDwA/IBbYA9yPmV+8AzgC/AkcUNURrtt3RKQ0sEFVK4lIYeBLTJjcnZg/4CPutvnUa9BQl/68Niuali5FC2e89cfbbNp3Olv1Qc54FM9upmxxvyDmbV7qVG2jqrqdy3NHxdA6+vyEuRnKPHJzSLq6RKQv0FVV73XuB2OOST/q3OcDlgNDVXW/p9vuMupBrsPMN24WkbnAdODvhIeqOiu9jHkZVd0ItEjj0YukcYJIVdu6vD6BMwepqpeAAVlSSYvlWkMyfZImguThqIOdtASKArWAFc4GFH9groj0yshIejJfVgg4iYlBo5jpAiVpYcJisVgyhZDp0zLrgWoiEoIxjAMwU1wAqOpZoHSiPi/0IMs6K9i/k2QYE/Vdae0tFoslIzKziu1MBz4KLAbyAxNUdbuIjMRMe2U8fk+HjAxkfuBGkhvGxPpcjTKLxWJJCyHzPh9V9QfghxRpL6cj29aTMjMykFGqOtLj2lksFsvVIpAvF57FzshA5r7aWiyWaxKzDzL3mZyMDGRu2iRlsViucXKhO8j0DaSqnsrOilgslusZQfJYD9JisViyBW8s0mQF1kBaLJZcQV6bg7TkAPlFsv3oX3bTIKRETlchWyjR+NFs1Xd6/YfZqg/gJW8VJNghtsVisaSFkDtDLlgDabFYcgW5zzxaA2mxWHIBtgdpsVgsGZAL7aM1kBaLJTcgdhXbYrFY0sLsg7QG0mKxWFIjkA2BIa8YayAtFkuuQGwP0mKxWFKTW1exc2Gn1pKSJYsXUSesOmGhVXlzzKhUz6Ojo7lzYH/CQqvSqkVTDuzfn/jszdFvEBZalTph1Vm6ZHGu1He96Pxk+CAOLHuDDdNfSFfm7ef68vuc4ayb9h/qhQYnpg/q2ZRtc15m25yXGdSzabr5c7qNmUEk4ytHUFV7XeUF/BfYDmwFNmPCTH4O1HSe78fEwfADHvakzAYNGuqly5p4XfgnVkMqV9Ydf/ylZ/+O1tq16+imLduTyYx9f5zee98Deumy6lfffKt9+t2uly6rbtqyXWvXrqNnLvyjO//cqyGVK+uFf2KT5U15Zbe+a1lnoXqPJLs6DHtHmw14Q3/fHZHqWaF6j+gtj47TRat/10L1HtHWg9/UdVv3aaF6j2hA62d176HjGtD6WfVv9YzuPXRc/Vs9kyp/TrQRE84g09+l6mF19ec/TmZ4eUvXlVy2B3mViEhzIBxooKp1gI7AIVW9V1V3pBD3Ax6+Gj3r162jSpWqhFSujK+vL/36D2D+vDnJZObPm8OgwUMAuK1PX1YsX4aqMn/eHPr1H0DBggWpFBJClSpVWb9uXa7Sdz3pXLPpL06dvZju8/A2dZgy35Szbtt+ihctjH/pYnRqUYNla3dx+txFzpy/xLK1u+h8c81c2carR9z+ywmsgbx6AoATqhoNJuSrqkaKyAoRSRm7dxRQRUQ2i8ibV6IkMjKC4OCkaJZBQcFERESklilvZHx8fChWvDgnT54kIiJ13sjIjGMnZ7e+60mnOwLL+nH4SFLM8IijZwgs60dgGT8OH3VJP3aGwDJ+bsvLjW1MFzEOczO6cgJrIK+eJUB5EflTRD4SkTYZyP4b+EtV66nqsykfisj9IrJBRDYcP3E8yypsseRWEkIuZHTlBNZAXiWqegFoCNwPHAemicjQqyxrvKo2UtVGZUqXSfYsMDCIw4cPJd5HRBwmKCgotcwhIxMbG8u5s2cpVaoUQUGp8wYGJs+bkuzWdz3pdEfksTME+ye5ggsq50fksTNEHj9DcDmX9LJ+RB4/47a83NjGjMiNizTWQGYCVY1T1RWqOhx4FOjjbR2NGjdmz57d7N+3j5iYGKZPm0qP8F7JZHqE92LypK8AmDVzBm3atUdE6BHei+nTphIdHc3+ffvYs2c3jZs0yVX6ried7ljw8zYGhptymtSuxLkLlzhy4hxLf9lJx+ah+BUtjF/RwnRsHsrSX3bmyTZmRG6cg7T7IK8SEakOxKvqbiepHnAAqJWG+Hmg6NXo8fHx4d33PqRnjy7ExcUxZOgwaoaFMXLEyzRo2Ijwnr0YOuwehg0dTFhoVUqUKMmkyVMBqBkWRp9+t1O/Tk18fHwY+/448ufPn6v0XU86v3pjKK0aVqO0343sWfQqr37yAwV8TL7PZ6xm0ertdGkZxva5w7n4z2UeGPENAKfPXeSNzxax+pvnAHh9/CJOn0t/sScn25gZcmPQLnG2o1iuEBFpCHyAWaGOBfZghtszgGdUdYOI7AcaqeoJEZkC1AEWpjUPmUDDho10zf82ZHX1LdnA9eBRvHAB2aiqKRclr5gatevr13NXZCjTpLKfV3RdCbYHeZWo6kagRRqP2rrIVHJ5PTDra2Wx5E1EMh+TRkS6Au8B+YHPVXVUiudPAfdiOjTHgWGqeiCjMu0cpMViyRWImyvDvCL5gXFAN6AmcIeIpNws+htmRFcHM9Ib465O1kBaLJZcgImLndHlhibAHlXdq6oxwFTgFlcBVf1JVRMmb9cCwbjBGkiLxZIryOQ2nyDgkMv9YSctPe4BFror1M5BWiyWHEfwyAiWFhHXFczxqjr+inWJ3Ak0AjI63AFYA2mxWHIJHux1PJHBKnYEUN7lPthJS65DpCPGyUybhGPCGWGH2BaLJVeQybPY64FqIhIiIr7AAGCuq4CI1Ac+BXqp6jGP6nTlzbBYLBYv424J242BVNVYzGm2xcBO4DtV3S4iI0Uk4fjQm8CNwHTHcczcdIpLxA6xLRZLjpPgrCIzqOoPwA8p0l52ed3xSsu0BjKX8XdMHJv2nXYv6EUahJRwL+RFzl+6nK36AIoWLpDtOg+ufDdb9XX/6Jds1edtcuFJQ2sgLRZL7sCDvY7ZjjWQFoslV5AL7aM1kBaLJXdgDaTFYrGkgVmozn0W0hpIi8WS8+Rg3JmMsAbSYrHkDqyBtFgslrTIucBcGWENpMViyXE88fmYE1gDabFYcgW5cR+kPYudB1i78kcGdGnC7R0bMunTsameT50wjkHdmnFXz5Y8fldvjkQkucVrFVqaIb1aM6RXa5570LOoD0sWL6JOWHXCQqvy5phRqZ5HR0dz58D+hIVWpVWLphzYvz/x2Zuj3yAstCp1wqqzdMlij9u4fOlimjcIo0ndGrz/TmpHz9HR0dw3dCBN6taga7ubOXggSef237fSrUMrWjWpS5tm9fnnn39yZTtzoo2NK/rx1eD6TLqrPnc0TNs9YptqpZhwZz0mDKrHf7tUA6BK6SJ80K82EwbV47OBdWlbrZRH+jJDbgz7mmU9SBGJA7Y5OvYBg1X1jIgEAu+rat+rLHcFTlAsr1U2Y329gT9VdYdzPxJYqao/XmE5lYD5qppW1MN0iYuL4+1XnmPsl7Mo6x/IvX060LJDV0KqhibKVKtZhy9mLadQ4SJ8P2UC48YM59X3JgBQsFBhvpq78or0Pfn4IyxYuJSg4GBaNmtMeHgvatRM8l4/ccIXlPArwfZde/hu2lT++8LzfDNlGjt37GD6tKls2rKdqMhIunftyLYdf7qNhhcXF8fzTz/B9Dk/EBgUTOe2zenSPZzqoUk6J3/9JcX9SrBuy06+nzGNV4e/wGcTpxAbG8vD9w1l3PgvqVW7LqdOnqRAAffHCrO7nTnRxnwCT7StzLPfb+f4hRg+7l+HX/ad4sCpS4kyQcULMbBREI9P38aF6Dj8nCOZ0bHxjFqym4iz/1DqhgJ8MqAu6w+c4e+YOLd6r4pcuoqdlT3IS6pazzEIp4BHAFQ18mqNY3YjIj5Ab0yMC8Acfr9S45gZdm7dSHDFEIIqVKKAry8detzGqh+TO0Ju2KwVhQoXASCsXiOOH428an3r162jSpWqhFSujK+vL/36D2D+vDnJZObPm8OgwUMAuK1PX1YsX4aqMn/eHPr1H0DBggWpFBJClSpVWb9unVudmzasJ6RyFSqFGJ239rmdRQvmJZNZtGAe/e8YDEDP3n1YteInVJUVy5ZSM6w2tWrXBaBkqVIehSfN7nbmRBtDy91IxJlLRJ2LJjZeWb77BC0ql0wm06NWOeZsPcKFaGP4zjjn5A+f+YeIs6aXevLvy5y5eDnReGYdmYlKkzVk1xD7Vxz35yJSSUR+d14PFZE5IrJCRHaLyHAXmV0iMllEdorIDBEpkrJQEeksIr+KyCYRmS4iN6Z4Hioi61zuK4nINud1QxH5WUQ2ishiEQlw0leIyFjHc/HzQC/gTcc9UhURmSgifR3ZxiLyi4hsEZF1IlLU0bHKqdMmEUkr8qHHHD8aRVn/pKFRWf9Ajh+NSld+3vRvaNY6yWlJTPQ/DLutPff168TKpQvc6ouMjCA4OMnvaFBQMBEREallyhsZHx8fihUvzsmTJ4mISJ03MjKVz9JUHImKICg4KTxIQGAQUZGR6cr4+PhQtFhxTp06yV97diMi3N67Bx1aNeGDsW+51ZcT7cyJNpa+sSDHLsQk3p+4EEOZG3yTyQT7FSLYrzDv963Fh7fXpnFFv1TlhJa7EZ/8QuRZz4b1V4Px5pMpf5BZQpYv0jjRxjoAX6Qj0gSoBVwE1ovIAuAEUB24R1XXiMgE4GEg8ZMhIqWBF4GOqvq3iDwPPAWMTJBR1V0i4isiIaq6D+gPTBORApiY1reo6nER6Q+8BgxzsvomeC4WkWqYofEM5z5Bvy8wDeivqutFpBhwCTgGdFLVf5y832Lcu2c5i+d8x67ff2Pc5PmJaTN/2kIZ/0AiDu7n8SG3ULl6TYIrhGRHdbKF2LhY1q39hcUrfqFw4SL06dmFuvUa0Lpt+5yumtfIyjbmzycE+xXiX7O2U+ZGX8b2qcU9kzcnDqVLFinAfzpXY9TS3WimtWVMLlyjydIeZGER2QwcAcoBS9ORW6qqJ1X1EjALaOmkH1LVNc7rb1zSE2iGGfqucfQMASqmUf53GMOI8/80jPGtBSx18r5I8ghn0zxoX3UgSlXXA6jqOcdpZwHgM6enOh2X4Xl6iMj9IrJBRDacOXUi2bMy5QI4diSpd3LsSCRlygWkKmP9mhV89fHbjPlkCr6+BZPy+wcCEFShEvWbtGT3jq0Z1iUwMIjDh5MWeSIiDhMUFJRa5pCRiY2N5dzZs5QqVYqgoNR5AwMziptk8A8IIuLw4cT7qMgIAgID05WJjY3l/LmzlCxZisDAIJq1aEmpUqUpUqQIHTt3ZeuW39zqzO525kQbT1yIpuyNST3G0jf6cvzvmGQyxy/E8Mve08TFK0fORXP4zCWC/QoDUMQ3P2/0qsEXvx5k55ELbvVllkxGNcwSsnwOEmO0BGcOMg1S/jCpm/QEBGNc6zlXTVW9J43ypwG3i8hNgKrqbifvdpe8tVW1s0uevzNuWob8CzgK1MX0HH0zFgdVHa+qjVS1kV/J0smehdZuwOH9e4k8dIDLMTEsWzCLlh26JpP5c8dWxrz8FKM/mUKJUmUS08+dPUNMjAm7cebUSbZt+h+VqlbPsC6NGjdmz57d7N+3j5iYGKZPm0qP8F7JZHqE92LypK8AmDVzBm3atUdE6BHei+nTphIdHc3+ffvYs2c3jZs0cdd86jdsxN69eziw3+j8fuZ3dOkenkymS/dwpn07CYB5s2fSsk1bRIR2HTqzc8fvXLx4kdjYWH5Zs4rq1Wu41Znd7cyJNu46eoEgv8L4FyuITz6hfbXS/Lr3VDKZNXtPUTe4GADFCvkQ7FeYqHP/4JNPGNmjOkt2HWflnpNudXmD3DcDmQ1DbFW9KCKPA7NF5KM0RDqJSEnM8LQ3ScPcCiLSXFV/BQYCq1PkWwuME5GqqrpHRG4AglT1zxT6/3JW1F8iqWf4B1AmoXxnyH2Tqm5Po37ngaJppP8BBIhIY2eIXdRpQ3HgsKrGi8gQwP1segb4+Pjwr5fH8NQ9fYmLiyO87yAqV6vBZ++9Tmit+rTq0I1xo4dz6eLfvPj43QCUCwxmzCdTOPDXH4x5+SnyST7iNZ47738i2ep3evrefe9DevboQlxcHEOGDqNmWBgjR7xMg4aNCO/Zi6HD7mHY0MGEhValRImSTJo8FYCaYWH06Xc79evUxMfHh7Hvj/NoMcHHx4dRb46l/609iIuLZ+DgIYTWCGPU/42gXoOGdO3ek0F33c0j9w+lSd0alChRgk+//AYAvxIlePCRJ+jStjkiQofOXenUtbtHOrOznTnRxniFD1bsZfQtNcmfT1i4/Sj7T11iaNPy/HnsAr/sO836A2doVMGPCXfWIz5e+XT1fs79E0vH6qWpE1iMYoUK0KVGWQBGL93NXycuutF6dYhk3qN4ViCqWTOzICIXVPVGl/t5mOHuKpztLiIyFGMUi2OGuN+o6ivOlphFwAagIbADs03oous2HxFpD4wGEsaUL6pqqjgTIvIMJh5FiKrud9LqAe87un2Asar6WcptRCJyM/AZEA30xRja+ao6Q0QaY+YyC2OMY0cgAJiJ6fEuAh5R1Rs93eYTWru+Tpi1POM318tYj+JZQ3a3s/+X67NVH8BPT9y8MYNIgx5Tr0FDXbryfxnKlC1awCu6roQs60G6GkfnvqfLrauROKyqvdMoIlZV70yj3LYur5cDjT2oy1u4LPA4aZuB1hmV79yvIfk84lCXZ+sxc6Gu7AbquNw/78juJ3m7LRaLC7lxH6Q9amixWHIBYv1BpkRVJwIT00jfj+1tWSzXDULu3OZje5AWiyVXYA2kxWKxpEUuXcW2BtJiseQ41h+kxWKxZID1B2mxWCzpkFl/kCLSVUT+EJE9IvLvNJ4XFJFpzvP/OXuTM8QaSIvFkivIjIF0nOKMA7ph9i3fISIp/SDcA5xW1arAu5hDJhliDaTFYskViJt/bmgC7FHVvaoaA0wFbkkhcwvwlfN6BtBB3Izr7RxkLuOP3zefuPmmkgeuImtpjJu47CS7dV4PbcwJnZnRl5YHrSvmt00bFxfxldJuxAo5floTGK+q453XQcAhl2eHgaYp8ifKqGqsiJwFSpFB262BzGWoahn3UqkRkQ3ZfU41u3VeD23MCZ050caUqGpX91LZjx1iWyyWa4EIoLzLfbCTlqaMmHAqxYEMfblZA2mxWK4F1gPVRCTE8fY/AEjp2WsuxrE2GM9cy9WNOzM7xL52GO9eJM/rvB7amBM6c6KNXsWZU3wUWIzxwTpBVbeLiUK6wXGD+AUwSUT2YAIJDnBXbpb5g7RYLJa8jh1iWywWSzpYA2mxWCzpYA2kxXId426j9PWONZCWK0JE/EWkdjbrzPbPqYg0FpFbnIBuOUJWGy8RKQvMcGK6W9LAGsg8THb/+otIKWA28KCIuD3H6i1UNd7R30tE/LJJbTXgv5iomwXdCWcWESnt7M0j4QfI3RYUL3AGOAd850TltKTAGsg8iohIwhdIRLqJSCMRCctitUWBtar6CPC3iPR0lyEziEiDBB1OT+5psvgzm9BbVdUpwFLgP0CvbPgxagF8ISL/Ap4TkeJZrA/nzPIDwB7ge2skU2MNZB7FxTj+C9PT6QO8KCIpD+hnGhEp4ujcD1wWkVGYaJJZ9iV2vLPUBJ4SkXBVvQwUAnyycsjt0lt9FKiBObv7DsZIen3fsIjUFZF8zj69asAI4DVVPZtVw3tXY6+qMar6KCYapzWSKbAGMo8hIhVE5EbndTugi6q2BHyBCkB/EentRX3VgbdEpDyAqj4LLAE+U9VvvKUnhU5R1ThgHmYT84NOm34CTgMFHLks+TKLSBXgbuBJVR0IPIf5EbrVMdzeZBQwT0QKAQswpz3eFBE/50fBqySMPESki4g8KiJPA6jqQxgjOd3OSbqgqvbKIxcQADwLFMN4qC8PhGC+zMuBQMxpgV+A27ygrwawFhjm3OdLQyZVWiZ1isvrCoAfcAewGojHuKlaAUwDpgC+3tTp3PsC3wItgQJO2gjgAtDJS+2snqAX80MwAcjv3H8KLHZet/PG3zKF7h7AFqAtsA/4yuXZRMwPUf7s+Ezn9sv2IPMQqhoFfARUAh4DzqjqPuf+VVWNBA5iPuBrM6PLmQObA/ymqhMShrwicrOLTD51hqTeQhMslsiTmC+rAIuADzHHyFYAvYGHgP+omUe7alLM5VYSkSCnzEMY4xTsiP6GeV93Zkafo6ck8AjG1Raq2hMoB0xzhr8PAREish3j2HVbZnW66C4B3Is5ZlcM086GIjLPqctQ4DE1PfjrHnvUMA/g+iV27ocCzYGNwNcYY/kU8B7Ga3Jnx3BmRmcxzMH+psAkYBgQg3FM+rOq3p+Z8t3ovhWzONJHVQ85aX5AF0xb31DVBV7Q42ocn8K8d3uBnzHeqT/G+CsoAIQ69dmTSZ3hQEPM3y0AY6ieVtXLIrIAuKiq/RzZbsAOVb0a/6CuOhOG1SVV9ZSIlMMY528wn6OiwDFguqr2z4yua46c7sLay/MLqOLyuiemN3mPcz8UeAkIy6SOYJxhM1ASx0098KGTdgOmR/NYFrbzdsz8H8CNLumlgX5AeS/ra4oxFiEYQ7gReN55Vh8Y7PreZ0JPOGZo29u5D8T0jl/FmSrA9NqXerFtCZ2gHpipl7LOfRhmOsYXYyRHAR2y43Ocl64cr4C9MvjjuMzvAY9jJtHHA486aQlG8lGgsBf03YgZos8iae6tRMovjlOXIV5qo6SRNgDYkaL9d2LmzFLJZ0Y3UBfYSvI5wIrAOuA9L+ryxwzRGzv3RZz/mwHLMAtBBZ20qUCwF3Xf7PyotXdJCwUmA58AR4G26f09rufLzkHmYjRpy0lHzJe2N/ADECYiz6nqPMziTCXAW5uZf8MYjckiUlBVTwMrEx6KSFPgPowhzTSa8K0UGSQiL4nIw8BCzCLMehFpIiIPYVaRjyTIXy0ptrioqm4BPgCqAk1FpICaIW1/oI6IlPPSHsho4DLwj7Ni/ZyI/IRZdFPMj93/iYiPqg5Q1cNXq0hEAkTkZpd6+wMTVXV5wqZ3Vd0FvI5Z6LpNVVc46XbOzQVrIHMxIpJfRCpjttUUVdXtmN7GDKCSiIxQ1RnACFU9k1l9qnoBmA70wnxpvxATGrOuU58WmB7HC6r609XqSWlwROQRzNziOczq7iLgM4yRfADoiJn/23W1OhNwMch9ReR+Eamrqp9helMjSDKS+zAr1ke9ZDTOYBaZ3sJszK7k6HwH2Ax8hxlyl/SCrg4YT9k3OAaxIHC3iBRV1WhI3CJ2o6quVNU1XtB5bZLTXVh7Jb9Ie8jZB/gHZ6gLFMaEt3wXKOVl/c9iVsTB9E7jgSec+zpA3fTqeQU6Cqa4/xRn6OncvwB87nJfwAvtKuLy+klgFTAcM+x9wEm/F/gf0DyL/rY3Yub7bnd9DzCR9rp5oXzXKYnSwJeYnmkB4DXMj18I0BqzGt85K9p5LV22B5mLSLGq2kdEhjsruvMxw+vZItJZVS9hvtj/VdUMY2pcBd8BZ53XZTDzcy2dum1VMyQloZ5Xioh0BqY6bevjoqe7i9h8wHUonKkN0yLSA3hdRIKcKYLmqtoK+BtzGqihiDygqp9jVq9TxjLxCqp6QVV/VdXvNKkn1w+ohZlfvmpEpLBTDiKScMppN8ZAdgI+B/7CbJ0aATyrqksyo/O6IKcttL1SX5hFl9+AlzG9gPFAWcwqaDzQLgt1+zm6L+CsVGPmBBt6oeyumB7aI8ArmC+tH+aL/QdJK9eDML3X4l7QmXLluDAm/GcPzJ5KH4zB+B2nJ5lNf+MATE92O1DLC+WVd97TT4BIoKqT/ozz+ens3BfATNeAXZBx/77mdAXspWDO4CZsvyiAmX+r5vLseeA5574fUD2L6pGwitsVuNMlPdNfJMzcWjzQ07kPxgwtb3buwzArrV86xipT25WcMlOuHBfGzMcFO4bjBSd9WMKPUDb+zQs7RrqqF8pK2MrzIGYe921cpiUwe2SnOvrsCZkruOxG8RzEWazwxcwN7cM4KTgmIjOAw6r6pCPXA7Ny3FdVY72hV1VVREIxwYt81WXVNMVQP7966VSF044xmCHuOWdjdHFgE6ZnuR64BFxS1asNZO+qrwRmoedpzHDz35jjg7EYg90IM+RsDYSrFxaBcgpn6qId8Cdm69BWYKGq7hXjZOMJYImqeu1UzvWANZA5SMJRPTFhKmdhhravYbzYDAN2q+p7zjzkEGCwqp7PpM4E4xiO2Vi+1NH3sqr+npmyPdTfDXgfs1JdlaTpg/sw7X9aVc95SZdgek+dMT3UHzFnundi5jwjgIvAas3kCZmcRIz/yCcxkfzWOMZyMGYKQTCu1B5Xs0vBcgVYA5kDpHF08A7M5ui2mKHQGMx2l2cwq9flgUGqujUTOhPPTYtICKZnFY5Zue2CWQQ6q14+W51OXTpiti4FqOrRhPoBJb3Rc0yh60agNuY9nKNJiyNfAXNVdaY39WUnzvn4ApgRSAVML/Fn5wewE2ZxpinmFNT0nKtp3sUayBzA2Wd32XndGbMXrilm4v59zPDoNcxwsxLGKcVVGw4RCcQYwvGqesTZW/kgpjf1b+AuVd0jIq2A39VsDs9SnJ7k25gTHMeyWl8K3f0w7b5dVf/KTt3ewGUUUERVLzpTCR9hpmneSfisiMgNmLnIMyl/lC2eYbf5ZDPOvN/HLpulYzErmdHOMO9uYCBmNdJPVfd4oVcVg+mdPiYmbMJBoAFm/+FtjnFsj1kFvSGTujxCVRdiHFIskmyKOeOcMHkSs2o9JC8aRzBbrESkK2a71BuYxZeHMftUHxYTawZV/VudAwTWOF4d1kBmP7sx525bOV5VdmLmieqIyA3OkPNLzApspoe7ziLLCcwQPgxjlPwwvdbFwL+d/YhjgbGaiSNuV4qqzgFaZ8ew3uEM5v2/JTvmW7MKEWkLvIEZZRQD7nZ6/Q8CbYAnJAeDjV1L2CF2NiEpfCeKyCeYX/yOmH1/nTFHzgRzVOxuNSEOMqMzraHYeIyR+Bwzf/UkZt/cBlVdaIdiuZMUOwtuxywwFcR44emnqgfEuKgrgnF0sSHnanvtYA1kNpDiw90Fc55aMb2AesAtGD+LTTCLM++o6g4v6e6KcVn2O8bd1WrM/sM9wChvrRhbsh5njjgK8xkZjzGSXVT1tLMo0xF4STPpRNiShB1iZwMuxvERjFPbCs7ewn9jNkfPBrar6pvAg140jg0xewAXYU7GPIAZag/F+Dkc7mwxsuQNWmL+nosxxzGPYaJLdsR8rlZa4+hdbA8ym3B+/d8DujqbwRsCRzDzYqOAKphzs+qNOTlnK88yzMr1KJftLk9gXPoXwDie3ZhZXZasIY3tYAmu5v6F6dyMwewljcfMHy+wUyTexRrILCKND3czzDHBwxi3Vt0w8UD+o6qbRaRcwp5Ab+nHzDN2A2qr6kln4n4G5sTOOm/psmQdItIEqKPGkUbC/s1odUJeOD98qOoFaxy9jx1iZwEp5hyDRaQ0xkN1NHATME9VawEHMMfdyKxxTNg2JCbOck/M6ZRHMSvii0WkDuZcd02M41ZL3qAoJjb4aBHpjzmXf9n5e6LGQ9AF57U1jl7G64HQr2cSDKOLcXwcs6fxb8zK8aPqnKV2jg82xThQzazehCOLnTHR//YA92Pmqj7AbOv5FTNvNUhVf8usTkv2oKrLRKQlZiTQGTMHWQgTkuKqT1ZZPMP2IL1L4g+OM+c4FLgNM7dYAeNBOmFl+VGcEyxXq0xEioAJzSAiNTBHE/upandMjJWKGAe3j2AMcSDmvHMqr96W3IXLiMBHVU+p6mRVvQfj6WkvZqrGksVYA+klnG0WX4vIv51VxeOY2NRRqnrRMVoVnU3ZPwN3aCY8qzh73r4UkZLOmdxOmH2VzQFU9XvgPMbJBcBIzFaf2Y68JRfhYhBDnZMwQQAuIw5x7j8DBqjqHPsjl/XYIbYXcHqEIzHxo8tihtWbMJHjapM0FFqOmSq6hDlnfdWocRf2JCa+cZiqvi/GrVULEYnQpIBe9cXEIjkvIo9iQjTYoPC5CJcN/ck8LIlIoocl53nCFM4/CWk5WO3rAmsgM4mIlMREGrxFVeeJSAXM9ovNGFda40VkCmayvSfG/2Bm9N3orFjmV9UoEbkbGCEiAzHHBR/FhBfohTlaOEodF2mOYcxWxxCW9EmYO3aMXwjGg3yCh6VSQITrCSxrELMfayAziaqeclaNx4jIz6p6UEQUqKGqn4nIOYwH63KY+cE/r1aXGEcX40RkH7BfRD5Q1S9FJAbj3OJBpyfpCzQGvlHVuZlupMXriONhSUTGq+oRzBHTFRhnt+GY+enTItJKRLLFw5IlNdZAegFng248sFFEFmPOyE5xns3whg4RqYk5XjYRszG4AcaD9GxVnezMK34oIk9hHFE8ALQWkT9V9Udv1MHiVRI8LBUUkXdI8rA0GKivxi1de+BF4C7AGsgcwG4U9yKS5AjW3zktU9iZb8xsub4Yrz/bVbWXMzn/NCZ06Gvi+JcUkXswK9mNMD3W9sACVY3KbB0s3sOZHolzFmPG45yLx5zFvx1zuiohLO2LdhSQc1gD6WXEOIJ9CxN50GvzfWJCeS4ARqjqRyLyX8xc1RbMOetxmC9afmfI5tV4Mhbv4LIgYz0s5QGsgcwCROQWzK9/I8zculfeZBFphFnhXIGZxH8CE0qgBdAQeFhVMxVf2ZL1iPWwlGewBjKLSFhtzoJy62O274xV1VdcTtGUVi/Hc7F4HzFOSkZhYg/5YfatLsDECJqJOSHzH7VeeXIF1kDmQZwv2ULgDVV910mzw7BcjlgPS3kOe5ImD+J8gXoCI0WkgjWOeYb9wE/A4yJSyhlhbAAKA9VU9Zg1jrkLayDzKKr6PyBIVQ9a45g7sR6W8j52H2Te5jzY4XVuxHpYujawBjIPk2AUrXHMPSRs30nDw9IWx8VdCxwPSyJyArNXNdHDkv1b5i7sENti8RLWw9K1h+1BWixewnpYuvawPUiLJZM423USTi5FYaIPfiMiN2M8LG3AeFj6DOPp6UtXD0vePHFl8S62B2mxZALrYenaxvYgLZarxPGw9DnwLebIoD/GwxKqOhl4E+NhqR3Gw9IKoJXj1MSSB7A9SIvlKnB6hPMwHpY+d/Y8lsQ4KZ7teFj6Wkyo3Y8w5/IXY/Y7bs+peluuDHvU0GK5SqyHpWsfayAtlkxgPSxd21gDabFkEuth6drFzkFaLJlEVX9zFl4Wisi5BA9LwMmcrJcl89gepMXiJUSkKfAjZqHmkD02mPexBtJi8SIiUsx6BL92sPsgLRbvkuhhKacrYsk8tgdpsVgs6WB7kBaLxZIO1kBaLBZLOlgDabFYLOlgDaQlSxCROBHZLCK/i8h0ESmSibImikhf5/XnjpOI9GTbikiLq9CxX0RKe5qeQuaKwvuKyAgReeZK62jJfqyBtGQVl1S1nqrWAmKAB10fOo5krxhVvVdVd2Qg0hZzzM9iyTTWQFqyg1VAVad3t0pE5gI7RCS/iLwpIutFZKuIPABmi4yIfCgif4jIj5hogDjPVjjnnxGRriKySUS2iMgyEamEMcT/cnqvrUSkjIjMdHSsd5zYIiKlRGSJiGwXkc8Bt9tyRGS2iGx08tyf4tm7TvoyESnjpFURkUVOnlWO70hLHsIeNbRkKU5PsRuwyElqANRS1X2OkTmrqo1FpCCwRkSWAPWB6phwqOWAHcCEFOWWAT4DWjtllVTVUyLyCXBBVd9y5KYA76rqahGpgHE5VgMYDqxW1ZEi0gO4x4PmDHN0FAbWi8hMVT0J3ABsUNV/icjLTtmPAuMxDnN3O6dsPsIE6bLkEayBtGQVhUVks/N6FfAFZui7TlX3OemdgToJ84tAcUyc6NbAt45bsEgRWZ5G+c2AlQllqeqpdOrREajpsm+7mBMioTVwm5N3gYic9qBNj4uJTAjGY081zHnreGCak/4NMMvR0QKY7qK7oAc6LLkIayAtWcUlVa3nmuAYir9dk4DHVHVxCrnuXqxHPqCZqv6TRl08RkTaYoxtc1W9KCIrgELpiKuj90zK98CSt7BzkJacZDHwkON1GxG5SURuAFYC/Z05ygCcMAYpWAu0FpEQJ29JJ/08UNRFbgnwWMKNiNRzXq4EBjpp3YASbupaHDjtGMdQTA82gXxAQi94IGbofg7YJyL9HB0iInXd6LDkMqyBtOQkn2PmFzeJyO/Ap5hRzffAbufZ18CvKTOq6nHgfsxwdgtJQ9x5wK0JizTA40AjZxFoB0mr6a9gDOx2zFD7oJu6LgJ8RGQnMApjoBP4G2jitKE9Jt41wCDgHqd+24FbPHhPLLkIexbbYrFY0sH2IC0WiyUdrIG0WCyWdLAG0mKxWNLBGkiLxWJJB2sgLRaLJR2sgbRYLJZ0sAbSYrFY0uH/AYuoLewEcCe9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A9S3-YFQujV",
        "outputId": "e8de1a7d-c746-462f-9a01-d8fe430c4331"
      },
      "source": [
        "#-------------------NEURAL NETWORK WITH SCIKIT LEARN AND TENSORFLOW---------------------\n",
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#Fonction de construction du CNN\n",
        "def build_classifier(optimizer='adam'):\n",
        "    # Initialising the CNN\n",
        "    classifier = Sequential()\n",
        "\n",
        "    # Step 4 - Full connection\n",
        "    classifier.add(Dense(units = 128, activation = 'relu',input_dim = 40000))\n",
        "    classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "    #classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "    classifier.add(Dense(units = 6, activation = 'softmax'))\n",
        "\n",
        "    # Compiling the CNN\n",
        "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "#Instance du classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "\n",
        "#Liste de paramétres à tester lors de l'entraînement.\n",
        "parameters = {'batch_size': [50],\n",
        "              'epochs': [150],\n",
        "              'optimizer': ['adam']}\n",
        "#Création de la grille d'entraînement.\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5)\n",
        "#On entraîne avec les différents paramètres spécipfiés dans la liste.\n",
        "grid_search = grid_search.fit(X_train, y_train,verbose=0)\n",
        "#On évalue le score et les meilleurs paramétres\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "print(best_accuracy,best_parameters)\n",
        "score = grid_search.score(X_test, y_test)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5cb5ac7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5cb516f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5cb5033268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5cb4f2aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5cb4e55950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.4333333333333334 {'batch_size': 50, 'epochs': 150, 'optimizer': 'adam'}\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5cb4c9c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.43333333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oF8DvhuQujV",
        "outputId": "326bb09a-1bff-4c70-a37d-cb11f1d5232a"
      },
      "source": [
        "#-------------------------------LEARNING CURVE FOR NEURAL NETWORK ONLY-----------------------------------------------#\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def fit_model(trainX, trainy, testX, testy, lrate):\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(120, input_dim=40000, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(6, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=lrate)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0)\n",
        "\t# plot learning curves\n",
        "\tpyplot.plot(history.history['accuracy'], label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], label='test')\n",
        "\tpyplot.title('lrate='+str(lrate), pad=-50)\n",
        "\n",
        "# create learning curves for different learning rates\n",
        "learning_rates = [1E-6, 1E-7,1E-8,1E-9]\n",
        "for i in range(len(learning_rates)):\n",
        "\t# determine the plot number\n",
        "\tplot_no = 420 + (i+1)\n",
        "\tpyplot.subplot(plot_no)\n",
        "\t# fit model and plot learning curves for a learning rate\n",
        "\tfit_model(X_train, y_train, X_test, y_test, learning_rates[i])\n",
        "# show learning curves\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.9770 - accuracy: 0.2000 - val_loss: 1.9352 - val_accuracy: 0.2778\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.7927 - accuracy: 0.3111 - val_loss: 1.8414 - val_accuracy: 0.3556\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7048 - accuracy: 0.3556 - val_loss: 1.8220 - val_accuracy: 0.3778\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6538 - accuracy: 0.3704 - val_loss: 1.8104 - val_accuracy: 0.3889\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6041 - accuracy: 0.4074 - val_loss: 1.8030 - val_accuracy: 0.3889\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5546 - accuracy: 0.4296 - val_loss: 1.8055 - val_accuracy: 0.3889\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5114 - accuracy: 0.4444 - val_loss: 1.8063 - val_accuracy: 0.3889\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.4690 - accuracy: 0.4481 - val_loss: 1.8036 - val_accuracy: 0.3889\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4272 - accuracy: 0.4556 - val_loss: 1.7963 - val_accuracy: 0.3889\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3899 - accuracy: 0.4889 - val_loss: 1.7932 - val_accuracy: 0.3889\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3533 - accuracy: 0.5000 - val_loss: 1.7919 - val_accuracy: 0.4000\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3157 - accuracy: 0.5074 - val_loss: 1.7904 - val_accuracy: 0.4000\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2802 - accuracy: 0.5222 - val_loss: 1.7890 - val_accuracy: 0.4000\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2458 - accuracy: 0.5370 - val_loss: 1.7841 - val_accuracy: 0.4000\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2150 - accuracy: 0.5630 - val_loss: 1.7803 - val_accuracy: 0.4000\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1819 - accuracy: 0.5741 - val_loss: 1.7776 - val_accuracy: 0.4000\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1528 - accuracy: 0.5889 - val_loss: 1.7750 - val_accuracy: 0.3889\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1229 - accuracy: 0.6037 - val_loss: 1.7735 - val_accuracy: 0.3889\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0949 - accuracy: 0.6296 - val_loss: 1.7779 - val_accuracy: 0.3889\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0675 - accuracy: 0.6296 - val_loss: 1.7730 - val_accuracy: 0.3889\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0401 - accuracy: 0.6407 - val_loss: 1.7737 - val_accuracy: 0.3889\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0131 - accuracy: 0.6556 - val_loss: 1.7686 - val_accuracy: 0.3778\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9884 - accuracy: 0.6704 - val_loss: 1.7649 - val_accuracy: 0.3778\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9639 - accuracy: 0.6889 - val_loss: 1.7608 - val_accuracy: 0.3778\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9401 - accuracy: 0.6926 - val_loss: 1.7613 - val_accuracy: 0.3778\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9186 - accuracy: 0.7111 - val_loss: 1.7566 - val_accuracy: 0.3778\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8941 - accuracy: 0.7222 - val_loss: 1.7560 - val_accuracy: 0.3778\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8728 - accuracy: 0.7370 - val_loss: 1.7549 - val_accuracy: 0.3889\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8516 - accuracy: 0.7630 - val_loss: 1.7545 - val_accuracy: 0.3778\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8317 - accuracy: 0.7852 - val_loss: 1.7546 - val_accuracy: 0.3889\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8116 - accuracy: 0.7926 - val_loss: 1.7505 - val_accuracy: 0.3778\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7933 - accuracy: 0.8111 - val_loss: 1.7509 - val_accuracy: 0.3889\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7752 - accuracy: 0.8148 - val_loss: 1.7492 - val_accuracy: 0.3889\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.7567 - accuracy: 0.8296 - val_loss: 1.7444 - val_accuracy: 0.3889\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7402 - accuracy: 0.8481 - val_loss: 1.7432 - val_accuracy: 0.3889\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7248 - accuracy: 0.8519 - val_loss: 1.7423 - val_accuracy: 0.4000\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7072 - accuracy: 0.8556 - val_loss: 1.7363 - val_accuracy: 0.3889\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6916 - accuracy: 0.8741 - val_loss: 1.7351 - val_accuracy: 0.3889\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6776 - accuracy: 0.8704 - val_loss: 1.7343 - val_accuracy: 0.4000\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.8852 - val_loss: 1.7301 - val_accuracy: 0.3889\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6495 - accuracy: 0.8926 - val_loss: 1.7326 - val_accuracy: 0.4000\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6354 - accuracy: 0.8963 - val_loss: 1.7360 - val_accuracy: 0.4000\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6215 - accuracy: 0.9037 - val_loss: 1.7352 - val_accuracy: 0.4000\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6087 - accuracy: 0.9074 - val_loss: 1.7315 - val_accuracy: 0.4000\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5963 - accuracy: 0.9111 - val_loss: 1.7279 - val_accuracy: 0.4000\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5844 - accuracy: 0.9185 - val_loss: 1.7270 - val_accuracy: 0.4000\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5728 - accuracy: 0.9185 - val_loss: 1.7245 - val_accuracy: 0.4000\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5612 - accuracy: 0.9222 - val_loss: 1.7265 - val_accuracy: 0.3889\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5510 - accuracy: 0.9222 - val_loss: 1.7263 - val_accuracy: 0.3889\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5392 - accuracy: 0.9259 - val_loss: 1.7291 - val_accuracy: 0.4000\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.9333 - val_loss: 1.7276 - val_accuracy: 0.4000\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5199 - accuracy: 0.9407 - val_loss: 1.7289 - val_accuracy: 0.4000\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5091 - accuracy: 0.9444 - val_loss: 1.7199 - val_accuracy: 0.4000\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5004 - accuracy: 0.9481 - val_loss: 1.7168 - val_accuracy: 0.4111\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4905 - accuracy: 0.9481 - val_loss: 1.7213 - val_accuracy: 0.4000\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4818 - accuracy: 0.9481 - val_loss: 1.7259 - val_accuracy: 0.4000\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.9481 - val_loss: 1.7273 - val_accuracy: 0.4111\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4653 - accuracy: 0.9519 - val_loss: 1.7278 - val_accuracy: 0.4000\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.9556 - val_loss: 1.7247 - val_accuracy: 0.4222\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4487 - accuracy: 0.9556 - val_loss: 1.7208 - val_accuracy: 0.4000\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4410 - accuracy: 0.9556 - val_loss: 1.7190 - val_accuracy: 0.4111\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.9556 - val_loss: 1.7192 - val_accuracy: 0.4111\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.9556 - val_loss: 1.7228 - val_accuracy: 0.4222\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4181 - accuracy: 0.9593 - val_loss: 1.7245 - val_accuracy: 0.4222\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.9593 - val_loss: 1.7282 - val_accuracy: 0.4222\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4041 - accuracy: 0.9593 - val_loss: 1.7255 - val_accuracy: 0.4222\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3978 - accuracy: 0.9593 - val_loss: 1.7260 - val_accuracy: 0.4222\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.9593 - val_loss: 1.7294 - val_accuracy: 0.4333\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3847 - accuracy: 0.9593 - val_loss: 1.7229 - val_accuracy: 0.4333\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3777 - accuracy: 0.9667 - val_loss: 1.7171 - val_accuracy: 0.4222\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3717 - accuracy: 0.9667 - val_loss: 1.7192 - val_accuracy: 0.4111\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3661 - accuracy: 0.9630 - val_loss: 1.7226 - val_accuracy: 0.4333\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.9630 - val_loss: 1.7227 - val_accuracy: 0.4333\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3552 - accuracy: 0.9630 - val_loss: 1.7248 - val_accuracy: 0.4333\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3482 - accuracy: 0.9667 - val_loss: 1.7223 - val_accuracy: 0.4333\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3437 - accuracy: 0.9704 - val_loss: 1.7224 - val_accuracy: 0.4333\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.9704 - val_loss: 1.7231 - val_accuracy: 0.4333\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3331 - accuracy: 0.9704 - val_loss: 1.7275 - val_accuracy: 0.4222\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3278 - accuracy: 0.9704 - val_loss: 1.7188 - val_accuracy: 0.4444\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3229 - accuracy: 0.9704 - val_loss: 1.7212 - val_accuracy: 0.4333\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3181 - accuracy: 0.9741 - val_loss: 1.7240 - val_accuracy: 0.4222\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3130 - accuracy: 0.9741 - val_loss: 1.7274 - val_accuracy: 0.4333\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3087 - accuracy: 0.9741 - val_loss: 1.7299 - val_accuracy: 0.4333\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3039 - accuracy: 0.9741 - val_loss: 1.7258 - val_accuracy: 0.4333\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2996 - accuracy: 0.9741 - val_loss: 1.7241 - val_accuracy: 0.4333\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2951 - accuracy: 0.9741 - val_loss: 1.7246 - val_accuracy: 0.4333\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2905 - accuracy: 0.9741 - val_loss: 1.7269 - val_accuracy: 0.4333\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2861 - accuracy: 0.9741 - val_loss: 1.7311 - val_accuracy: 0.4333\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2827 - accuracy: 0.9704 - val_loss: 1.7296 - val_accuracy: 0.4333\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2779 - accuracy: 0.9778 - val_loss: 1.7303 - val_accuracy: 0.4222\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2742 - accuracy: 0.9889 - val_loss: 1.7273 - val_accuracy: 0.4333\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2704 - accuracy: 0.9889 - val_loss: 1.7327 - val_accuracy: 0.4333\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2664 - accuracy: 0.9852 - val_loss: 1.7350 - val_accuracy: 0.4222\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2628 - accuracy: 0.9852 - val_loss: 1.7299 - val_accuracy: 0.4222\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2593 - accuracy: 0.9852 - val_loss: 1.7266 - val_accuracy: 0.4333\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2553 - accuracy: 0.9889 - val_loss: 1.7346 - val_accuracy: 0.4333\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2521 - accuracy: 0.9852 - val_loss: 1.7405 - val_accuracy: 0.4333\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2491 - accuracy: 0.9852 - val_loss: 1.7381 - val_accuracy: 0.4333\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2452 - accuracy: 0.9889 - val_loss: 1.7307 - val_accuracy: 0.4444\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2421 - accuracy: 0.9889 - val_loss: 1.7316 - val_accuracy: 0.4333\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2384 - accuracy: 0.9852 - val_loss: 1.7322 - val_accuracy: 0.4333\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2358 - accuracy: 0.9889 - val_loss: 1.7308 - val_accuracy: 0.4333\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2325 - accuracy: 0.9889 - val_loss: 1.7309 - val_accuracy: 0.4333\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2290 - accuracy: 0.9889 - val_loss: 1.7370 - val_accuracy: 0.4333\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.9889 - val_loss: 1.7386 - val_accuracy: 0.4333\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2231 - accuracy: 0.9889 - val_loss: 1.7424 - val_accuracy: 0.4333\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2202 - accuracy: 0.9889 - val_loss: 1.7445 - val_accuracy: 0.4333\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2176 - accuracy: 0.9889 - val_loss: 1.7417 - val_accuracy: 0.4333\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2147 - accuracy: 0.9889 - val_loss: 1.7407 - val_accuracy: 0.4333\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2126 - accuracy: 0.9889 - val_loss: 1.7352 - val_accuracy: 0.4333\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2093 - accuracy: 0.9926 - val_loss: 1.7355 - val_accuracy: 0.4333\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2071 - accuracy: 0.9926 - val_loss: 1.7393 - val_accuracy: 0.4222\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2046 - accuracy: 0.9889 - val_loss: 1.7367 - val_accuracy: 0.4333\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2016 - accuracy: 0.9926 - val_loss: 1.7440 - val_accuracy: 0.4333\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1993 - accuracy: 0.9889 - val_loss: 1.7485 - val_accuracy: 0.4333\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 0.9926 - val_loss: 1.7471 - val_accuracy: 0.4333\n",
            "Epoch 117/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1941 - accuracy: 0.9926 - val_loss: 1.7482 - val_accuracy: 0.4333\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1920 - accuracy: 0.9926 - val_loss: 1.7473 - val_accuracy: 0.4222\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1901 - accuracy: 0.9926 - val_loss: 1.7499 - val_accuracy: 0.4333\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1873 - accuracy: 0.9926 - val_loss: 1.7468 - val_accuracy: 0.4333\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9926 - val_loss: 1.7498 - val_accuracy: 0.4222\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1830 - accuracy: 0.9926 - val_loss: 1.7551 - val_accuracy: 0.4222\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1805 - accuracy: 0.9926 - val_loss: 1.7527 - val_accuracy: 0.4333\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 0.9926 - val_loss: 1.7464 - val_accuracy: 0.4222\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1764 - accuracy: 0.9926 - val_loss: 1.7492 - val_accuracy: 0.4222\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1746 - accuracy: 0.9926 - val_loss: 1.7574 - val_accuracy: 0.4222\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.9926 - val_loss: 1.7583 - val_accuracy: 0.4222\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1704 - accuracy: 0.9926 - val_loss: 1.7533 - val_accuracy: 0.4222\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1684 - accuracy: 0.9926 - val_loss: 1.7551 - val_accuracy: 0.4222\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1665 - accuracy: 0.9926 - val_loss: 1.7579 - val_accuracy: 0.4222\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1645 - accuracy: 0.9963 - val_loss: 1.7581 - val_accuracy: 0.4222\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1627 - accuracy: 0.9926 - val_loss: 1.7582 - val_accuracy: 0.4222\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1608 - accuracy: 0.9926 - val_loss: 1.7634 - val_accuracy: 0.4222\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9963 - val_loss: 1.7617 - val_accuracy: 0.4222\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1575 - accuracy: 0.9963 - val_loss: 1.7630 - val_accuracy: 0.4222\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1557 - accuracy: 0.9963 - val_loss: 1.7618 - val_accuracy: 0.4222\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1537 - accuracy: 0.9963 - val_loss: 1.7629 - val_accuracy: 0.4222\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.9963 - val_loss: 1.7607 - val_accuracy: 0.4222\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.9963 - val_loss: 1.7722 - val_accuracy: 0.4222\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.9963 - val_loss: 1.7681 - val_accuracy: 0.4222\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.9963 - val_loss: 1.7660 - val_accuracy: 0.4222\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1457 - accuracy: 0.9963 - val_loss: 1.7691 - val_accuracy: 0.4222\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1439 - accuracy: 0.9963 - val_loss: 1.7683 - val_accuracy: 0.4222\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1424 - accuracy: 0.9963 - val_loss: 1.7708 - val_accuracy: 0.4222\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1411 - accuracy: 0.9963 - val_loss: 1.7692 - val_accuracy: 0.4222\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.9963 - val_loss: 1.7665 - val_accuracy: 0.4222\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1381 - accuracy: 1.0000 - val_loss: 1.7696 - val_accuracy: 0.4222\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 1.0000 - val_loss: 1.7692 - val_accuracy: 0.4222\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 1.0000 - val_loss: 1.7737 - val_accuracy: 0.4222\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1338 - accuracy: 1.0000 - val_loss: 1.7691 - val_accuracy: 0.4222\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 1.7727 - val_accuracy: 0.4222\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 1.0000 - val_loss: 1.7813 - val_accuracy: 0.4222\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1295 - accuracy: 1.0000 - val_loss: 1.7803 - val_accuracy: 0.4222\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 1.7779 - val_accuracy: 0.4222\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1270 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.4222\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1256 - accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.4222\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 1.7819 - val_accuracy: 0.4222\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.4222\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 1.7843 - val_accuracy: 0.4222\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.4222\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 1.7844 - val_accuracy: 0.4222\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 1.7829 - val_accuracy: 0.4222\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1169 - accuracy: 1.0000 - val_loss: 1.7889 - val_accuracy: 0.4222\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 1.7936 - val_accuracy: 0.4222\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 1.7989 - val_accuracy: 0.4222\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 1.7960 - val_accuracy: 0.4222\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 1.7949 - val_accuracy: 0.4222\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1111 - accuracy: 1.0000 - val_loss: 1.7925 - val_accuracy: 0.4222\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 1.7945 - val_accuracy: 0.4222\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 1.7997 - val_accuracy: 0.4222\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.4222\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 1.8050 - val_accuracy: 0.4222\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.4222\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 1.8046 - val_accuracy: 0.4222\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 1.7985 - val_accuracy: 0.4222\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.8031 - val_accuracy: 0.4222\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 1.8052 - val_accuracy: 0.4222\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 1.8043 - val_accuracy: 0.4222\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 1.7977 - val_accuracy: 0.4222\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 1.8026 - val_accuracy: 0.4222\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 1.8053 - val_accuracy: 0.4222\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.8095 - val_accuracy: 0.4222\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.4222\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.4222\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 1.8149 - val_accuracy: 0.4222\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.8176 - val_accuracy: 0.4222\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 1.8121 - val_accuracy: 0.4222\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 1.8177 - val_accuracy: 0.4222\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.8226 - val_accuracy: 0.4222\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 1.8183 - val_accuracy: 0.4222\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.8182 - val_accuracy: 0.4222\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.8216 - val_accuracy: 0.4222\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.8244 - val_accuracy: 0.4222\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 1.8264 - val_accuracy: 0.4222\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.4222\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 1.8272 - val_accuracy: 0.4222\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 1.8231 - val_accuracy: 0.4222\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 1.8238 - val_accuracy: 0.4222\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.4222\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 1.8329 - val_accuracy: 0.4222\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 2.5479 - accuracy: 0.1148 - val_loss: 2.6850 - val_accuracy: 0.1556\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5023 - accuracy: 0.1185 - val_loss: 2.6361 - val_accuracy: 0.1556\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4608 - accuracy: 0.1259 - val_loss: 2.5901 - val_accuracy: 0.1556\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4203 - accuracy: 0.1259 - val_loss: 2.5475 - val_accuracy: 0.1556\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3839 - accuracy: 0.1333 - val_loss: 2.5075 - val_accuracy: 0.1556\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3481 - accuracy: 0.1370 - val_loss: 2.4712 - val_accuracy: 0.1556\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3171 - accuracy: 0.1481 - val_loss: 2.4347 - val_accuracy: 0.1556\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2849 - accuracy: 0.1519 - val_loss: 2.4014 - val_accuracy: 0.1556\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2559 - accuracy: 0.1593 - val_loss: 2.3695 - val_accuracy: 0.1556\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2268 - accuracy: 0.1741 - val_loss: 2.3401 - val_accuracy: 0.2000\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2012 - accuracy: 0.1815 - val_loss: 2.3120 - val_accuracy: 0.2000\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1766 - accuracy: 0.2000 - val_loss: 2.2862 - val_accuracy: 0.2111\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1530 - accuracy: 0.2148 - val_loss: 2.2621 - val_accuracy: 0.2556\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1315 - accuracy: 0.2222 - val_loss: 2.2378 - val_accuracy: 0.2556\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1104 - accuracy: 0.2296 - val_loss: 2.2148 - val_accuracy: 0.3000\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0895 - accuracy: 0.2407 - val_loss: 2.1939 - val_accuracy: 0.3111\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0712 - accuracy: 0.2370 - val_loss: 2.1747 - val_accuracy: 0.3111\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0530 - accuracy: 0.2481 - val_loss: 2.1563 - val_accuracy: 0.3111\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0359 - accuracy: 0.2667 - val_loss: 2.1388 - val_accuracy: 0.3000\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0199 - accuracy: 0.2704 - val_loss: 2.1224 - val_accuracy: 0.3000\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0039 - accuracy: 0.2778 - val_loss: 2.1076 - val_accuracy: 0.3000\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9892 - accuracy: 0.2852 - val_loss: 2.0929 - val_accuracy: 0.3000\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9747 - accuracy: 0.2926 - val_loss: 2.0785 - val_accuracy: 0.3000\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9613 - accuracy: 0.2926 - val_loss: 2.0649 - val_accuracy: 0.3000\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9479 - accuracy: 0.2926 - val_loss: 2.0523 - val_accuracy: 0.3000\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9349 - accuracy: 0.3037 - val_loss: 2.0399 - val_accuracy: 0.3000\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9225 - accuracy: 0.3037 - val_loss: 2.0281 - val_accuracy: 0.3000\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9105 - accuracy: 0.3037 - val_loss: 2.0172 - val_accuracy: 0.3000\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8989 - accuracy: 0.3037 - val_loss: 2.0073 - val_accuracy: 0.3000\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.8878 - accuracy: 0.3074 - val_loss: 1.9965 - val_accuracy: 0.3000\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.8762 - accuracy: 0.3074 - val_loss: 1.9866 - val_accuracy: 0.3111\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.8654 - accuracy: 0.3074 - val_loss: 1.9762 - val_accuracy: 0.3111\n",
            "Epoch 33/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 9ms/step - loss: 1.8545 - accuracy: 0.3111 - val_loss: 1.9662 - val_accuracy: 0.3111\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8439 - accuracy: 0.3148 - val_loss: 1.9576 - val_accuracy: 0.3111\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.8342 - accuracy: 0.3148 - val_loss: 1.9482 - val_accuracy: 0.3111\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8243 - accuracy: 0.3148 - val_loss: 1.9397 - val_accuracy: 0.3111\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8145 - accuracy: 0.3111 - val_loss: 1.9312 - val_accuracy: 0.3111\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8051 - accuracy: 0.3111 - val_loss: 1.9240 - val_accuracy: 0.3111\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7965 - accuracy: 0.3111 - val_loss: 1.9162 - val_accuracy: 0.3111\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7875 - accuracy: 0.3111 - val_loss: 1.9084 - val_accuracy: 0.3111\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7786 - accuracy: 0.3148 - val_loss: 1.9012 - val_accuracy: 0.3111\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7701 - accuracy: 0.3148 - val_loss: 1.8942 - val_accuracy: 0.3000\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7613 - accuracy: 0.3148 - val_loss: 1.8875 - val_accuracy: 0.3000\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7534 - accuracy: 0.3222 - val_loss: 1.8804 - val_accuracy: 0.3000\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7450 - accuracy: 0.3296 - val_loss: 1.8746 - val_accuracy: 0.3000\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7373 - accuracy: 0.3296 - val_loss: 1.8685 - val_accuracy: 0.3000\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7297 - accuracy: 0.3296 - val_loss: 1.8627 - val_accuracy: 0.3000\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7226 - accuracy: 0.3370 - val_loss: 1.8570 - val_accuracy: 0.3000\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7153 - accuracy: 0.3370 - val_loss: 1.8512 - val_accuracy: 0.3111\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7083 - accuracy: 0.3407 - val_loss: 1.8463 - val_accuracy: 0.3111\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7014 - accuracy: 0.3407 - val_loss: 1.8416 - val_accuracy: 0.3111\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6945 - accuracy: 0.3407 - val_loss: 1.8374 - val_accuracy: 0.3222\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6880 - accuracy: 0.3444 - val_loss: 1.8327 - val_accuracy: 0.3222\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6815 - accuracy: 0.3481 - val_loss: 1.8279 - val_accuracy: 0.3222\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6750 - accuracy: 0.3519 - val_loss: 1.8244 - val_accuracy: 0.3222\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6688 - accuracy: 0.3481 - val_loss: 1.8207 - val_accuracy: 0.3222\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6632 - accuracy: 0.3481 - val_loss: 1.8171 - val_accuracy: 0.3222\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6575 - accuracy: 0.3519 - val_loss: 1.8128 - val_accuracy: 0.3222\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6513 - accuracy: 0.3519 - val_loss: 1.8103 - val_accuracy: 0.3222\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6455 - accuracy: 0.3556 - val_loss: 1.8073 - val_accuracy: 0.3222\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6400 - accuracy: 0.3556 - val_loss: 1.8049 - val_accuracy: 0.3222\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6349 - accuracy: 0.3556 - val_loss: 1.8021 - val_accuracy: 0.3222\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6293 - accuracy: 0.3556 - val_loss: 1.7989 - val_accuracy: 0.3222\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6241 - accuracy: 0.3556 - val_loss: 1.7954 - val_accuracy: 0.3222\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6186 - accuracy: 0.3519 - val_loss: 1.7932 - val_accuracy: 0.3222\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6137 - accuracy: 0.3556 - val_loss: 1.7906 - val_accuracy: 0.3222\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6084 - accuracy: 0.3630 - val_loss: 1.7877 - val_accuracy: 0.3222\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6033 - accuracy: 0.3667 - val_loss: 1.7857 - val_accuracy: 0.3222\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5981 - accuracy: 0.3704 - val_loss: 1.7837 - val_accuracy: 0.3222\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5934 - accuracy: 0.3778 - val_loss: 1.7812 - val_accuracy: 0.3222\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5882 - accuracy: 0.3778 - val_loss: 1.7788 - val_accuracy: 0.3222\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5837 - accuracy: 0.3815 - val_loss: 1.7772 - val_accuracy: 0.3444\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5790 - accuracy: 0.3815 - val_loss: 1.7752 - val_accuracy: 0.3444\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5743 - accuracy: 0.3815 - val_loss: 1.7737 - val_accuracy: 0.3444\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5696 - accuracy: 0.3815 - val_loss: 1.7716 - val_accuracy: 0.3444\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5650 - accuracy: 0.3815 - val_loss: 1.7702 - val_accuracy: 0.3444\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5605 - accuracy: 0.3815 - val_loss: 1.7690 - val_accuracy: 0.3444\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5559 - accuracy: 0.3852 - val_loss: 1.7669 - val_accuracy: 0.3333\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5514 - accuracy: 0.3852 - val_loss: 1.7650 - val_accuracy: 0.3333\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5470 - accuracy: 0.3889 - val_loss: 1.7637 - val_accuracy: 0.3333\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5426 - accuracy: 0.3889 - val_loss: 1.7625 - val_accuracy: 0.3444\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5379 - accuracy: 0.3852 - val_loss: 1.7610 - val_accuracy: 0.3444\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5337 - accuracy: 0.3852 - val_loss: 1.7600 - val_accuracy: 0.3556\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5293 - accuracy: 0.3852 - val_loss: 1.7586 - val_accuracy: 0.3556\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5249 - accuracy: 0.3852 - val_loss: 1.7574 - val_accuracy: 0.3556\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5206 - accuracy: 0.3852 - val_loss: 1.7564 - val_accuracy: 0.3556\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5162 - accuracy: 0.3852 - val_loss: 1.7552 - val_accuracy: 0.3556\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5122 - accuracy: 0.3852 - val_loss: 1.7537 - val_accuracy: 0.3556\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5080 - accuracy: 0.3852 - val_loss: 1.7523 - val_accuracy: 0.3556\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5037 - accuracy: 0.3852 - val_loss: 1.7511 - val_accuracy: 0.3556\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4994 - accuracy: 0.3889 - val_loss: 1.7503 - val_accuracy: 0.3556\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4953 - accuracy: 0.3889 - val_loss: 1.7498 - val_accuracy: 0.3556\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4914 - accuracy: 0.3889 - val_loss: 1.7482 - val_accuracy: 0.3444\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4870 - accuracy: 0.3926 - val_loss: 1.7474 - val_accuracy: 0.3444\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4830 - accuracy: 0.4000 - val_loss: 1.7472 - val_accuracy: 0.3444\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4790 - accuracy: 0.4037 - val_loss: 1.7466 - val_accuracy: 0.3556\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4749 - accuracy: 0.4074 - val_loss: 1.7452 - val_accuracy: 0.3556\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4711 - accuracy: 0.4074 - val_loss: 1.7440 - val_accuracy: 0.3556\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4670 - accuracy: 0.4074 - val_loss: 1.7431 - val_accuracy: 0.3556\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4632 - accuracy: 0.4074 - val_loss: 1.7419 - val_accuracy: 0.3556\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4593 - accuracy: 0.4074 - val_loss: 1.7410 - val_accuracy: 0.3556\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4553 - accuracy: 0.4111 - val_loss: 1.7404 - val_accuracy: 0.3556\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4516 - accuracy: 0.4111 - val_loss: 1.7395 - val_accuracy: 0.3556\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4477 - accuracy: 0.4111 - val_loss: 1.7394 - val_accuracy: 0.3556\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4439 - accuracy: 0.4185 - val_loss: 1.7386 - val_accuracy: 0.3556\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4401 - accuracy: 0.4185 - val_loss: 1.7386 - val_accuracy: 0.3556\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4362 - accuracy: 0.4222 - val_loss: 1.7375 - val_accuracy: 0.3556\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4324 - accuracy: 0.4222 - val_loss: 1.7365 - val_accuracy: 0.3556\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4285 - accuracy: 0.4259 - val_loss: 1.7356 - val_accuracy: 0.3556\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4246 - accuracy: 0.4296 - val_loss: 1.7345 - val_accuracy: 0.3556\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4208 - accuracy: 0.4296 - val_loss: 1.7341 - val_accuracy: 0.3556\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4170 - accuracy: 0.4296 - val_loss: 1.7337 - val_accuracy: 0.3556\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4132 - accuracy: 0.4296 - val_loss: 1.7326 - val_accuracy: 0.3556\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4094 - accuracy: 0.4333 - val_loss: 1.7322 - val_accuracy: 0.3556\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4055 - accuracy: 0.4370 - val_loss: 1.7313 - val_accuracy: 0.3556\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4020 - accuracy: 0.4370 - val_loss: 1.7301 - val_accuracy: 0.3556\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3981 - accuracy: 0.4370 - val_loss: 1.7297 - val_accuracy: 0.3556\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3948 - accuracy: 0.4407 - val_loss: 1.7288 - val_accuracy: 0.3556\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3906 - accuracy: 0.4444 - val_loss: 1.7280 - val_accuracy: 0.3556\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3872 - accuracy: 0.4481 - val_loss: 1.7273 - val_accuracy: 0.3556\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3836 - accuracy: 0.4519 - val_loss: 1.7266 - val_accuracy: 0.3556\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3798 - accuracy: 0.4519 - val_loss: 1.7260 - val_accuracy: 0.3556\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3763 - accuracy: 0.4519 - val_loss: 1.7251 - val_accuracy: 0.3556\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3727 - accuracy: 0.4556 - val_loss: 1.7244 - val_accuracy: 0.3556\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3691 - accuracy: 0.4593 - val_loss: 1.7239 - val_accuracy: 0.3556\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3656 - accuracy: 0.4593 - val_loss: 1.7235 - val_accuracy: 0.3556\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3620 - accuracy: 0.4630 - val_loss: 1.7228 - val_accuracy: 0.3556\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3587 - accuracy: 0.4630 - val_loss: 1.7223 - val_accuracy: 0.3556\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3550 - accuracy: 0.4630 - val_loss: 1.7215 - val_accuracy: 0.3556\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3516 - accuracy: 0.4630 - val_loss: 1.7211 - val_accuracy: 0.3556\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3481 - accuracy: 0.4667 - val_loss: 1.7209 - val_accuracy: 0.3667\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3445 - accuracy: 0.4741 - val_loss: 1.7203 - val_accuracy: 0.3667\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3410 - accuracy: 0.4704 - val_loss: 1.7195 - val_accuracy: 0.3667\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3378 - accuracy: 0.4704 - val_loss: 1.7192 - val_accuracy: 0.3667\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.4741 - val_loss: 1.7184 - val_accuracy: 0.3667\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3307 - accuracy: 0.4741 - val_loss: 1.7177 - val_accuracy: 0.3667\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3270 - accuracy: 0.4741 - val_loss: 1.7168 - val_accuracy: 0.3667\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3236 - accuracy: 0.4778 - val_loss: 1.7160 - val_accuracy: 0.3667\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3202 - accuracy: 0.4852 - val_loss: 1.7156 - val_accuracy: 0.3667\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3168 - accuracy: 0.4852 - val_loss: 1.7150 - val_accuracy: 0.3667\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3135 - accuracy: 0.4889 - val_loss: 1.7145 - val_accuracy: 0.3667\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3101 - accuracy: 0.4889 - val_loss: 1.7140 - val_accuracy: 0.3667\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3067 - accuracy: 0.4889 - val_loss: 1.7136 - val_accuracy: 0.3667\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3036 - accuracy: 0.4889 - val_loss: 1.7129 - val_accuracy: 0.3667\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3001 - accuracy: 0.4889 - val_loss: 1.7121 - val_accuracy: 0.3667\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2966 - accuracy: 0.4889 - val_loss: 1.7119 - val_accuracy: 0.3667\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2934 - accuracy: 0.4889 - val_loss: 1.7120 - val_accuracy: 0.3667\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2901 - accuracy: 0.4889 - val_loss: 1.7113 - val_accuracy: 0.3667\n",
            "Epoch 149/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2869 - accuracy: 0.4889 - val_loss: 1.7109 - val_accuracy: 0.3667\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2835 - accuracy: 0.4889 - val_loss: 1.7099 - val_accuracy: 0.3667\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2804 - accuracy: 0.4889 - val_loss: 1.7091 - val_accuracy: 0.3667\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2772 - accuracy: 0.4926 - val_loss: 1.7087 - val_accuracy: 0.3667\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2739 - accuracy: 0.4963 - val_loss: 1.7080 - val_accuracy: 0.3667\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2707 - accuracy: 0.5000 - val_loss: 1.7073 - val_accuracy: 0.3667\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2675 - accuracy: 0.5000 - val_loss: 1.7070 - val_accuracy: 0.3667\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2643 - accuracy: 0.5037 - val_loss: 1.7064 - val_accuracy: 0.3667\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2612 - accuracy: 0.5037 - val_loss: 1.7058 - val_accuracy: 0.3667\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2580 - accuracy: 0.5111 - val_loss: 1.7053 - val_accuracy: 0.3667\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2550 - accuracy: 0.5111 - val_loss: 1.7049 - val_accuracy: 0.3667\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2517 - accuracy: 0.5148 - val_loss: 1.7040 - val_accuracy: 0.3667\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2486 - accuracy: 0.5148 - val_loss: 1.7035 - val_accuracy: 0.3667\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2456 - accuracy: 0.5148 - val_loss: 1.7029 - val_accuracy: 0.3778\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2424 - accuracy: 0.5148 - val_loss: 1.7019 - val_accuracy: 0.3778\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2395 - accuracy: 0.5222 - val_loss: 1.7016 - val_accuracy: 0.3778\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2363 - accuracy: 0.5259 - val_loss: 1.7012 - val_accuracy: 0.3778\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2332 - accuracy: 0.5259 - val_loss: 1.7007 - val_accuracy: 0.3778\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2301 - accuracy: 0.5259 - val_loss: 1.7000 - val_accuracy: 0.3778\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2270 - accuracy: 0.5296 - val_loss: 1.6993 - val_accuracy: 0.3778\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2239 - accuracy: 0.5296 - val_loss: 1.6989 - val_accuracy: 0.3778\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2211 - accuracy: 0.5296 - val_loss: 1.6982 - val_accuracy: 0.3778\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2179 - accuracy: 0.5333 - val_loss: 1.6977 - val_accuracy: 0.3778\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2153 - accuracy: 0.5333 - val_loss: 1.6976 - val_accuracy: 0.3778\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2119 - accuracy: 0.5370 - val_loss: 1.6973 - val_accuracy: 0.3778\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2090 - accuracy: 0.5444 - val_loss: 1.6976 - val_accuracy: 0.3778\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2059 - accuracy: 0.5481 - val_loss: 1.6967 - val_accuracy: 0.3778\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2030 - accuracy: 0.5444 - val_loss: 1.6964 - val_accuracy: 0.3778\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2000 - accuracy: 0.5444 - val_loss: 1.6953 - val_accuracy: 0.3778\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1971 - accuracy: 0.5519 - val_loss: 1.6944 - val_accuracy: 0.3778\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1941 - accuracy: 0.5556 - val_loss: 1.6941 - val_accuracy: 0.3778\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1912 - accuracy: 0.5593 - val_loss: 1.6941 - val_accuracy: 0.3778\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1883 - accuracy: 0.5630 - val_loss: 1.6935 - val_accuracy: 0.3778\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1853 - accuracy: 0.5667 - val_loss: 1.6931 - val_accuracy: 0.3778\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1826 - accuracy: 0.5704 - val_loss: 1.6924 - val_accuracy: 0.3778\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1796 - accuracy: 0.5741 - val_loss: 1.6916 - val_accuracy: 0.3778\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1768 - accuracy: 0.5741 - val_loss: 1.6913 - val_accuracy: 0.3778\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1739 - accuracy: 0.5741 - val_loss: 1.6907 - val_accuracy: 0.3778\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1713 - accuracy: 0.5741 - val_loss: 1.6900 - val_accuracy: 0.3778\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1680 - accuracy: 0.5704 - val_loss: 1.6896 - val_accuracy: 0.3778\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1651 - accuracy: 0.5741 - val_loss: 1.6889 - val_accuracy: 0.3778\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1623 - accuracy: 0.5778 - val_loss: 1.6886 - val_accuracy: 0.3778\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1595 - accuracy: 0.5778 - val_loss: 1.6878 - val_accuracy: 0.3778\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1566 - accuracy: 0.5778 - val_loss: 1.6876 - val_accuracy: 0.3778\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1538 - accuracy: 0.5778 - val_loss: 1.6875 - val_accuracy: 0.3778\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1509 - accuracy: 0.5815 - val_loss: 1.6869 - val_accuracy: 0.3778\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1481 - accuracy: 0.5815 - val_loss: 1.6864 - val_accuracy: 0.3778\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1453 - accuracy: 0.5852 - val_loss: 1.6855 - val_accuracy: 0.3778\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1425 - accuracy: 0.5852 - val_loss: 1.6848 - val_accuracy: 0.3778\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1397 - accuracy: 0.5852 - val_loss: 1.6852 - val_accuracy: 0.3778\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1369 - accuracy: 0.5852 - val_loss: 1.6849 - val_accuracy: 0.3778\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1344 - accuracy: 0.5889 - val_loss: 1.6851 - val_accuracy: 0.3778\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 2.5629 - accuracy: 0.1000 - val_loss: 2.7038 - val_accuracy: 0.1111\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5587 - accuracy: 0.1000 - val_loss: 2.6992 - val_accuracy: 0.1111\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5546 - accuracy: 0.1000 - val_loss: 2.6945 - val_accuracy: 0.1111\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5505 - accuracy: 0.1000 - val_loss: 2.6899 - val_accuracy: 0.1111\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5466 - accuracy: 0.1000 - val_loss: 2.6854 - val_accuracy: 0.1111\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5424 - accuracy: 0.1000 - val_loss: 2.6810 - val_accuracy: 0.1111\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5384 - accuracy: 0.1000 - val_loss: 2.6765 - val_accuracy: 0.1111\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5344 - accuracy: 0.1000 - val_loss: 2.6720 - val_accuracy: 0.1111\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5303 - accuracy: 0.1000 - val_loss: 2.6675 - val_accuracy: 0.1111\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5265 - accuracy: 0.1037 - val_loss: 2.6632 - val_accuracy: 0.1111\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5226 - accuracy: 0.1074 - val_loss: 2.6588 - val_accuracy: 0.1111\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5186 - accuracy: 0.1037 - val_loss: 2.6545 - val_accuracy: 0.1111\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5148 - accuracy: 0.1037 - val_loss: 2.6504 - val_accuracy: 0.1111\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5111 - accuracy: 0.1037 - val_loss: 2.6461 - val_accuracy: 0.1111\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5074 - accuracy: 0.1037 - val_loss: 2.6419 - val_accuracy: 0.1111\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5036 - accuracy: 0.1037 - val_loss: 2.6379 - val_accuracy: 0.1111\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5000 - accuracy: 0.1037 - val_loss: 2.6337 - val_accuracy: 0.1111\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4963 - accuracy: 0.1037 - val_loss: 2.6297 - val_accuracy: 0.1111\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4926 - accuracy: 0.1037 - val_loss: 2.6256 - val_accuracy: 0.1111\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4890 - accuracy: 0.1037 - val_loss: 2.6215 - val_accuracy: 0.1111\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4853 - accuracy: 0.1074 - val_loss: 2.6174 - val_accuracy: 0.1111\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4816 - accuracy: 0.1074 - val_loss: 2.6134 - val_accuracy: 0.1111\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4781 - accuracy: 0.1074 - val_loss: 2.6093 - val_accuracy: 0.1111\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4745 - accuracy: 0.1074 - val_loss: 2.6054 - val_accuracy: 0.1111\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4709 - accuracy: 0.1074 - val_loss: 2.6016 - val_accuracy: 0.1111\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4675 - accuracy: 0.1074 - val_loss: 2.5977 - val_accuracy: 0.1111\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4640 - accuracy: 0.1074 - val_loss: 2.5939 - val_accuracy: 0.1111\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4607 - accuracy: 0.1074 - val_loss: 2.5899 - val_accuracy: 0.1111\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4572 - accuracy: 0.1074 - val_loss: 2.5861 - val_accuracy: 0.1111\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4538 - accuracy: 0.1074 - val_loss: 2.5823 - val_accuracy: 0.1111\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4504 - accuracy: 0.1074 - val_loss: 2.5786 - val_accuracy: 0.1111\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4471 - accuracy: 0.1111 - val_loss: 2.5749 - val_accuracy: 0.1111\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4437 - accuracy: 0.1111 - val_loss: 2.5712 - val_accuracy: 0.1111\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4404 - accuracy: 0.1111 - val_loss: 2.5674 - val_accuracy: 0.1111\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4370 - accuracy: 0.1111 - val_loss: 2.5637 - val_accuracy: 0.1111\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4337 - accuracy: 0.1111 - val_loss: 2.5601 - val_accuracy: 0.1111\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4304 - accuracy: 0.1111 - val_loss: 2.5564 - val_accuracy: 0.1111\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4271 - accuracy: 0.1111 - val_loss: 2.5527 - val_accuracy: 0.1111\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4239 - accuracy: 0.1111 - val_loss: 2.5491 - val_accuracy: 0.1111\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4207 - accuracy: 0.1148 - val_loss: 2.5457 - val_accuracy: 0.1111\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4176 - accuracy: 0.1148 - val_loss: 2.5423 - val_accuracy: 0.1111\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4144 - accuracy: 0.1148 - val_loss: 2.5389 - val_accuracy: 0.1111\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4115 - accuracy: 0.1148 - val_loss: 2.5354 - val_accuracy: 0.1111\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4083 - accuracy: 0.1148 - val_loss: 2.5321 - val_accuracy: 0.1111\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4053 - accuracy: 0.1148 - val_loss: 2.5287 - val_accuracy: 0.1111\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4023 - accuracy: 0.1148 - val_loss: 2.5254 - val_accuracy: 0.1111\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3994 - accuracy: 0.1185 - val_loss: 2.5222 - val_accuracy: 0.1111\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3964 - accuracy: 0.1222 - val_loss: 2.5191 - val_accuracy: 0.1111\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3936 - accuracy: 0.1222 - val_loss: 2.5158 - val_accuracy: 0.1222\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3906 - accuracy: 0.1259 - val_loss: 2.5126 - val_accuracy: 0.1222\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3877 - accuracy: 0.1296 - val_loss: 2.5095 - val_accuracy: 0.1333\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3848 - accuracy: 0.1296 - val_loss: 2.5064 - val_accuracy: 0.1333\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3819 - accuracy: 0.1333 - val_loss: 2.5032 - val_accuracy: 0.1333\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3792 - accuracy: 0.1333 - val_loss: 2.5000 - val_accuracy: 0.1333\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3763 - accuracy: 0.1333 - val_loss: 2.4971 - val_accuracy: 0.1333\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3736 - accuracy: 0.1333 - val_loss: 2.4941 - val_accuracy: 0.1333\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3709 - accuracy: 0.1333 - val_loss: 2.4910 - val_accuracy: 0.1444\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3682 - accuracy: 0.1333 - val_loss: 2.4880 - val_accuracy: 0.1444\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3652 - accuracy: 0.1333 - val_loss: 2.4852 - val_accuracy: 0.1444\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3626 - accuracy: 0.1333 - val_loss: 2.4822 - val_accuracy: 0.1444\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3601 - accuracy: 0.1333 - val_loss: 2.4791 - val_accuracy: 0.1444\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3573 - accuracy: 0.1333 - val_loss: 2.4763 - val_accuracy: 0.1556\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3547 - accuracy: 0.1333 - val_loss: 2.4735 - val_accuracy: 0.1667\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3520 - accuracy: 0.1333 - val_loss: 2.4707 - val_accuracy: 0.1667\n",
            "Epoch 65/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3494 - accuracy: 0.1407 - val_loss: 2.4678 - val_accuracy: 0.1667\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3468 - accuracy: 0.1407 - val_loss: 2.4651 - val_accuracy: 0.1667\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3443 - accuracy: 0.1407 - val_loss: 2.4623 - val_accuracy: 0.1667\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3417 - accuracy: 0.1444 - val_loss: 2.4596 - val_accuracy: 0.1778\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3391 - accuracy: 0.1444 - val_loss: 2.4571 - val_accuracy: 0.1778\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3368 - accuracy: 0.1444 - val_loss: 2.4543 - val_accuracy: 0.1778\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3342 - accuracy: 0.1481 - val_loss: 2.4517 - val_accuracy: 0.1778\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3318 - accuracy: 0.1519 - val_loss: 2.4491 - val_accuracy: 0.1778\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3293 - accuracy: 0.1519 - val_loss: 2.4466 - val_accuracy: 0.1778\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3269 - accuracy: 0.1556 - val_loss: 2.4441 - val_accuracy: 0.1778\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3244 - accuracy: 0.1593 - val_loss: 2.4415 - val_accuracy: 0.1778\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3221 - accuracy: 0.1593 - val_loss: 2.4390 - val_accuracy: 0.1778\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3197 - accuracy: 0.1593 - val_loss: 2.4364 - val_accuracy: 0.1778\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3173 - accuracy: 0.1593 - val_loss: 2.4340 - val_accuracy: 0.1778\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3149 - accuracy: 0.1630 - val_loss: 2.4316 - val_accuracy: 0.1778\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3126 - accuracy: 0.1630 - val_loss: 2.4291 - val_accuracy: 0.1778\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3102 - accuracy: 0.1630 - val_loss: 2.4266 - val_accuracy: 0.1778\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.3079 - accuracy: 0.1630 - val_loss: 2.4241 - val_accuracy: 0.1778\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3056 - accuracy: 0.1667 - val_loss: 2.4217 - val_accuracy: 0.1778\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3033 - accuracy: 0.1704 - val_loss: 2.4192 - val_accuracy: 0.1778\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.3010 - accuracy: 0.1704 - val_loss: 2.4168 - val_accuracy: 0.1778\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.2987 - accuracy: 0.1704 - val_loss: 2.4145 - val_accuracy: 0.1778\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2965 - accuracy: 0.1741 - val_loss: 2.4123 - val_accuracy: 0.2000\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2944 - accuracy: 0.1778 - val_loss: 2.4100 - val_accuracy: 0.2111\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2921 - accuracy: 0.1778 - val_loss: 2.4077 - val_accuracy: 0.2111\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2899 - accuracy: 0.1778 - val_loss: 2.4054 - val_accuracy: 0.2111\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.2878 - accuracy: 0.1778 - val_loss: 2.4031 - val_accuracy: 0.2111\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.2856 - accuracy: 0.1815 - val_loss: 2.4009 - val_accuracy: 0.2222\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.2835 - accuracy: 0.1815 - val_loss: 2.3988 - val_accuracy: 0.2222\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.2814 - accuracy: 0.1815 - val_loss: 2.3966 - val_accuracy: 0.2333\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2793 - accuracy: 0.1815 - val_loss: 2.3945 - val_accuracy: 0.2333\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2771 - accuracy: 0.1852 - val_loss: 2.3923 - val_accuracy: 0.2333\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2750 - accuracy: 0.1852 - val_loss: 2.3901 - val_accuracy: 0.2333\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2729 - accuracy: 0.1889 - val_loss: 2.3879 - val_accuracy: 0.2333\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2709 - accuracy: 0.1889 - val_loss: 2.3858 - val_accuracy: 0.2333\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2688 - accuracy: 0.1889 - val_loss: 2.3837 - val_accuracy: 0.2333\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2668 - accuracy: 0.1889 - val_loss: 2.3815 - val_accuracy: 0.2333\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2647 - accuracy: 0.1889 - val_loss: 2.3795 - val_accuracy: 0.2333\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2627 - accuracy: 0.1963 - val_loss: 2.3774 - val_accuracy: 0.2333\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2607 - accuracy: 0.2037 - val_loss: 2.3754 - val_accuracy: 0.2333\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2586 - accuracy: 0.2037 - val_loss: 2.3734 - val_accuracy: 0.2333\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2567 - accuracy: 0.2074 - val_loss: 2.3713 - val_accuracy: 0.2444\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2547 - accuracy: 0.2111 - val_loss: 2.3694 - val_accuracy: 0.2444\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2528 - accuracy: 0.2148 - val_loss: 2.3673 - val_accuracy: 0.2444\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2508 - accuracy: 0.2148 - val_loss: 2.3654 - val_accuracy: 0.2556\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2489 - accuracy: 0.2148 - val_loss: 2.3636 - val_accuracy: 0.2556\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2471 - accuracy: 0.2148 - val_loss: 2.3616 - val_accuracy: 0.2556\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2452 - accuracy: 0.2148 - val_loss: 2.3597 - val_accuracy: 0.2556\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2433 - accuracy: 0.2148 - val_loss: 2.3579 - val_accuracy: 0.2556\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2415 - accuracy: 0.2222 - val_loss: 2.3561 - val_accuracy: 0.2556\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2397 - accuracy: 0.2222 - val_loss: 2.3542 - val_accuracy: 0.2556\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2378 - accuracy: 0.2222 - val_loss: 2.3523 - val_accuracy: 0.2556\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2359 - accuracy: 0.2222 - val_loss: 2.3506 - val_accuracy: 0.2556\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2341 - accuracy: 0.2296 - val_loss: 2.3487 - val_accuracy: 0.2556\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2323 - accuracy: 0.2296 - val_loss: 2.3469 - val_accuracy: 0.2556\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2305 - accuracy: 0.2296 - val_loss: 2.3451 - val_accuracy: 0.2556\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2287 - accuracy: 0.2296 - val_loss: 2.3433 - val_accuracy: 0.2556\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2269 - accuracy: 0.2259 - val_loss: 2.3415 - val_accuracy: 0.2556\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2251 - accuracy: 0.2296 - val_loss: 2.3398 - val_accuracy: 0.2556\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2233 - accuracy: 0.2296 - val_loss: 2.3379 - val_accuracy: 0.2556\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2215 - accuracy: 0.2296 - val_loss: 2.3363 - val_accuracy: 0.2556\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2198 - accuracy: 0.2296 - val_loss: 2.3345 - val_accuracy: 0.2556\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2181 - accuracy: 0.2296 - val_loss: 2.3328 - val_accuracy: 0.2556\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2164 - accuracy: 0.2296 - val_loss: 2.3311 - val_accuracy: 0.2556\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2147 - accuracy: 0.2296 - val_loss: 2.3293 - val_accuracy: 0.2556\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2130 - accuracy: 0.2296 - val_loss: 2.3278 - val_accuracy: 0.2556\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2113 - accuracy: 0.2296 - val_loss: 2.3261 - val_accuracy: 0.2556\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2097 - accuracy: 0.2296 - val_loss: 2.3246 - val_accuracy: 0.2556\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2080 - accuracy: 0.2296 - val_loss: 2.3229 - val_accuracy: 0.2444\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2064 - accuracy: 0.2296 - val_loss: 2.3212 - val_accuracy: 0.2444\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2047 - accuracy: 0.2333 - val_loss: 2.3196 - val_accuracy: 0.2444\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2031 - accuracy: 0.2370 - val_loss: 2.3181 - val_accuracy: 0.2444\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2014 - accuracy: 0.2407 - val_loss: 2.3165 - val_accuracy: 0.2444\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1999 - accuracy: 0.2407 - val_loss: 2.3149 - val_accuracy: 0.2444\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1983 - accuracy: 0.2407 - val_loss: 2.3134 - val_accuracy: 0.2444\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1967 - accuracy: 0.2407 - val_loss: 2.3118 - val_accuracy: 0.2444\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.2481 - val_loss: 2.3104 - val_accuracy: 0.2444\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1935 - accuracy: 0.2481 - val_loss: 2.3088 - val_accuracy: 0.2444\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1919 - accuracy: 0.2519 - val_loss: 2.3073 - val_accuracy: 0.2556\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1904 - accuracy: 0.2519 - val_loss: 2.3058 - val_accuracy: 0.2667\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1888 - accuracy: 0.2519 - val_loss: 2.3043 - val_accuracy: 0.2778\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1873 - accuracy: 0.2519 - val_loss: 2.3029 - val_accuracy: 0.2778\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1858 - accuracy: 0.2519 - val_loss: 2.3015 - val_accuracy: 0.2778\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1843 - accuracy: 0.2519 - val_loss: 2.3000 - val_accuracy: 0.2889\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1828 - accuracy: 0.2519 - val_loss: 2.2986 - val_accuracy: 0.2889\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1813 - accuracy: 0.2519 - val_loss: 2.2972 - val_accuracy: 0.2889\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1798 - accuracy: 0.2519 - val_loss: 2.2958 - val_accuracy: 0.2778\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1783 - accuracy: 0.2519 - val_loss: 2.2944 - val_accuracy: 0.2778\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1768 - accuracy: 0.2519 - val_loss: 2.2929 - val_accuracy: 0.2778\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1753 - accuracy: 0.2556 - val_loss: 2.2915 - val_accuracy: 0.2778\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1738 - accuracy: 0.2556 - val_loss: 2.2902 - val_accuracy: 0.2778\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1724 - accuracy: 0.2556 - val_loss: 2.2888 - val_accuracy: 0.2778\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1710 - accuracy: 0.2556 - val_loss: 2.2875 - val_accuracy: 0.2778\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1695 - accuracy: 0.2556 - val_loss: 2.2861 - val_accuracy: 0.2778\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1680 - accuracy: 0.2556 - val_loss: 2.2846 - val_accuracy: 0.2889\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1665 - accuracy: 0.2556 - val_loss: 2.2832 - val_accuracy: 0.2889\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1651 - accuracy: 0.2556 - val_loss: 2.2819 - val_accuracy: 0.2889\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1637 - accuracy: 0.2593 - val_loss: 2.2806 - val_accuracy: 0.2889\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1623 - accuracy: 0.2630 - val_loss: 2.2792 - val_accuracy: 0.2889\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1608 - accuracy: 0.2630 - val_loss: 2.2779 - val_accuracy: 0.2889\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1595 - accuracy: 0.2667 - val_loss: 2.2766 - val_accuracy: 0.2889\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1581 - accuracy: 0.2667 - val_loss: 2.2753 - val_accuracy: 0.2889\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1567 - accuracy: 0.2667 - val_loss: 2.2740 - val_accuracy: 0.2889\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1554 - accuracy: 0.2667 - val_loss: 2.2728 - val_accuracy: 0.2889\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1540 - accuracy: 0.2667 - val_loss: 2.2715 - val_accuracy: 0.2889\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1526 - accuracy: 0.2667 - val_loss: 2.2702 - val_accuracy: 0.2889\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1512 - accuracy: 0.2704 - val_loss: 2.2689 - val_accuracy: 0.2889\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1498 - accuracy: 0.2704 - val_loss: 2.2676 - val_accuracy: 0.2889\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1485 - accuracy: 0.2704 - val_loss: 2.2663 - val_accuracy: 0.2889\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1471 - accuracy: 0.2704 - val_loss: 2.2650 - val_accuracy: 0.2889\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1458 - accuracy: 0.2704 - val_loss: 2.2638 - val_accuracy: 0.2889\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1444 - accuracy: 0.2704 - val_loss: 2.2626 - val_accuracy: 0.2889\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1431 - accuracy: 0.2704 - val_loss: 2.2615 - val_accuracy: 0.2889\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1418 - accuracy: 0.2704 - val_loss: 2.2603 - val_accuracy: 0.2889\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1405 - accuracy: 0.2704 - val_loss: 2.2590 - val_accuracy: 0.2889\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1392 - accuracy: 0.2741 - val_loss: 2.2578 - val_accuracy: 0.2889\n",
            "Epoch 181/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1379 - accuracy: 0.2741 - val_loss: 2.2567 - val_accuracy: 0.2889\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1366 - accuracy: 0.2741 - val_loss: 2.2555 - val_accuracy: 0.2889\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1354 - accuracy: 0.2741 - val_loss: 2.2544 - val_accuracy: 0.2889\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1341 - accuracy: 0.2741 - val_loss: 2.2533 - val_accuracy: 0.2889\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1329 - accuracy: 0.2741 - val_loss: 2.2522 - val_accuracy: 0.2889\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1316 - accuracy: 0.2741 - val_loss: 2.2511 - val_accuracy: 0.2889\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1303 - accuracy: 0.2741 - val_loss: 2.2500 - val_accuracy: 0.2889\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1291 - accuracy: 0.2741 - val_loss: 2.2489 - val_accuracy: 0.2889\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1278 - accuracy: 0.2741 - val_loss: 2.2478 - val_accuracy: 0.2889\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1266 - accuracy: 0.2741 - val_loss: 2.2467 - val_accuracy: 0.2889\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1253 - accuracy: 0.2741 - val_loss: 2.2456 - val_accuracy: 0.2889\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1241 - accuracy: 0.2741 - val_loss: 2.2444 - val_accuracy: 0.2889\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1229 - accuracy: 0.2741 - val_loss: 2.2433 - val_accuracy: 0.2889\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1216 - accuracy: 0.2741 - val_loss: 2.2422 - val_accuracy: 0.2889\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1204 - accuracy: 0.2741 - val_loss: 2.2412 - val_accuracy: 0.2889\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1192 - accuracy: 0.2741 - val_loss: 2.2401 - val_accuracy: 0.2889\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1180 - accuracy: 0.2741 - val_loss: 2.2391 - val_accuracy: 0.2889\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1169 - accuracy: 0.2741 - val_loss: 2.2380 - val_accuracy: 0.2889\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1156 - accuracy: 0.2741 - val_loss: 2.2371 - val_accuracy: 0.2889\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1145 - accuracy: 0.2778 - val_loss: 2.2360 - val_accuracy: 0.2889\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 2.0686 - accuracy: 0.2185 - val_loss: 2.1814 - val_accuracy: 0.2222\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0683 - accuracy: 0.2185 - val_loss: 2.1810 - val_accuracy: 0.2222\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0679 - accuracy: 0.2185 - val_loss: 2.1806 - val_accuracy: 0.2222\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0676 - accuracy: 0.2185 - val_loss: 2.1803 - val_accuracy: 0.2222\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0672 - accuracy: 0.2185 - val_loss: 2.1799 - val_accuracy: 0.2222\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0669 - accuracy: 0.2185 - val_loss: 2.1795 - val_accuracy: 0.2222\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0665 - accuracy: 0.2185 - val_loss: 2.1791 - val_accuracy: 0.2222\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0662 - accuracy: 0.2185 - val_loss: 2.1788 - val_accuracy: 0.2222\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0659 - accuracy: 0.2185 - val_loss: 2.1784 - val_accuracy: 0.2222\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0655 - accuracy: 0.2185 - val_loss: 2.1780 - val_accuracy: 0.2222\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0652 - accuracy: 0.2185 - val_loss: 2.1777 - val_accuracy: 0.2222\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0649 - accuracy: 0.2185 - val_loss: 2.1773 - val_accuracy: 0.2222\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0645 - accuracy: 0.2185 - val_loss: 2.1769 - val_accuracy: 0.2222\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0642 - accuracy: 0.2185 - val_loss: 2.1766 - val_accuracy: 0.2222\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0639 - accuracy: 0.2185 - val_loss: 2.1762 - val_accuracy: 0.2222\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0635 - accuracy: 0.2185 - val_loss: 2.1758 - val_accuracy: 0.2222\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0632 - accuracy: 0.2185 - val_loss: 2.1755 - val_accuracy: 0.2222\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0628 - accuracy: 0.2185 - val_loss: 2.1751 - val_accuracy: 0.2222\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0625 - accuracy: 0.2185 - val_loss: 2.1747 - val_accuracy: 0.2111\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0622 - accuracy: 0.2185 - val_loss: 2.1744 - val_accuracy: 0.2111\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0618 - accuracy: 0.2185 - val_loss: 2.1740 - val_accuracy: 0.2111\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0615 - accuracy: 0.2185 - val_loss: 2.1736 - val_accuracy: 0.2111\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0612 - accuracy: 0.2185 - val_loss: 2.1733 - val_accuracy: 0.2111\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0608 - accuracy: 0.2185 - val_loss: 2.1729 - val_accuracy: 0.2111\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0605 - accuracy: 0.2185 - val_loss: 2.1726 - val_accuracy: 0.2111\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0602 - accuracy: 0.2185 - val_loss: 2.1722 - val_accuracy: 0.2111\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0598 - accuracy: 0.2185 - val_loss: 2.1718 - val_accuracy: 0.2111\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0595 - accuracy: 0.2185 - val_loss: 2.1715 - val_accuracy: 0.2111\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0592 - accuracy: 0.2185 - val_loss: 2.1711 - val_accuracy: 0.2111\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0588 - accuracy: 0.2185 - val_loss: 2.1708 - val_accuracy: 0.2111\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0585 - accuracy: 0.2185 - val_loss: 2.1704 - val_accuracy: 0.2111\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0582 - accuracy: 0.2185 - val_loss: 2.1700 - val_accuracy: 0.2222\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0578 - accuracy: 0.2185 - val_loss: 2.1697 - val_accuracy: 0.2222\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0575 - accuracy: 0.2185 - val_loss: 2.1693 - val_accuracy: 0.2222\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0572 - accuracy: 0.2185 - val_loss: 2.1689 - val_accuracy: 0.2222\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0568 - accuracy: 0.2185 - val_loss: 2.1686 - val_accuracy: 0.2222\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0565 - accuracy: 0.2185 - val_loss: 2.1682 - val_accuracy: 0.2222\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0562 - accuracy: 0.2185 - val_loss: 2.1679 - val_accuracy: 0.2222\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0559 - accuracy: 0.2185 - val_loss: 2.1675 - val_accuracy: 0.2222\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0556 - accuracy: 0.2185 - val_loss: 2.1672 - val_accuracy: 0.2222\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0552 - accuracy: 0.2185 - val_loss: 2.1668 - val_accuracy: 0.2222\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0549 - accuracy: 0.2185 - val_loss: 2.1664 - val_accuracy: 0.2222\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0546 - accuracy: 0.2185 - val_loss: 2.1661 - val_accuracy: 0.2222\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0542 - accuracy: 0.2185 - val_loss: 2.1657 - val_accuracy: 0.2222\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0539 - accuracy: 0.2185 - val_loss: 2.1653 - val_accuracy: 0.2222\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0536 - accuracy: 0.2185 - val_loss: 2.1650 - val_accuracy: 0.2222\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0532 - accuracy: 0.2222 - val_loss: 2.1646 - val_accuracy: 0.2222\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0529 - accuracy: 0.2222 - val_loss: 2.1643 - val_accuracy: 0.2222\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0526 - accuracy: 0.2222 - val_loss: 2.1639 - val_accuracy: 0.2222\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0523 - accuracy: 0.2222 - val_loss: 2.1635 - val_accuracy: 0.2222\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0519 - accuracy: 0.2222 - val_loss: 2.1632 - val_accuracy: 0.2222\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0516 - accuracy: 0.2222 - val_loss: 2.1628 - val_accuracy: 0.2222\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0513 - accuracy: 0.2222 - val_loss: 2.1625 - val_accuracy: 0.2222\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0510 - accuracy: 0.2222 - val_loss: 2.1621 - val_accuracy: 0.2222\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0506 - accuracy: 0.2222 - val_loss: 2.1617 - val_accuracy: 0.2222\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0503 - accuracy: 0.2222 - val_loss: 2.1614 - val_accuracy: 0.2222\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0500 - accuracy: 0.2222 - val_loss: 2.1610 - val_accuracy: 0.2222\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0497 - accuracy: 0.2222 - val_loss: 2.1607 - val_accuracy: 0.2222\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0493 - accuracy: 0.2222 - val_loss: 2.1603 - val_accuracy: 0.2222\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0490 - accuracy: 0.2222 - val_loss: 2.1600 - val_accuracy: 0.2222\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0487 - accuracy: 0.2222 - val_loss: 2.1596 - val_accuracy: 0.2222\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0484 - accuracy: 0.2222 - val_loss: 2.1592 - val_accuracy: 0.2333\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0480 - accuracy: 0.2222 - val_loss: 2.1589 - val_accuracy: 0.2333\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0477 - accuracy: 0.2222 - val_loss: 2.1586 - val_accuracy: 0.2333\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0474 - accuracy: 0.2222 - val_loss: 2.1582 - val_accuracy: 0.2333\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0471 - accuracy: 0.2222 - val_loss: 2.1579 - val_accuracy: 0.2333\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0468 - accuracy: 0.2222 - val_loss: 2.1575 - val_accuracy: 0.2333\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0465 - accuracy: 0.2222 - val_loss: 2.1572 - val_accuracy: 0.2333\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0461 - accuracy: 0.2222 - val_loss: 2.1568 - val_accuracy: 0.2333\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0458 - accuracy: 0.2222 - val_loss: 2.1565 - val_accuracy: 0.2333\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0455 - accuracy: 0.2222 - val_loss: 2.1561 - val_accuracy: 0.2333\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0452 - accuracy: 0.2222 - val_loss: 2.1558 - val_accuracy: 0.2333\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0449 - accuracy: 0.2222 - val_loss: 2.1554 - val_accuracy: 0.2333\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0446 - accuracy: 0.2222 - val_loss: 2.1551 - val_accuracy: 0.2333\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0442 - accuracy: 0.2222 - val_loss: 2.1547 - val_accuracy: 0.2333\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0439 - accuracy: 0.2222 - val_loss: 2.1544 - val_accuracy: 0.2333\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0436 - accuracy: 0.2222 - val_loss: 2.1540 - val_accuracy: 0.2444\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0433 - accuracy: 0.2185 - val_loss: 2.1537 - val_accuracy: 0.2444\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0430 - accuracy: 0.2222 - val_loss: 2.1534 - val_accuracy: 0.2444\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0427 - accuracy: 0.2222 - val_loss: 2.1530 - val_accuracy: 0.2444\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0424 - accuracy: 0.2222 - val_loss: 2.1527 - val_accuracy: 0.2444\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0420 - accuracy: 0.2222 - val_loss: 2.1523 - val_accuracy: 0.2444\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0417 - accuracy: 0.2222 - val_loss: 2.1520 - val_accuracy: 0.2444\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0414 - accuracy: 0.2222 - val_loss: 2.1516 - val_accuracy: 0.2444\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0411 - accuracy: 0.2222 - val_loss: 2.1513 - val_accuracy: 0.2444\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0408 - accuracy: 0.2222 - val_loss: 2.1509 - val_accuracy: 0.2444\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0405 - accuracy: 0.2222 - val_loss: 2.1506 - val_accuracy: 0.2444\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0401 - accuracy: 0.2222 - val_loss: 2.1502 - val_accuracy: 0.2444\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0398 - accuracy: 0.2222 - val_loss: 2.1499 - val_accuracy: 0.2444\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0395 - accuracy: 0.2222 - val_loss: 2.1495 - val_accuracy: 0.2444\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0392 - accuracy: 0.2222 - val_loss: 2.1492 - val_accuracy: 0.2556\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0389 - accuracy: 0.2222 - val_loss: 2.1488 - val_accuracy: 0.2556\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0386 - accuracy: 0.2222 - val_loss: 2.1485 - val_accuracy: 0.2556\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0382 - accuracy: 0.2222 - val_loss: 2.1482 - val_accuracy: 0.2556\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0379 - accuracy: 0.2222 - val_loss: 2.1478 - val_accuracy: 0.2556\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0376 - accuracy: 0.2259 - val_loss: 2.1475 - val_accuracy: 0.2556\n",
            "Epoch 97/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0373 - accuracy: 0.2259 - val_loss: 2.1471 - val_accuracy: 0.2556\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0370 - accuracy: 0.2259 - val_loss: 2.1468 - val_accuracy: 0.2556\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0367 - accuracy: 0.2259 - val_loss: 2.1464 - val_accuracy: 0.2556\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0364 - accuracy: 0.2259 - val_loss: 2.1461 - val_accuracy: 0.2556\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0361 - accuracy: 0.2259 - val_loss: 2.1457 - val_accuracy: 0.2556\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0358 - accuracy: 0.2259 - val_loss: 2.1454 - val_accuracy: 0.2556\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0354 - accuracy: 0.2259 - val_loss: 2.1451 - val_accuracy: 0.2556\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0351 - accuracy: 0.2259 - val_loss: 2.1447 - val_accuracy: 0.2667\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0348 - accuracy: 0.2259 - val_loss: 2.1444 - val_accuracy: 0.2667\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0345 - accuracy: 0.2259 - val_loss: 2.1440 - val_accuracy: 0.2667\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0342 - accuracy: 0.2259 - val_loss: 2.1437 - val_accuracy: 0.2667\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0339 - accuracy: 0.2259 - val_loss: 2.1434 - val_accuracy: 0.2667\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0336 - accuracy: 0.2259 - val_loss: 2.1430 - val_accuracy: 0.2667\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0333 - accuracy: 0.2259 - val_loss: 2.1427 - val_accuracy: 0.2667\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0330 - accuracy: 0.2259 - val_loss: 2.1424 - val_accuracy: 0.2667\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0327 - accuracy: 0.2259 - val_loss: 2.1420 - val_accuracy: 0.2667\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0324 - accuracy: 0.2259 - val_loss: 2.1417 - val_accuracy: 0.2667\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0321 - accuracy: 0.2259 - val_loss: 2.1413 - val_accuracy: 0.2667\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0318 - accuracy: 0.2259 - val_loss: 2.1410 - val_accuracy: 0.2667\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0315 - accuracy: 0.2259 - val_loss: 2.1407 - val_accuracy: 0.2667\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0312 - accuracy: 0.2259 - val_loss: 2.1404 - val_accuracy: 0.2667\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0309 - accuracy: 0.2259 - val_loss: 2.1400 - val_accuracy: 0.2667\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0306 - accuracy: 0.2259 - val_loss: 2.1397 - val_accuracy: 0.2667\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0303 - accuracy: 0.2296 - val_loss: 2.1394 - val_accuracy: 0.2667\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0300 - accuracy: 0.2296 - val_loss: 2.1391 - val_accuracy: 0.2667\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0297 - accuracy: 0.2296 - val_loss: 2.1387 - val_accuracy: 0.2667\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0294 - accuracy: 0.2296 - val_loss: 2.1384 - val_accuracy: 0.2667\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0291 - accuracy: 0.2296 - val_loss: 2.1381 - val_accuracy: 0.2778\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0288 - accuracy: 0.2296 - val_loss: 2.1377 - val_accuracy: 0.2778\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0285 - accuracy: 0.2296 - val_loss: 2.1374 - val_accuracy: 0.2778\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0282 - accuracy: 0.2296 - val_loss: 2.1371 - val_accuracy: 0.2778\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0279 - accuracy: 0.2296 - val_loss: 2.1367 - val_accuracy: 0.2778\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0276 - accuracy: 0.2296 - val_loss: 2.1364 - val_accuracy: 0.2778\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0273 - accuracy: 0.2296 - val_loss: 2.1361 - val_accuracy: 0.2778\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0270 - accuracy: 0.2296 - val_loss: 2.1357 - val_accuracy: 0.2778\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0267 - accuracy: 0.2296 - val_loss: 2.1354 - val_accuracy: 0.2778\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0264 - accuracy: 0.2296 - val_loss: 2.1350 - val_accuracy: 0.2778\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0261 - accuracy: 0.2296 - val_loss: 2.1347 - val_accuracy: 0.2778\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0258 - accuracy: 0.2296 - val_loss: 2.1344 - val_accuracy: 0.2778\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0255 - accuracy: 0.2296 - val_loss: 2.1341 - val_accuracy: 0.2778\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0252 - accuracy: 0.2296 - val_loss: 2.1337 - val_accuracy: 0.2778\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0249 - accuracy: 0.2296 - val_loss: 2.1334 - val_accuracy: 0.2778\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0246 - accuracy: 0.2296 - val_loss: 2.1331 - val_accuracy: 0.2778\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0243 - accuracy: 0.2296 - val_loss: 2.1328 - val_accuracy: 0.2778\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0240 - accuracy: 0.2296 - val_loss: 2.1324 - val_accuracy: 0.2778\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0237 - accuracy: 0.2296 - val_loss: 2.1321 - val_accuracy: 0.2778\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0234 - accuracy: 0.2296 - val_loss: 2.1318 - val_accuracy: 0.2778\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0231 - accuracy: 0.2296 - val_loss: 2.1314 - val_accuracy: 0.2778\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0228 - accuracy: 0.2296 - val_loss: 2.1311 - val_accuracy: 0.2889\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0225 - accuracy: 0.2296 - val_loss: 2.1308 - val_accuracy: 0.2889\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0222 - accuracy: 0.2296 - val_loss: 2.1305 - val_accuracy: 0.2889\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0220 - accuracy: 0.2296 - val_loss: 2.1302 - val_accuracy: 0.2889\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0217 - accuracy: 0.2296 - val_loss: 2.1298 - val_accuracy: 0.2889\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0214 - accuracy: 0.2296 - val_loss: 2.1295 - val_accuracy: 0.2889\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0211 - accuracy: 0.2296 - val_loss: 2.1292 - val_accuracy: 0.2889\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0208 - accuracy: 0.2296 - val_loss: 2.1289 - val_accuracy: 0.2889\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0205 - accuracy: 0.2296 - val_loss: 2.1286 - val_accuracy: 0.2889\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0202 - accuracy: 0.2296 - val_loss: 2.1282 - val_accuracy: 0.2889\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0199 - accuracy: 0.2296 - val_loss: 2.1279 - val_accuracy: 0.2889\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0196 - accuracy: 0.2296 - val_loss: 2.1276 - val_accuracy: 0.2889\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0193 - accuracy: 0.2296 - val_loss: 2.1273 - val_accuracy: 0.2889\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0190 - accuracy: 0.2333 - val_loss: 2.1269 - val_accuracy: 0.2889\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0188 - accuracy: 0.2333 - val_loss: 2.1266 - val_accuracy: 0.2889\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0185 - accuracy: 0.2333 - val_loss: 2.1263 - val_accuracy: 0.2889\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0182 - accuracy: 0.2333 - val_loss: 2.1260 - val_accuracy: 0.2889\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0179 - accuracy: 0.2333 - val_loss: 2.1257 - val_accuracy: 0.2889\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0176 - accuracy: 0.2333 - val_loss: 2.1254 - val_accuracy: 0.2889\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0173 - accuracy: 0.2333 - val_loss: 2.1250 - val_accuracy: 0.2889\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0170 - accuracy: 0.2333 - val_loss: 2.1247 - val_accuracy: 0.2889\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0167 - accuracy: 0.2333 - val_loss: 2.1244 - val_accuracy: 0.2889\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0165 - accuracy: 0.2333 - val_loss: 2.1241 - val_accuracy: 0.2889\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0162 - accuracy: 0.2333 - val_loss: 2.1238 - val_accuracy: 0.2889\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0159 - accuracy: 0.2333 - val_loss: 2.1234 - val_accuracy: 0.2889\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0156 - accuracy: 0.2333 - val_loss: 2.1231 - val_accuracy: 0.2889\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0153 - accuracy: 0.2333 - val_loss: 2.1228 - val_accuracy: 0.2889\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0150 - accuracy: 0.2333 - val_loss: 2.1224 - val_accuracy: 0.2889\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0147 - accuracy: 0.2333 - val_loss: 2.1221 - val_accuracy: 0.2889\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0144 - accuracy: 0.2333 - val_loss: 2.1218 - val_accuracy: 0.2889\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0141 - accuracy: 0.2333 - val_loss: 2.1215 - val_accuracy: 0.2889\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0138 - accuracy: 0.2333 - val_loss: 2.1212 - val_accuracy: 0.2889\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0136 - accuracy: 0.2333 - val_loss: 2.1209 - val_accuracy: 0.2889\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0133 - accuracy: 0.2333 - val_loss: 2.1205 - val_accuracy: 0.2889\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0130 - accuracy: 0.2333 - val_loss: 2.1202 - val_accuracy: 0.2889\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0127 - accuracy: 0.2333 - val_loss: 2.1199 - val_accuracy: 0.2889\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0124 - accuracy: 0.2333 - val_loss: 2.1196 - val_accuracy: 0.2889\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0121 - accuracy: 0.2333 - val_loss: 2.1193 - val_accuracy: 0.2889\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0118 - accuracy: 0.2370 - val_loss: 2.1189 - val_accuracy: 0.2889\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0116 - accuracy: 0.2370 - val_loss: 2.1186 - val_accuracy: 0.3000\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0113 - accuracy: 0.2370 - val_loss: 2.1183 - val_accuracy: 0.3000\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0110 - accuracy: 0.2370 - val_loss: 2.1180 - val_accuracy: 0.3000\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0107 - accuracy: 0.2370 - val_loss: 2.1177 - val_accuracy: 0.3000\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0104 - accuracy: 0.2370 - val_loss: 2.1174 - val_accuracy: 0.3000\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0101 - accuracy: 0.2370 - val_loss: 2.1171 - val_accuracy: 0.3000\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0099 - accuracy: 0.2370 - val_loss: 2.1168 - val_accuracy: 0.3000\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0096 - accuracy: 0.2370 - val_loss: 2.1165 - val_accuracy: 0.3000\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0093 - accuracy: 0.2370 - val_loss: 2.1162 - val_accuracy: 0.3000\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0090 - accuracy: 0.2370 - val_loss: 2.1158 - val_accuracy: 0.3000\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0088 - accuracy: 0.2370 - val_loss: 2.1155 - val_accuracy: 0.3000\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0085 - accuracy: 0.2370 - val_loss: 2.1152 - val_accuracy: 0.3000\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0082 - accuracy: 0.2370 - val_loss: 2.1149 - val_accuracy: 0.3000\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0079 - accuracy: 0.2370 - val_loss: 2.1146 - val_accuracy: 0.3000\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0076 - accuracy: 0.2370 - val_loss: 2.1143 - val_accuracy: 0.3000\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0074 - accuracy: 0.2370 - val_loss: 2.1140 - val_accuracy: 0.3000\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0071 - accuracy: 0.2370 - val_loss: 2.1137 - val_accuracy: 0.3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZdy4Bu1QujV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgAeXlhZQujV",
        "outputId": "28101cb2-a942-4e32-9a0b-d368f1ebc09c"
      },
      "source": [
        "#-------------------REGRESSION LOGISTIQUE WITH SCIKIT LEARN ---------------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
        "logreg=LogisticRegression()\n",
        "logreg_cv=GridSearchCV(logreg,grid,cv=4)\n",
        "logreg_cv.fit(X_train,y_train)\n",
        "#score\n",
        "best_parameters = logreg_cv.best_params_\n",
        "best_accuracy = logreg_cv.best_score_\n",
        "print(best_accuracy,best_parameters)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4074846356453029 {'C': 0.1, 'penalty': 'l2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uXnAatjQujV",
        "outputId": "17d1ed48-d114-4010-8431-d3bca785b10b"
      },
      "source": [
        "#-------------------RANDOM FOREST WITH SCIKIT LEARN ---------------------\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc=RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = { \n",
        "    'n_estimators': [50,100],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [4,8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3)\n",
        "CV_rfc.fit(X_train, y_train)\n",
        "#score\n",
        "best_parameters = CV_rfc.best_params_\n",
        "best_accuracy = CV_rfc.best_score_\n",
        "print(best_accuracy,best_parameters)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5592592592592592 {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aDxFOeHQujV",
        "outputId": "36f9fb71-ffb8-433e-c49a-45ccfd653b31"
      },
      "source": [
        "#-------------------SVM WITH SCIKIT LEARN ---------------------\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "param_grid = {'C': [1e3, 1e5],\n",
        "              'gamma': [0.0001, 0.1], }\n",
        "clf = GridSearchCV(\n",
        "    svm.SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
        ")\n",
        "clf = clf.fit(X_train, y_train)\n",
        "#score\n",
        "best_parameters = clf.best_params_\n",
        "best_accuracy = clf.best_score_\n",
        "print(best_accuracy,best_parameters)\n",
        "#scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "# Use score method to get accuracy of model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5962962962962963 {'C': 1000.0, 'gamma': 0.0001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekWMMWQrQujV"
      },
      "source": [
        "#-------------------Neural Network WITH SCIKIT LEARN ---------------------\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "parameters = {'solver': ['lbfgs'], 'max_iter': [100,200 ], 'alpha': 10.0 ** -np.arange(1, 5), 'hidden_layer_sizes':np.arange(10, 12), 'random_state':[0,3,6,9]}\n",
        "ML = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
        "\n",
        "ML.fit(X_train, y_train)\n",
        "\n",
        "#score\n",
        "best_parameters = ML.best_params_\n",
        "best_accuracy = ML.best_score_\n",
        "print(best_accuracy,best_parameters)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPJ1qExlv6BQ"
      },
      "source": [
        "**<ins>Question</ins>: Évaluer les modèles appris en décrivant votre méthode**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNAFZTFvv6BS"
      },
      "source": [
        "Pour chaques modèle on entraîne sur le jeu de donnée puis on test. \n",
        "Pour ce qui est des méthodes d'optimisation des hyper-paramètres, il y a deux méthodes:\n",
        "-Learning/validation curve \n",
        "elle permet de voir l'évolution de la qualité du modèle en fonction de l'entraînement. \n",
        "Très utile pour detecter le surentraînement et autre spécificités du modèle.\n",
        "\n",
        "-Grid search CV \n",
        "Permet de croiser tout les hyper-paramètres spécifiés et ressort le modèle avec les meilleurs hyper-paramètres.\n",
        "\n",
        "# Pour le réseau de neurones avec tensorflow:\n",
        "J'ai utilisé les deux méthodes \n",
        "Le réseau permet d'obtenir une accuracy de 46% sur les données d'entraînement et de 43% sur les données de test.\n",
        "\n",
        "# Regression logistique:\n",
        "j'utilise Grid search CV \n",
        "\n",
        "hyper-paramètres: Learning rate, C paramètre de régularisation\n",
        "\n",
        "J'obtiens un score de 41%\n",
        "\n",
        "# Random forest:\n",
        "j'utilise Grid search CV \n",
        "\n",
        "hyper-paramètres: Profondeur de l'arbre, nombre d'arbres dans la forêt \n",
        "\n",
        "J'obtiens un score de 35%\n",
        "\n",
        "# SVM:\n",
        "j'utilise Grid search CV \n",
        "\n",
        "hyper-paramètres: C paramètre de régularisation, gamma \n",
        "\n",
        "J'obtiens un score de 71%\n",
        "\n",
        "# Neural Network with Sklearn\n",
        "j'utilise Grid search CV \n",
        "\n",
        "hyper-paramètres: Learning rate, nombre d'hiden layer, le solver (algo backpropagation)...\n",
        "\n",
        "J'obtiens un score de 71%\n",
        "\n",
        "\n",
        "Le modèle SVM est donc le grand gagnant pour cette classification. \n",
        "Ce qui est prévisible car étant donné le jeu de données, c'est celui qui est recommandé par la SKlearn map que l'on peut retrouver sur l'API de la bibliothèque."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xw7bbYtv6BX"
      },
      "source": [
        "**<ins>Question</ins>: Réalisez un diagramme fonctionnel décrivant le flux des données tout au long de l'approche supervisée. Ce diagramme devra faire apparaître au minimum: les trois ensembles d'images, les descripteurs, les différents algorithmes d'apprentissage, l'évaluation (mettre une image dans le répertoire courant et dans la cellule ci-dessous remplacer par le nom du fichier)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDclLV6xv6BX"
      },
      "source": [
        " <img src=\"graphs.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNgbxS-Fv6BY"
      },
      "source": [
        "# Partie 2: Approche supervisée sur descripteurs issus du scattering operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTyHJCfTQujV"
      },
      "source": [
        "## Chargement des descripteurs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYGGoa--v6BZ"
      },
      "source": [
        "**<ins>Question</ins>: Chargez les données du fichier matlab imdb_200x200_SmallSonarTex_db_6classes_scatValOnly.mat**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LmzGnm9v6BZ"
      },
      "source": [
        "_Your Code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w4sdmcCv6Bb"
      },
      "source": [
        "from pythonTools import *\n",
        "from usefulCmds import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Loading the csv file\n",
        "DATASET_PATH = r'./dataset/'\n",
        "DATASET_FILE = r'./imdb_200x200_SmallSonarTex_db_6classes_scatValOnly.mat'\n",
        "DATASET = os.path.join(DATASET_PATH, DATASET_FILE)\n",
        "\n",
        "DATASET_PATH = r'./dataset/imgs/'\n",
        "LABEL_PATH = r'./dataset/labels/labels.csv'\n",
        "dataset_df = pd.read_csv(LABEL_PATH)\n",
        "\n",
        "X = np.array([img.reshape(217,) for img in data_mat[\"featVal\"]])\n",
        "\n",
        "\n",
        "data_mat = loadmat(DATASET)\n",
        "\n",
        "#On récupère les labels\n",
        "label_names = dataset_df['seafloor']\n",
        "label_names_unique = label_names.unique()\n",
        "\n",
        "#  transformation des labels selon différents codages\n",
        "# indices\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(label_names_unique)\n",
        "label_indices = le.transform(label_names_unique)\n",
        "# Getting labels for our dataset\n",
        "y = le.transform(label_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaLfLtawQujW"
      },
      "source": [
        "## Prétraitements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpnR5ECxv6Bf"
      },
      "source": [
        "**<ins>Question</ins>: Y-a-t-il besoin de normaliser les descripteurs? Si oui, que faut-il conserver comme information et pourquoi?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1kxf9u-v6Bf"
      },
      "source": [
        "Oui il faut normaliser les descripteurs car cela permet de réduire le temps d'entraînement. Notamment pour les réseaux de neuronnes. En revanche , il faut garder la taille du vecteur et bien sûr les paramètres de la normalisation. Ces paramètres sont essentielles pour faire une prédiction. En effet, on entraîne le réseau sur un jeu de données normalisé. Il faut garder ces paramètres pour pouvoir présenter au réseau une image dans les même condition lors d'une prédiction ( moyenne , écart-type)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa57t02CQujW"
      },
      "source": [
        "_Your Code below_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz6os5L9QujW",
        "outputId": "cbb6fd6e-9406-4e19-d329-ec2cd1263873"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(270, 217) (270,) (90, 217) (90,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOUUuqesQujW"
      },
      "source": [
        "## Apprentissage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKfZD5Ymv6Bg"
      },
      "source": [
        "<strong><ins>Question</ins>: Séparer en deux ensembles de données et réalisez l'apprentissage successifs des modèles:\n",
        "* régression logistique, réseaux de neurones, svm et random forest en utilisant les fonctions du package scikit-learn\n",
        "</strong>\n",
        "\n",
        "<span style='color:red'> **Pas de code à développer ici, réutiliser celui de la partie 1**</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N1W3SAeQujW"
      },
      "source": [
        "## Fixer les hyper paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMEkJXYOQujW"
      },
      "source": [
        "**<ins>Question</ins>: Déterminez les hyper-paramètres (paramètre uniquement lié à l'algorithme d'apprentissage) de chaque algorithme. Comment allez vous les fixer?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7VljD2mQujW"
      },
      "source": [
        "Même façon que la partie 1. Lire la partie 1.\n",
        "\n",
        "Il y a deux possibilités de faire :\n",
        "\n",
        "Utiliser la learning/validation curve qui permet de visualiser l'erreur du réseau en fonction du nombre d'entraînement.\n",
        "\n",
        "Utiliser la fonction gridsearch cv bassée sur la cross validation. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPTVxU1Av6Bt"
      },
      "source": [
        "**<ins>Question</ins>:\n",
        "Lisez le [tutoriel suivant](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html\\#sphx-glr-auto-examples-applications-plot-face-recognition-py) en faisant particulièrement attention à la façon dont est gérée la détermination des hyperparamètres et l'évaluation des performances. Reproduisez cette méthodologie en testant différents nombres de plis (fold).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5LRVGpuQujW",
        "outputId": "a07190ee-530b-45bb-a4cd-7019e184753a"
      },
      "source": [
        "#-------------------REGRESSION LOGISTIQUE WITH SCIKIT LEARN ---------------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
        "logreg=LogisticRegression()\n",
        "logreg_cv=GridSearchCV(logreg,grid,cv=4)\n",
        "logreg_cv.fit(X_train,y_train)\n",
        "#score\n",
        "best_parameters = logreg_cv.best_params_\n",
        "best_accuracy = logreg_cv.best_score_\n",
        "print(best_accuracy,best_parameters)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9888608428446005 {'C': 1.0, 'penalty': 'l2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyaSW0qWQujW",
        "outputId": "4b89f9ff-7b61-4d63-f824-8a3047c4f3f8"
      },
      "source": [
        "#-------------------RANDOM FOREST WITH SCIKIT LEARN ---------------------\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc=RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = { \n",
        "    'n_estimators': [50,100],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [4,8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3)\n",
        "CV_rfc.fit(X_train, y_train)\n",
        "#score\n",
        "best_parameters = CV_rfc.best_params_\n",
        "best_accuracy = CV_rfc.best_score_\n",
        "print(best_accuracy,best_parameters)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9592592592592593 {'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mNBexjOQujW",
        "outputId": "97c3f920-26a1-4838-e53b-1ab5440d648f"
      },
      "source": [
        "#-------------------SVM WITH SCIKIT LEARN ---------------------\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "param_grid = {'C': [1e3,1e4, 1e5],\n",
        "              'gamma': [0.0001,0.001,0.005,0.01,0.05, 0.1], }\n",
        "clf = GridSearchCV(\n",
        "    svm.SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
        ")\n",
        "clf = clf.fit(X_train, y_train)\n",
        "#score\n",
        "best_parameters = clf.best_params_\n",
        "best_accuracy = clf.best_score_\n",
        "print(best_accuracy,best_parameters)\n",
        "#scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "# Use score method to get accuracy of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9925925925925926 {'C': 1000.0, 'gamma': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GgQHdwrQujW",
        "outputId": "de00bb54-bab5-4dfe-e2ab-ef163e42c4b6"
      },
      "source": [
        "#-------------------Neural Network WITH SCIKIT LEARN ---------------------\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "parameters = {'solver': ['lbfgs'], 'max_iter': [1000,2000 ], 'alpha': 10.0 ** -np.arange(1, 5), 'hidden_layer_sizes':np.arange(10, 12), 'random_state':[0,3,6,9]}\n",
        "ML = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
        "\n",
        "ML.fit(X_train, y_train)\n",
        "\n",
        "#score\n",
        "best_parameters = ML.best_params_\n",
        "best_accuracy = ML.best_score_\n",
        "print(best_accuracy,best_parameters)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9962962962962962 {'alpha': 0.01, 'hidden_layer_sizes': 10, 'max_iter': 1000, 'random_state': 9, 'solver': 'lbfgs'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXG85EQLv6Bn"
      },
      "source": [
        "**<ins>Question</ins>: Évaluer les résultats et donner la valeur des paramètres optimaux**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2imQo5dcv6Bu"
      },
      "source": [
        "# Résultats\n",
        "\n",
        "## Regression logistique\n",
        "Best score = 0.9888608428446005\n",
        "\n",
        "Best parametres : C=1.0, 'penalty=l2\n",
        "\n",
        "## Random forest\n",
        "Best score = 0.9592592592592593\n",
        "\n",
        "Best parametres : criterion = gini, max_depth = 8, max_features = log2, n_estimators = 100\n",
        "\n",
        "## SVM\n",
        "Best score = 0.9925925925925926\n",
        "\n",
        "Best parametres : C = 1000.0, gamma = 0.01\n",
        "\n",
        "## Neural Network\n",
        "Best score = 0.9962962962962962\n",
        "\n",
        "Best parametres : alpha = 0.01, hidden_layer_sizes = 10, max_iter = 1000, random_state = 9, solver = lbfgs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCfpimWXQujW"
      },
      "source": [
        "## Apprendre le modèle final pour chaque classifieur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaScSTpdQujW",
        "outputId": "c2a478bb-b7a6-4e14-c9c2-dbf258236b4d"
      },
      "source": [
        "# Logistic regression\n",
        "logreg=LogisticRegression(C=1.0, penalty='l2')\n",
        "logreg.fit(X_train,y_train)\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = logreg.predict(X_test)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (logreg, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(logreg, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       1.00      0.94      0.97        16\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.93      0.88      0.90        16\n",
            "\n",
            "    accuracy                           0.97        90\n",
            "   macro avg       0.96      0.97      0.96        90\n",
            "weighted avg       0.97      0.97      0.97        90\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[15  0  0  0  0  0]\n",
            " [ 0 17  0  0  0  0]\n",
            " [ 0  0 10  0  0  0]\n",
            " [ 0  0  0 15  0  1]\n",
            " [ 0  0  0  0 16  0]\n",
            " [ 0  0  2  0  0 14]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TshOkDtsQujX",
        "outputId": "aff4af02-27d9-4dbb-c7e3-57d43bdc5d31"
      },
      "source": [
        "#Random Forest\n",
        "\n",
        "rfc=RandomForestClassifier(random_state=42,criterion='gini',max_depth=8, max_features='log2',n_estimators=100)\n",
        "rfc.fit(X_train,y_train)\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = rfc.predict(X_test)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (rfc, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(rfc, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=8, max_features='log2',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      0.94      0.97        17\n",
            "           2       0.69      0.90      0.78        10\n",
            "           3       0.94      0.94      0.94        16\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.93      0.81      0.87        16\n",
            "\n",
            "    accuracy                           0.93        90\n",
            "   macro avg       0.93      0.93      0.93        90\n",
            "weighted avg       0.94      0.93      0.94        90\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[15  0  0  0  0  0]\n",
            " [ 0 16  0  1  0  0]\n",
            " [ 0  0  9  0  0  1]\n",
            " [ 0  0  1 15  0  0]\n",
            " [ 0  0  0  0 16  0]\n",
            " [ 0  0  3  0  0 13]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nvBF7qXQujX",
        "outputId": "f4d20511-21ff-4485-9529-34f4be27158b"
      },
      "source": [
        "#SVM\n",
        "\n",
        "clf=svm.SVC(kernel='rbf', class_weight='balanced',C=1000.0, gamma= 0.01)\n",
        "clf.fit(X_train,y_train)\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = clf.predict(X_test)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (clf, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(clf, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1000.0, break_ties=False, cache_size=200, class_weight='balanced',\n",
            "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,\n",
            "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
            "    shrinking=True, tol=0.001, verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       1.00      0.94      0.97        16\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.94      0.94      0.94        16\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.97      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[15  0  0  0  0  0]\n",
            " [ 0 17  0  0  0  0]\n",
            " [ 0  0 10  0  0  0]\n",
            " [ 0  0  0 15  0  1]\n",
            " [ 0  0  0  0 16  0]\n",
            " [ 0  0  1  0  0 15]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ncNG_hQujX",
        "outputId": "b2fdb4be-7e0a-49cc-8d4d-617d6573a7ac"
      },
      "source": [
        "# Neural network\n",
        "ML=MLPClassifier(solver='lbfgs',alpha=0.01, hidden_layer_sizes=10, max_iter=1000, random_state=9)\n",
        "ML.fit(X_train,y_train)\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = ML.predict(X_test)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (ML, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(ML, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=10, learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=9, shuffle=True, solver='lbfgs',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       1.00      0.94      0.97        16\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.94      0.94      0.94        16\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.97      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[15  0  0  0  0  0]\n",
            " [ 0 17  0  0  0  0]\n",
            " [ 0  0 10  0  0  0]\n",
            " [ 0  0  0 15  0  1]\n",
            " [ 0  0  0  0 16  0]\n",
            " [ 0  0  1  0  0 15]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rpSf449v6Bt"
      },
      "source": [
        "# Résultats des modèles finaux\n",
        "Dans cette dernière partie, on a entraîné les différents modèles avec les hyper-paramètres optimaux que nous avions déterminez dans la partie précédente. \n",
        "On a pu évaluer ces différents modèles sur le test set. \n",
        "On a pu visualiser notamment la matrice de confusion qui permet de visualiser les erreurs qu'à pu commettre le modèle lors de la prédiction des images du test set.\n",
        "\n",
        "## Regression logistique\n",
        "Comme on peut le visualiser sur la matrice de confusion le modèle de Regression logistique a fait 3 erreurs sur le test set.\n",
        "\n",
        "## Random forest\n",
        "Comme on peut le visualiser sur la matrice de confusion le modèle de Random forest a fait 6 erreurs sur le test set.\n",
        "\n",
        "## SVM\n",
        "Comme on peut le visualiser sur la matrice de confusion le modèle SVM a fait 2 erreurs sur le test set.\n",
        "\n",
        "## Neural Network\n",
        "Comme on peut le visualiser sur la matrice de confusion le modèle de Machine learning a fait 2 erreurs sur le test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnMpegufv6By"
      },
      "source": [
        "## Partie 4 Analyse finale des résultats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew9r6cPgv6By"
      },
      "source": [
        "**<ins>Question</ins>: Réalisez un diagramme fonctionnel décrivant le flux des données tout au long de l'approche supervisée. Ce diagramme devra faire apparaître au minimum: les trois ensembles d'images, les descripteurs, les différents algorithmes d'apprentissage, l'évaluation, les différents blocs de traitements.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k91uEbZGv6B1"
      },
      "source": [
        " <img src=\"graphs.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVqpga1vv6B5"
      },
      "source": [
        "**<ins>Question</ins>: Faites une synthèse des résultats obtenus. Dresser en particulier des conclusions en fonction des descripteurs utilisés, des algorithmes utilisés et des prétraitements effectués.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUF82_f1v6B5"
      },
      "source": [
        "La synthèse des différents modèles a été réalisée précédement. On s'aperçoit que les modèles les plus performant sont le modèle de neural network et SVM qu'on pouvait prédire grace à la carte proposée par SKlearn.On remarque que le traitement de convolution et de pooling pour les données de la partie 2 a permis aux modèles de converger vers des résultats bien meilleurs qu'à la partie 1.\n",
        "Ainsi de façon général pour un traitement d'image on retiendra le modèle du neural network avec en amont un traitement de convolution pour l'extraction de features et pooling pour réduire la taille du vecteur d'entrée."
      ]
    }
  ]
}