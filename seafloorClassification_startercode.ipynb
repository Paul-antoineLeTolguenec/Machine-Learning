{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZiULAOAv6AZ"
   },
   "source": [
    "# Machine Learning Programming Exercise 6: <ins>Supervised classification</ins>\n",
    "\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "\n",
    "Nous allons dans ce TP classer automatiquement des patchs extraits d'images sonar (cf. figure ci-dessous) en types de fond marin (roches, sables, vases, rides de sable verticales et à 45°, [Posidonie](https://fr.wikipedia.org/wiki/Posidonia_oceanica)).\n",
    "\n",
    "Quelques exemples de patchs d'image sonar de fond marin:\n",
    "<img src=\"imgs/screenshot001.png\" />\n",
    "\n",
    "\n",
    "L'objectif est d'écrire des scripts permettant de mettre en \\oe uvre un système basé sur différentes approches supervisées de machine learning. Ces scripts devront ainsi suivre la chaîne générale décrite en cours (à l'exception de la phase de captation; cf. figure ci-dessous ) :\n",
    "* prétraitements\n",
    "* extraction des descripteurs\n",
    "* apprentissage d'un modèle de classement\n",
    "* classement des pixels\n",
    "* évaluation du classifieur appris\n",
    "\n",
    "<img src=\"imgs/screenshot002.png\" />\n",
    "\n",
    "Le TP est globalement organisé de la manière suivante\n",
    "* **Données**\n",
    " 1. tout d'abord apprendre les modèles de classement (classifieurs) sur les données brutes (descripteurs=features=valeurs des pixels) \n",
    " 2. puis dans un second temps sur des descripteurs extraits à partir d'un algorithme appelé [scattering operator](https://www.di.ens.fr/data/scattering) (le fonctionnement exact n'est pas au programme mais il s'apparente à une banque de filtres mise en cascade). \n",
    "\n",
    "* **Prétraitements** Aucun prétraitement ne sera réalisé. \n",
    "\n",
    "* **Ensembles de données**\n",
    " 1. Les ensembles de données seront composés de 1/3 de la base totale d'images. \n",
    " 2. Dans un second temps, nous procéderons par [validation croisée](https://scikit-learn.org/stable/modules/cross_validation.html) car la base d'images est de taille réduite.\n",
    "* **Algorithmes** \n",
    "    Concernant les algorithmes supervisés de machine learning, l'objectif est d'utiliser les deux algorithmes de regression logistique et de réseaux de neurones que vous avez développés aux TP précédents et de découvrir le package python [scikit-learn](http://scikit-learn.org/stable/user_guide.html) qui vous permettra d'utiliser les algorithmes de [régression logistique](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), [réseaux de neurones](https://scikit-learn.org/stable/modules/neural_networks_supervised.html), [random forests](https://scikit-learn.org/stable/modules/ensemble.html#forest) et [svm](https://scikit-learn.org/stable/modules/svm.html#svm-classification).\n",
    "\n",
    "* Pour commencer avec cette séance, vous aurez besoin de **télécharger** le _starter code_  disponible sur le lien Moodle du cours.\n",
    "\n",
    "<span style='color:red'>**Dans cet exercice, il vous est demandé de fournir un rapport regroupant les réponses aux questions, vos analyses et vos codes. Ce rapport pourra prendre la forme d'un pdf ou d'un jupyter notebook. Il est de plus conseillé de faire tourner les codes sur google colab si votre machine manque de puissance (dans ce cas un jupyter notebook est nécessaire).**</span>\n",
    "\n",
    "\n",
    "## Fichiers inclus dans le starter code pour cette séance\n",
    "* **pythonTools.py** - fonctions utiles pour l'affichage, le chargement des données et l'évaluation des performances\n",
    "* **usefulCmds.py** - quelques commandes pour faciliter l'import des patchs\n",
    "* **dataSet** - répertoire avec les images et les labels correspondants\n",
    "* **dataSet\\imdb_200x200_SmallSonarTex_db_6classes_scatValOnly.mat** - fichier matlab contenant les descripteurs extraits des images par le scattering operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-Y6TWZBv6Ab"
   },
   "source": [
    "# Part 0: intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsF0iPYhv6Ae"
   },
   "source": [
    "## 0.1 imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9vExjoNv6Af"
   },
   "source": [
    "_Your commented code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "vQhXCVuAv6Ag",
    "outputId": "e52b044d-8b30-4414-9a24-3a1bab9807f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from pythonTools import *\n",
    "from usefulCmds import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEAis_r1v6Ar"
   },
   "source": [
    "## 0.2 Examen des données\n",
    "\n",
    "Écrire des lignes de code permettant:\n",
    "* de charger les données comprises dans le fichier _labels.csv_,\n",
    "* de mettre en matrice les descripteurs de l'ensemble de la base d'images\n",
    "* d'afficher les images avec la fonction _plot\\_batch()_ du fichier \\_pythonTools.py_,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5dDA5Kiv6Ar"
   },
   "source": [
    "_Your commented code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "xGqVIrCxv6At",
    "outputId": "d4af001f-86e6-4ebf-d9f5-72269c8ec4fe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------Data information--------------------------------------------\n",
      "Dimensions du dataset: (360, 2)\n",
      "['Posidonia', 'Ripple 45°', 'Rock', 'Sand', 'Silt', 'Ripple vertical']\n",
      "                 id  seafloor\n",
      "seafloor                     \n",
      "Posidonia        60         1\n",
      "Ripple 45°       60         1\n",
      "Ripple vertical  60         1\n",
      "Rock             60         1\n",
      "Sand             60         1\n",
      "Silt             60         1\n",
      "----------------------------------------Batch--------------------------------------------\n",
      "                            id    seafloor\n",
      "115  Ripple 45°_Sure.00125.png  Ripple 45°\n",
      "47    Posidonia_Sure.00146.png   Posidonia\n",
      "66   Ripple 45°_Sure.00018.png  Ripple 45°\n",
      "191        Sand_Sure.00041.png        Sand\n",
      "63   Ripple 45°_Sure.00013.png  Ripple 45°\n"
     ]
    }
   ],
   "source": [
    "# Charger le fichier CSV\n",
    "DATASET_PATH = r'./dataset/imgs/'\n",
    "LABEL_PATH = r'./dataset/labels/labels.csv'\n",
    "dataset_df = pd.read_csv(LABEL_PATH)\n",
    "\n",
    "\n",
    "print(\"----------------------------------------Data information--------------------------------------------\")\n",
    "#print nombre de données\n",
    "print(\"Dimensions du dataset:\",dataset_df.shape)\n",
    "\n",
    "#Nombre de classes:\n",
    "print(pd.unique(dataset_df['seafloor']).tolist())\n",
    "#Nombre d'images par classes\n",
    "print(dataset_df.groupby('seafloor').nunique())\n",
    "\n",
    "#Ploting batch\n",
    "print(\"----------------------------------------Batch--------------------------------------------\")\n",
    "#getting 5 random data\n",
    "batch=load_batch(dataset_df,5)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbI5IPb4v6Az"
   },
   "source": [
    "**Question: Quels sont le nombre de données et le nombre de descripteurs?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ2JIo5Jv6A0"
   },
   "source": [
    "Il y a 360 données. C'est données sont réparties en 6 classes. \n",
    "Il y a 60 images par classes.\n",
    "\n",
    "Il y a 40000 descipteurs par images.(voir plus bas)\n",
    "\n",
    "Posidonia        60         \n",
    "Ripple 45°       60         \n",
    "Ripple vertical  60         \n",
    "Rock             60     \n",
    "Sand             60       \n",
    "Silt             60         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add another column to the labels dataset to identify image path\n",
    "dataset_df['image_path'] = dataset_df.apply( lambda row: (DATASET_PATH + row[\"id\"] ), axis=1)\n",
    "\n",
    "# Chargement des images\n",
    "feature_values = np.array([plt.imread(img).reshape(40000,) for img in dataset_df['image_path'].values.tolist()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCk7ykINv6A1"
   },
   "source": [
    "## 0.3 prétraitements des labels\n",
    "\n",
    "Écrire des lignes de code, un script ou une fonction _preprocessing()_ permettant:\n",
    "* de disposer des labels dans différents [codages](https://scikit-learn.org/stable/modules/preprocessing_targets.html) (noms, indices, one-hot-encoding, etc.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1GzYnP5v6A3"
   },
   "source": [
    "_Your commented code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "CW41N-eHv6A3",
    "outputId": "19c1a8ec-d25b-4525-d245-c3b35983b52b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Récupération des labels\n",
    "label_names = dataset_df['seafloor']\n",
    "label_names_unique = label_names.unique()\n",
    "\n",
    "#  transformation des labels selon différents codages\n",
    "# indices\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(label_names_unique)\n",
    "label_indices = le.transform(label_names_unique)\n",
    "\n",
    "# one-hot-encoding\n",
    "label_ohe = pd.get_dummies(label_names.reset_index(drop=True)).values\n",
    "\n",
    "# Getting labels for our dataset\n",
    "y = le.transform(label_names)\n",
    "#y = to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tu9u9Oqv6A8"
   },
   "source": [
    "## 0.4 Séparation des données en ensembles \n",
    "\n",
    "Écrire des lignes de code, un script ou une fonction _preprocessing()_ permettant:\n",
    "* de [normaliser](https://scikit-learn.org/stable/modules/preprocessing.html) les données si besoin \n",
    "* de [créer deux ensembles](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) un pour l'apprentissage et un pour le test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1p9-v4cv6A9"
   },
   "source": [
    "_Your commented code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "xjAfwumev6A-",
    "outputId": "2337cfe2-b29f-4769-d502-7ef858fc7505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 40000) (270,) (90, 40000) (90,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_values, y, test_size = 0.25, random_state = 0)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcDIy1Nmv6BD"
   },
   "source": [
    "<strong>Question:</strong> Pour <ins>chaque ensemble de données</ins> et <ins>pour chaque classe</ins>, quels sont le nombre de données et le nombre de descripteurs? Est-ce important? Pourquoi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nCFuRy2v6BE"
   },
   "source": [
    "Il y a 75 pourcents des données dans Xtrain et 25 pourcents des données dans Xtest.\n",
    "\n",
    "X_train= 270 examples\n",
    "\n",
    "X_test= 90 examples\n",
    "\n",
    "Pour chaques images il y a 40000 descripteurs (200*200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1p9-v4cv6A9"
   },
   "source": [
    "_Your commented code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "xjAfwumev6A-",
    "outputId": "2337cfe2-b29f-4769-d502-7ef858fc7505"
   },
   "outputs": [],
   "source": [
    "#Lets create a validation set\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "#print(X_train.shape, y_train.shape, X_test.shape, y_test.shape,X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6nioyvrv6BE"
   },
   "source": [
    "# Part 1 approches supervisées sur données brutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtkGMAtqv6BF"
   },
   "source": [
    "<strong><ins>Question</ins>: Y-a-t-il besoin de normaliser les descripteurs? Si oui, que faut-il conserver comme information et pourquoi?</strong> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbFeb9jAv6BG"
   },
   "source": [
    "Il est necessaire de normaliser les descripteurs. En effet de cette façon le modèle converge plus rapidement.On associe à chaque descripteurs la même importance dans la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "#X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01PQN1yev6Bl"
   },
   "source": [
    "**<ins>Question</ins>: Nous allons apprendre les modèles suivants:\n",
    "* régression logistique régularisée et réseaux de neurones développés dans les tps précédents,\n",
    "* régression logistique, réseaux de neurones (solver=lbfgs), svm et random forest en utilisant les fonctions du package scikit-learn\n",
    "\n",
    "Faire la liste des hyper-paramètres (paramètre uniquement lié à l'algorithme d'apprentissage) de chaque algorithme. Comment fixe-t-on leurs valeurs?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxHG8upGv6BO"
   },
   "source": [
    "# Pour la regression logistique regularisée les hyper-paramètres du modèle sont :\n",
    "\n",
    "-le taux d'apprendtissage\n",
    "\n",
    "-le paramètre de régularisation\n",
    "\n",
    "# Pour le réseau de neurones:\n",
    "\n",
    "-le taux d'apprentissage\n",
    "\n",
    "-le nombre d'hidden layer\n",
    "\n",
    "# Pour le random forest:\n",
    "\n",
    "-la pronfondeur des arbres\n",
    "\n",
    "-le nombre d'arbres dans la forêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE40sCAMv6BG"
   },
   "source": [
    "<strong><ins>Question</ins>: Fixez au mieux les valeurs des hyperparamètres, réalisez l'apprentissage des modèles suivants: \n",
    "* régression logistique régularisée et réseaux de neurones développés dans les tps précédents,\n",
    "* régression logistique, réseaux de neurones, svm et random forest en utilisant les fonctions du package scikit-learn\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRvvdn-Ev6BH"
   },
   "source": [
    "_Your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------REGRESSION LOGISTIQUE REGULARISEE---------------------\n",
    "from linearRegCostFunction import linearRegCostFunction\n",
    "from trainLinearReg import trainLinearReg\n",
    "from learningCurve import learningCurve\n",
    "from polyFeatures import polyFeatures\n",
    "from featureNormalize import featureNormalize\n",
    "from plotFit import plotFit\n",
    "from validationCurve import validationCurve\n",
    "#-------------------NEURAL NETWORK-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 14.5968 - accuracy: 0.2361\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.9842 - accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6994 - accuracy: 0.6111\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.0622 - accuracy: 0.6296\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.0589 - accuracy: 0.8102\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.1686 - accuracy: 0.8380\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6495 - accuracy: 0.8889\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.9352\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3722 - accuracy: 0.9583\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1793 - accuracy: 0.9444\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.9676\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0252 - accuracy: 0.8981\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.9491\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1650 - accuracy: 0.9815\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9907\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.9954\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3714e-04 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.6374e-04 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.9954\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0465e-04 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2735e-04 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4147e-04 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8496e-04 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9575e-04 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3898e-04 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1690e-04 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.2441e-05 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.0610e-05 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.9723e-05 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.0956e-05 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.5502e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1601e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.8807e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.6846e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4883e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.3263e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.1711e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0654e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.9341e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.8435e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7370e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6448e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.5530e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4798e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.3938e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3195e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.2422e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.1704e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.0997e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.0348e-05 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9752e-05 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9121e-05 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8557e-05 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8085e-05 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7500e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6942e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6497e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6078e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5576e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5097e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4721e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4299e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3913e-05 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3367e-05 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3006e-05 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2585e-05 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2161e-05 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1766e-05 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1338e-05 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1008e-05 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0645e-05 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0304e-05 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0008e-05 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9694e-05 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9461e-05 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9120e-05 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8881e-05 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8669e-05 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8405e-05 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8144e-05 - accuracy: 1.0000\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7875e-05 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7657e-05 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7415e-05 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7324e-05 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6971e-05 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6835e-05 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6637e-05 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6434e-05 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6236e-05 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6028e-05 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5840e-05 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5626e-05 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5417e-05 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5250e-05 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5155e-05 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4972e-05 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4751e-05 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4716e-05 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4634e-05 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4497e-05 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4318e-05 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4145e-05 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3911e-05 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3739e-05 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3574e-05 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3433e-05 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3308e-05 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3154e-05 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3026e-05 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2927e-05 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2792e-05 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2676e-05 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2533e-05 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2413e-05 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2303e-05 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2207e-05 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2090e-05 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1980e-05 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1878e-05 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1767e-05 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1658e-05 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1527e-05 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1453e-05 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1336e-05 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1214e-05 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1096e-05 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0979e-05 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0894e-05 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0790e-05 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0694e-05 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0597e-05 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0503e-05 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0424e-05 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0335e-05 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0256e-05 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0203e-05 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0142e-05 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0056e-05 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.9717e-06 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.8646e-06 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.7598e-06 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.6704e-06 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.6042e-06 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5049e-06 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.4237e-06 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.3454e-06 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.2549e-06 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1980e-06 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1175e-06 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd916eb26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1229 - accuracy: 0.2685\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3389 - accuracy: 0.4444\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1190 - accuracy: 0.5741\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6381 - accuracy: 0.6574\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0752 - accuracy: 0.8056\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0140 - accuracy: 0.8750\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2059 - accuracy: 0.8657\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2505 - accuracy: 0.9074\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5587 - accuracy: 0.9259\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2029 - accuracy: 0.9676\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.9676\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2223 - accuracy: 0.9676\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2520 - accuracy: 0.9815\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4866e-04 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6955e-04 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3591e-04 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7935e-04 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5291e-04 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2738e-04 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0702e-04 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.4940e-05 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0755e-05 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2801e-05 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3627e-05 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8864e-05 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6326e-05 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3553e-05 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1588e-05 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9838e-05 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.8538e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7026e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6034e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4900e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3944e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3118e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2070e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1294e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0617e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9800e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9148e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8462e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7827e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7301e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6704e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6168e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5662e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5159e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4591e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4111e-05 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3660e-05 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3308e-05 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2810e-05 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2360e-05 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2021e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1598e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1270e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0915e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0577e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0282e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9959e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9602e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9276e-05 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8973e-05 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8677e-05 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8413e-05 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8180e-05 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7929e-05 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7692e-05 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7418e-05 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7202e-05 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6980e-05 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6744e-05 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6546e-05 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6322e-05 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6088e-05 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5888e-05 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5687e-05 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5510e-05 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5283e-05 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5110e-05 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4901e-05 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4687e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4506e-05 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4347e-05 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4166e-05 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4017e-05 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3838e-05 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3681e-05 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3522e-05 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3383e-05 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3236e-05 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3063e-05 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2937e-05 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2784e-05 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2650e-05 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2506e-05 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2370e-05 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2257e-05 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2121e-05 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1991e-05 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1862e-05 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1745e-05 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1619e-05 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1507e-05 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1389e-05 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1248e-05 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1134e-05 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1021e-05 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0895e-05 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0794e-05 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0671e-05 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0570e-05 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0454e-05 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0357e-05 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0253e-05 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0155e-05 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0058e-05 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.9712e-06 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.8773e-06 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.7863e-06 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.6991e-06 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.6058e-06 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5192e-06 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.4287e-06 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.3382e-06 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.2444e-06 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.1577e-06 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.0761e-06 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.0027e-06 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.9171e-06 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.8404e-06 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.7615e-06 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.6931e-06 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.6258e-06 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5513e-06 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.4834e-06 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.4177e-06 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3410e-06 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2753e-06 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2108e-06 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1418e-06 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.0717e-06 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.0209e-06 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9459e-06 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.8774e-06 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.8101e-06 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7467e-06 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6893e-06 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd91504d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.4553 - accuracy: 0.2685\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.3995 - accuracy: 0.5093\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2479 - accuracy: 0.7500\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0664 - accuracy: 0.8426\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8888 - accuracy: 0.7269\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6846 - accuracy: 0.8380\n",
      "Epoch 7/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2265 - accuracy: 0.8426\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1069 - accuracy: 0.9028\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9917 - accuracy: 0.9306\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.9583\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9907\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9954\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9907\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0593 - accuracy: 0.9861\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.9907\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9907\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9954\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9907\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9583\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9907\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0164e-05 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9954\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9954\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9954\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0386e-05 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8865e-05 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9954\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4516e-05 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2861e-04 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0049e-04 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0070e-04 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2948e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6019e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7916e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1108e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7742e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5363e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3854e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2533e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1478e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0747e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9867e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9175e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8499e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8076e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7416e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6889e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6377e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5971e-05 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5537e-05 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5171e-05 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4777e-05 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4390e-05 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4140e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3867e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3566e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3351e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3070e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2841e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2629e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2444e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2260e-05 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2099e-05 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1922e-05 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1741e-05 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1595e-05 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1434e-05 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1263e-05 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1109e-05 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0957e-05 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0798e-05 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0642e-05 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0509e-05 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0362e-05 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0213e-05 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0084e-05 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.9363e-06 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.8016e-06 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.6653e-06 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5412e-06 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.4347e-06 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.3204e-06 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.2266e-06 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.1223e-06 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.0373e-06 - accuracy: 1.0000\n",
      "Epoch 88/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 8.9380e-06 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.8387e-06 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.7454e-06 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.6566e-06 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5749e-06 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.4860e-06 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3900e-06 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3194e-06 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2383e-06 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1522e-06 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.0733e-06 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9872e-06 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9160e-06 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.8205e-06 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.7427e-06 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6605e-06 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5992e-06 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5087e-06 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.4414e-06 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3763e-06 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3056e-06 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2394e-06 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.1876e-06 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.1280e-06 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0650e-06 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0104e-06 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9492e-06 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8807e-06 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8355e-06 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7637e-06 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7080e-06 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6489e-06 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.5960e-06 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.5397e-06 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.4928e-06 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4315e-06 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3835e-06 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.3217e-06 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2781e-06 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2312e-06 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1777e-06 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1412e-06 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0916e-06 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0463e-06 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0044e-06 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9564e-06 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9122e-06 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8620e-06 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8162e-06 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7743e-06 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7273e-06 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6838e-06 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6435e-06 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5982e-06 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5646e-06 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5149e-06 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4774e-06 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4426e-06 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3973e-06 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3598e-06 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3250e-06 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2853e-06 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2483e-06 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd9003a4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.7385 - accuracy: 0.2176\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.5566 - accuracy: 0.4722\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7838 - accuracy: 0.5602\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8809 - accuracy: 0.6806\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9139 - accuracy: 0.7824\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9690 - accuracy: 0.8148\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7802 - accuracy: 0.8981\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0631 - accuracy: 0.8657\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1385 - accuracy: 0.8657\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7762 - accuracy: 0.8935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7109 - accuracy: 0.8472\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.9306\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.9769\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2119 - accuracy: 0.9491\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9861\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.9907\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3556e-04 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6885e-04 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1347e-04 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6967e-04 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4035e-04 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2420e-04 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1057e-04 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0235e-04 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5122e-05 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.9599e-05 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.4377e-05 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.0353e-05 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6251e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3921e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7.0992e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.8217e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 6.5883e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.3491e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.1022e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.9361e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7149e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5041e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3510e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1996e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0715e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9253e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7863e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6789e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5485e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4314e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3392e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2212e-05 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1292e-05 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0230e-05 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.9297e-05 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8473e-05 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7348e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6441e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5671e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4944e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4247e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3544e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2969e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2386e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.1861e-05 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1291e-05 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0730e-05 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0267e-05 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9671e-05 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9137e-05 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8664e-05 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.8231e-05 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7617e-05 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7212e-05 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6672e-05 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6246e-05 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.5789e-05 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.5433e-05 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4990e-05 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4634e-05 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4326e-05 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3975e-05 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3629e-05 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3259e-05 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2978e-05 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2601e-05 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2305e-05 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1996e-05 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1716e-05 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1376e-05 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.1077e-05 - accuracy: 1.0000\n",
      "Epoch 91/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0724e-05 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0446e-05 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0125e-05 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9833e-05 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9560e-05 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9279e-05 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9032e-05 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8796e-05 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8562e-05 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8322e-05 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8084e-05 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7858e-05 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7659e-05 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7406e-05 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7207e-05 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7008e-05 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6802e-05 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6606e-05 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6377e-05 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6188e-05 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5974e-05 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5759e-05 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5585e-05 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5430e-05 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5235e-05 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5066e-05 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4866e-05 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4691e-05 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4525e-05 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4332e-05 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4184e-05 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3991e-05 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3854e-05 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3676e-05 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3546e-05 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3402e-05 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3252e-05 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3122e-05 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2994e-05 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2847e-05 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2715e-05 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2573e-05 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2443e-05 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2330e-05 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2197e-05 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2054e-05 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1888e-05 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1748e-05 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1586e-05 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1435e-05 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1298e-05 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1183e-05 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1064e-05 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0936e-05 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0821e-05 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0710e-05 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0610e-05 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0481e-05 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0376e-05 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0262e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd9145dd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.9355 - accuracy: 0.2454\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3441 - accuracy: 0.5185\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2430 - accuracy: 0.7130\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.7542 - accuracy: 0.6898\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8618 - accuracy: 0.8241\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0242 - accuracy: 0.8333\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.9213\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7065 - accuracy: 0.9120\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0507 - accuracy: 0.8889\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5032 - accuracy: 0.9444\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9861\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2002 - accuracy: 0.9815\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 6.1568e-04 - accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9954\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9907\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9954\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5651e-05 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9289e-05 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3458e-05 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0591e-05 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8918e-05 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7630e-05 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6492e-05 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5474e-05 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4473e-05 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3612e-05 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2692e-05 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1894e-05 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1131e-05 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0442e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9779e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9156e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8687e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8096e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7643e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7161e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6711e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6307e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5821e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5492e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5142e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4817e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4466e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4160e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3891e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3569e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3288e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2983e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2752e-05 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2493e-05 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2286e-05 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2063e-05 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1832e-05 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1643e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1469e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1273e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1110e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0954e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0776e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0637e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0488e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0321e-05 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0170e-05 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0019e-05 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.8773e-06 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.7443e-06 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.6118e-06 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.4722e-06 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.3331e-06 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.2057e-06 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.1047e-06 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.9667e-06 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.8437e-06 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.7339e-06 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.6240e-06 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5208e-06 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.4088e-06 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.3040e-06 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1986e-06 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1070e-06 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.0093e-06 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9160e-06 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.8184e-06 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.7372e-06 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6572e-06 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5645e-06 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.4911e-06 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3989e-06 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3244e-06 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2472e-06 - accuracy: 1.0000\n",
      "Epoch 93/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 7.1655e-06 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0993e-06 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0275e-06 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9370e-06 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8697e-06 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8002e-06 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7262e-06 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6639e-06 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.5999e-06 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.5381e-06 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4746e-06 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4255e-06 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3675e-06 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3079e-06 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2550e-06 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1898e-06 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1352e-06 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0806e-06 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0182e-06 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9680e-06 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.9194e-06 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8631e-06 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8140e-06 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7632e-06 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7081e-06 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6645e-06 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6109e-06 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5607e-06 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5149e-06 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4708e-06 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4272e-06 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3841e-06 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3460e-06 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3030e-06 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2660e-06 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2186e-06 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1854e-06 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1341e-06 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0999e-06 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0513e-06 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0149e-06 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9735e-06 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9377e-06 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9001e-06 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8632e-06 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8262e-06 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7887e-06 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7533e-06 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7153e-06 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6860e-06 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6496e-06 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6165e-06 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5850e-06 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5514e-06 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5182e-06 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4846e-06 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4498e-06 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4128e-06 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd9146f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.2508 - accuracy: 0.2667\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 10.5028 - accuracy: 0.4556\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6395 - accuracy: 0.6370\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3322 - accuracy: 0.7741\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5731 - accuracy: 0.7889\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7683 - accuracy: 0.7889\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3112 - accuracy: 0.8889\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7324 - accuracy: 0.9222\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3081 - accuracy: 0.9556\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7596 - accuracy: 0.9296\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2861 - accuracy: 0.9593\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3602 - accuracy: 0.9741\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1830 - accuracy: 0.9593\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4962 - accuracy: 0.9778\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.9778\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1213 - accuracy: 0.9741\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1382 - accuracy: 0.9815\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0776 - accuracy: 0.9704\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9926\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9963\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9963\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8489e-04 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1112e-04 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3997e-04 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6119e-04 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9597e-04 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5087e-04 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2376e-04 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0970e-04 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.8120e-05 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.0676e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.4862e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.0654e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.6516e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.2772e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0251e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.7243e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.5014e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.2709e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.0711e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.8580e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.6944e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.5300e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.3519e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1891e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.0744e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9317e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.8107e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.6760e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5628e-05 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.4707e-05 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.3623e-05 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.2708e-05 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1802e-05 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.0817e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9964e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.9111e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8439e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7649e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6836e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6176e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5453e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4847e-05 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4244e-05 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3606e-05 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3047e-05 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2453e-05 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1935e-05 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1475e-05 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0985e-05 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0436e-05 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0022e-05 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9575e-05 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9131e-05 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8744e-05 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8275e-05 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7914e-05 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7484e-05 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7093e-05 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6757e-05 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6384e-05 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6017e-05 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5709e-05 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5386e-05 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4996e-05 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4702e-05 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4331e-05 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4091e-05 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3780e-05 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3479e-05 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3193e-05 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2897e-05 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2642e-05 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2372e-05 - accuracy: 1.0000\n",
      "Epoch 96/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2157e-05 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1905e-05 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1616e-05 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1401e-05 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1164e-05 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0916e-05 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.0693e-05 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0478e-05 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.0226e-05 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.0023e-05 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9815e-05 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9574e-05 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9377e-05 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9171e-05 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8958e-05 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8771e-05 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8560e-05 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8395e-05 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8213e-05 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8058e-05 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.7921e-05 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7736e-05 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7599e-05 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7432e-05 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7274e-05 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7132e-05 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6974e-05 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6831e-05 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6670e-05 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6539e-05 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6393e-05 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6258e-05 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6116e-05 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5992e-05 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5846e-05 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5722e-05 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5613e-05 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5473e-05 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5337e-05 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5225e-05 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5094e-05 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4968e-05 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4856e-05 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4744e-05 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4628e-05 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4515e-05 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4418e-05 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4302e-05 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4189e-05 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4074e-05 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3976e-05 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3854e-05 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3757e-05 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3658e-05 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3556e-05 - accuracy: 1.0000\n",
      "0.4185185185185185 {'batch_size': 50, 'epochs': 150, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd916f3c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "#-------------------NEURAL NETWORK WITH SCIKIT LEARN AND TENSORFLOW---------------------\n",
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#Fonction de construction du CNN\n",
    "def build_classifier(optimizer='adam'):\n",
    "    # Initialising the CNN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Step 4 - Full connection\n",
    "    classifier.add(Dense(units = 128, activation = 'relu',input_dim = 40000))\n",
    "    classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "    #classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "    classifier.add(Dense(units = 6, activation = 'softmax'))\n",
    "\n",
    "    # Compiling the CNN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "#Instance du classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "\n",
    "#Liste de paramétres à tester lors de l'entraînement.\n",
    "parameters = {'batch_size': [50],\n",
    "              'epochs': [150],\n",
    "              'optimizer': ['adam']}\n",
    "#Création de la grille d'entraînement.\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5)\n",
    "#On entraîne avec les différents paramètres spécipfiés dans la liste.\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "#On évalue le score et les meilleurs paramétres\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(best_accuracy,best_parameters)\n",
    "score = grid_search.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1.9770 - accuracy: 0.2000 - val_loss: 1.9352 - val_accuracy: 0.2778\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.7927 - accuracy: 0.3111 - val_loss: 1.8414 - val_accuracy: 0.3556\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7048 - accuracy: 0.3556 - val_loss: 1.8220 - val_accuracy: 0.3778\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.6538 - accuracy: 0.3704 - val_loss: 1.8104 - val_accuracy: 0.3889\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6041 - accuracy: 0.4074 - val_loss: 1.8030 - val_accuracy: 0.3889\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.5546 - accuracy: 0.4296 - val_loss: 1.8055 - val_accuracy: 0.3889\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.5114 - accuracy: 0.4444 - val_loss: 1.8063 - val_accuracy: 0.3889\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.4690 - accuracy: 0.4481 - val_loss: 1.8036 - val_accuracy: 0.3889\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4272 - accuracy: 0.4556 - val_loss: 1.7963 - val_accuracy: 0.3889\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.3899 - accuracy: 0.4889 - val_loss: 1.7932 - val_accuracy: 0.3889\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.3533 - accuracy: 0.5000 - val_loss: 1.7919 - val_accuracy: 0.4000\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3157 - accuracy: 0.5074 - val_loss: 1.7904 - val_accuracy: 0.4000\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.2802 - accuracy: 0.5222 - val_loss: 1.7890 - val_accuracy: 0.4000\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.2458 - accuracy: 0.5370 - val_loss: 1.7841 - val_accuracy: 0.4000\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2150 - accuracy: 0.5630 - val_loss: 1.7803 - val_accuracy: 0.4000\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.1819 - accuracy: 0.5741 - val_loss: 1.7776 - val_accuracy: 0.4000\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1528 - accuracy: 0.5889 - val_loss: 1.7750 - val_accuracy: 0.3889\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1229 - accuracy: 0.6037 - val_loss: 1.7735 - val_accuracy: 0.3889\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0949 - accuracy: 0.6296 - val_loss: 1.7779 - val_accuracy: 0.3889\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0675 - accuracy: 0.6296 - val_loss: 1.7730 - val_accuracy: 0.3889\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0401 - accuracy: 0.6407 - val_loss: 1.7737 - val_accuracy: 0.3889\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0131 - accuracy: 0.6556 - val_loss: 1.7686 - val_accuracy: 0.3778\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9884 - accuracy: 0.6704 - val_loss: 1.7649 - val_accuracy: 0.3778\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9639 - accuracy: 0.6889 - val_loss: 1.7608 - val_accuracy: 0.3778\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9401 - accuracy: 0.6926 - val_loss: 1.7613 - val_accuracy: 0.3778\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9186 - accuracy: 0.7111 - val_loss: 1.7566 - val_accuracy: 0.3778\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8941 - accuracy: 0.7222 - val_loss: 1.7560 - val_accuracy: 0.3778\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8728 - accuracy: 0.7370 - val_loss: 1.7549 - val_accuracy: 0.3889\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8516 - accuracy: 0.7630 - val_loss: 1.7545 - val_accuracy: 0.3778\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8317 - accuracy: 0.7852 - val_loss: 1.7546 - val_accuracy: 0.3889\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8116 - accuracy: 0.7926 - val_loss: 1.7505 - val_accuracy: 0.3778\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7933 - accuracy: 0.8111 - val_loss: 1.7509 - val_accuracy: 0.3889\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7752 - accuracy: 0.8148 - val_loss: 1.7492 - val_accuracy: 0.3889\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7567 - accuracy: 0.8296 - val_loss: 1.7444 - val_accuracy: 0.3889\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7402 - accuracy: 0.8481 - val_loss: 1.7432 - val_accuracy: 0.3889\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7248 - accuracy: 0.8519 - val_loss: 1.7423 - val_accuracy: 0.4000\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7072 - accuracy: 0.8556 - val_loss: 1.7363 - val_accuracy: 0.3889\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6916 - accuracy: 0.8741 - val_loss: 1.7351 - val_accuracy: 0.3889\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6776 - accuracy: 0.8704 - val_loss: 1.7343 - val_accuracy: 0.4000\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.8852 - val_loss: 1.7301 - val_accuracy: 0.3889\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6495 - accuracy: 0.8926 - val_loss: 1.7326 - val_accuracy: 0.4000\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6354 - accuracy: 0.8963 - val_loss: 1.7360 - val_accuracy: 0.4000\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6215 - accuracy: 0.9037 - val_loss: 1.7352 - val_accuracy: 0.4000\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6087 - accuracy: 0.9074 - val_loss: 1.7315 - val_accuracy: 0.4000\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5963 - accuracy: 0.9111 - val_loss: 1.7279 - val_accuracy: 0.4000\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5844 - accuracy: 0.9185 - val_loss: 1.7270 - val_accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5728 - accuracy: 0.9185 - val_loss: 1.7245 - val_accuracy: 0.4000\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5612 - accuracy: 0.9222 - val_loss: 1.7265 - val_accuracy: 0.3889\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5510 - accuracy: 0.9222 - val_loss: 1.7263 - val_accuracy: 0.3889\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5392 - accuracy: 0.9259 - val_loss: 1.7291 - val_accuracy: 0.4000\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.9333 - val_loss: 1.7276 - val_accuracy: 0.4000\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5199 - accuracy: 0.9407 - val_loss: 1.7289 - val_accuracy: 0.4000\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5091 - accuracy: 0.9444 - val_loss: 1.7199 - val_accuracy: 0.4000\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5004 - accuracy: 0.9481 - val_loss: 1.7168 - val_accuracy: 0.4111\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4905 - accuracy: 0.9481 - val_loss: 1.7213 - val_accuracy: 0.4000\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4818 - accuracy: 0.9481 - val_loss: 1.7259 - val_accuracy: 0.4000\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.9481 - val_loss: 1.7273 - val_accuracy: 0.4111\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4653 - accuracy: 0.9519 - val_loss: 1.7278 - val_accuracy: 0.4000\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.9556 - val_loss: 1.7247 - val_accuracy: 0.4222\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4487 - accuracy: 0.9556 - val_loss: 1.7208 - val_accuracy: 0.4000\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4410 - accuracy: 0.9556 - val_loss: 1.7190 - val_accuracy: 0.4111\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.9556 - val_loss: 1.7192 - val_accuracy: 0.4111\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.9556 - val_loss: 1.7228 - val_accuracy: 0.4222\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4181 - accuracy: 0.9593 - val_loss: 1.7245 - val_accuracy: 0.4222\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.9593 - val_loss: 1.7282 - val_accuracy: 0.4222\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4041 - accuracy: 0.9593 - val_loss: 1.7255 - val_accuracy: 0.4222\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3978 - accuracy: 0.9593 - val_loss: 1.7260 - val_accuracy: 0.4222\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.9593 - val_loss: 1.7294 - val_accuracy: 0.4333\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3847 - accuracy: 0.9593 - val_loss: 1.7229 - val_accuracy: 0.4333\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3777 - accuracy: 0.9667 - val_loss: 1.7171 - val_accuracy: 0.4222\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3717 - accuracy: 0.9667 - val_loss: 1.7192 - val_accuracy: 0.4111\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3661 - accuracy: 0.9630 - val_loss: 1.7226 - val_accuracy: 0.4333\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.9630 - val_loss: 1.7227 - val_accuracy: 0.4333\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3552 - accuracy: 0.9630 - val_loss: 1.7248 - val_accuracy: 0.4333\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3482 - accuracy: 0.9667 - val_loss: 1.7223 - val_accuracy: 0.4333\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3437 - accuracy: 0.9704 - val_loss: 1.7224 - val_accuracy: 0.4333\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.9704 - val_loss: 1.7231 - val_accuracy: 0.4333\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3331 - accuracy: 0.9704 - val_loss: 1.7275 - val_accuracy: 0.4222\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3278 - accuracy: 0.9704 - val_loss: 1.7188 - val_accuracy: 0.4444\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3229 - accuracy: 0.9704 - val_loss: 1.7212 - val_accuracy: 0.4333\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3181 - accuracy: 0.9741 - val_loss: 1.7240 - val_accuracy: 0.4222\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3130 - accuracy: 0.9741 - val_loss: 1.7274 - val_accuracy: 0.4333\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3087 - accuracy: 0.9741 - val_loss: 1.7299 - val_accuracy: 0.4333\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3039 - accuracy: 0.9741 - val_loss: 1.7258 - val_accuracy: 0.4333\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2996 - accuracy: 0.9741 - val_loss: 1.7241 - val_accuracy: 0.4333\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2951 - accuracy: 0.9741 - val_loss: 1.7246 - val_accuracy: 0.4333\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2905 - accuracy: 0.9741 - val_loss: 1.7269 - val_accuracy: 0.4333\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2861 - accuracy: 0.9741 - val_loss: 1.7311 - val_accuracy: 0.4333\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2827 - accuracy: 0.9704 - val_loss: 1.7296 - val_accuracy: 0.4333\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2779 - accuracy: 0.9778 - val_loss: 1.7303 - val_accuracy: 0.4222\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2742 - accuracy: 0.9889 - val_loss: 1.7273 - val_accuracy: 0.4333\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2704 - accuracy: 0.9889 - val_loss: 1.7327 - val_accuracy: 0.4333\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2664 - accuracy: 0.9852 - val_loss: 1.7350 - val_accuracy: 0.4222\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2628 - accuracy: 0.9852 - val_loss: 1.7299 - val_accuracy: 0.4222\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2593 - accuracy: 0.9852 - val_loss: 1.7266 - val_accuracy: 0.4333\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2553 - accuracy: 0.9889 - val_loss: 1.7346 - val_accuracy: 0.4333\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2521 - accuracy: 0.9852 - val_loss: 1.7405 - val_accuracy: 0.4333\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2491 - accuracy: 0.9852 - val_loss: 1.7381 - val_accuracy: 0.4333\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2452 - accuracy: 0.9889 - val_loss: 1.7307 - val_accuracy: 0.4444\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2421 - accuracy: 0.9889 - val_loss: 1.7316 - val_accuracy: 0.4333\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2384 - accuracy: 0.9852 - val_loss: 1.7322 - val_accuracy: 0.4333\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2358 - accuracy: 0.9889 - val_loss: 1.7308 - val_accuracy: 0.4333\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2325 - accuracy: 0.9889 - val_loss: 1.7309 - val_accuracy: 0.4333\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2290 - accuracy: 0.9889 - val_loss: 1.7370 - val_accuracy: 0.4333\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.9889 - val_loss: 1.7386 - val_accuracy: 0.4333\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2231 - accuracy: 0.9889 - val_loss: 1.7424 - val_accuracy: 0.4333\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2202 - accuracy: 0.9889 - val_loss: 1.7445 - val_accuracy: 0.4333\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2176 - accuracy: 0.9889 - val_loss: 1.7417 - val_accuracy: 0.4333\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2147 - accuracy: 0.9889 - val_loss: 1.7407 - val_accuracy: 0.4333\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2126 - accuracy: 0.9889 - val_loss: 1.7352 - val_accuracy: 0.4333\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2093 - accuracy: 0.9926 - val_loss: 1.7355 - val_accuracy: 0.4333\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2071 - accuracy: 0.9926 - val_loss: 1.7393 - val_accuracy: 0.4222\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2046 - accuracy: 0.9889 - val_loss: 1.7367 - val_accuracy: 0.4333\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2016 - accuracy: 0.9926 - val_loss: 1.7440 - val_accuracy: 0.4333\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1993 - accuracy: 0.9889 - val_loss: 1.7485 - val_accuracy: 0.4333\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 0.9926 - val_loss: 1.7471 - val_accuracy: 0.4333\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1941 - accuracy: 0.9926 - val_loss: 1.7482 - val_accuracy: 0.4333\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1920 - accuracy: 0.9926 - val_loss: 1.7473 - val_accuracy: 0.4222\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1901 - accuracy: 0.9926 - val_loss: 1.7499 - val_accuracy: 0.4333\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1873 - accuracy: 0.9926 - val_loss: 1.7468 - val_accuracy: 0.4333\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9926 - val_loss: 1.7498 - val_accuracy: 0.4222\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1830 - accuracy: 0.9926 - val_loss: 1.7551 - val_accuracy: 0.4222\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1805 - accuracy: 0.9926 - val_loss: 1.7527 - val_accuracy: 0.4333\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 0.9926 - val_loss: 1.7464 - val_accuracy: 0.4222\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1764 - accuracy: 0.9926 - val_loss: 1.7492 - val_accuracy: 0.4222\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1746 - accuracy: 0.9926 - val_loss: 1.7574 - val_accuracy: 0.4222\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.9926 - val_loss: 1.7583 - val_accuracy: 0.4222\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1704 - accuracy: 0.9926 - val_loss: 1.7533 - val_accuracy: 0.4222\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1684 - accuracy: 0.9926 - val_loss: 1.7551 - val_accuracy: 0.4222\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1665 - accuracy: 0.9926 - val_loss: 1.7579 - val_accuracy: 0.4222\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1645 - accuracy: 0.9963 - val_loss: 1.7581 - val_accuracy: 0.4222\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1627 - accuracy: 0.9926 - val_loss: 1.7582 - val_accuracy: 0.4222\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1608 - accuracy: 0.9926 - val_loss: 1.7634 - val_accuracy: 0.4222\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9963 - val_loss: 1.7617 - val_accuracy: 0.4222\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1575 - accuracy: 0.9963 - val_loss: 1.7630 - val_accuracy: 0.4222\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1557 - accuracy: 0.9963 - val_loss: 1.7618 - val_accuracy: 0.4222\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1537 - accuracy: 0.9963 - val_loss: 1.7629 - val_accuracy: 0.4222\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.9963 - val_loss: 1.7607 - val_accuracy: 0.4222\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.9963 - val_loss: 1.7722 - val_accuracy: 0.4222\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.9963 - val_loss: 1.7681 - val_accuracy: 0.4222\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.9963 - val_loss: 1.7660 - val_accuracy: 0.4222\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1457 - accuracy: 0.9963 - val_loss: 1.7691 - val_accuracy: 0.4222\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1439 - accuracy: 0.9963 - val_loss: 1.7683 - val_accuracy: 0.4222\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1424 - accuracy: 0.9963 - val_loss: 1.7708 - val_accuracy: 0.4222\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1411 - accuracy: 0.9963 - val_loss: 1.7692 - val_accuracy: 0.4222\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.9963 - val_loss: 1.7665 - val_accuracy: 0.4222\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1381 - accuracy: 1.0000 - val_loss: 1.7696 - val_accuracy: 0.4222\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 1.0000 - val_loss: 1.7692 - val_accuracy: 0.4222\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 1.0000 - val_loss: 1.7737 - val_accuracy: 0.4222\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1338 - accuracy: 1.0000 - val_loss: 1.7691 - val_accuracy: 0.4222\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 1.7727 - val_accuracy: 0.4222\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 1.0000 - val_loss: 1.7813 - val_accuracy: 0.4222\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1295 - accuracy: 1.0000 - val_loss: 1.7803 - val_accuracy: 0.4222\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 1.7779 - val_accuracy: 0.4222\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1270 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.4222\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1256 - accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.4222\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 1.7819 - val_accuracy: 0.4222\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.4222\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 1.7843 - val_accuracy: 0.4222\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.4222\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 1.7844 - val_accuracy: 0.4222\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 1.7829 - val_accuracy: 0.4222\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1169 - accuracy: 1.0000 - val_loss: 1.7889 - val_accuracy: 0.4222\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 1.7936 - val_accuracy: 0.4222\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 1.7989 - val_accuracy: 0.4222\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 1.7960 - val_accuracy: 0.4222\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 1.7949 - val_accuracy: 0.4222\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1111 - accuracy: 1.0000 - val_loss: 1.7925 - val_accuracy: 0.4222\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 1.7945 - val_accuracy: 0.4222\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 1.7997 - val_accuracy: 0.4222\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.4222\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 1.8050 - val_accuracy: 0.4222\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.4222\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 1.8046 - val_accuracy: 0.4222\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 1.7985 - val_accuracy: 0.4222\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.8031 - val_accuracy: 0.4222\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 1.8052 - val_accuracy: 0.4222\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 1.8043 - val_accuracy: 0.4222\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 1.7977 - val_accuracy: 0.4222\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 1.8026 - val_accuracy: 0.4222\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 1.8053 - val_accuracy: 0.4222\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.8095 - val_accuracy: 0.4222\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.4222\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.4222\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 1.8149 - val_accuracy: 0.4222\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.8176 - val_accuracy: 0.4222\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 1.8121 - val_accuracy: 0.4222\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 1.8177 - val_accuracy: 0.4222\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.8226 - val_accuracy: 0.4222\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 1.8183 - val_accuracy: 0.4222\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.8182 - val_accuracy: 0.4222\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.8216 - val_accuracy: 0.4222\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.8244 - val_accuracy: 0.4222\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 1.8264 - val_accuracy: 0.4222\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.4222\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 1.8272 - val_accuracy: 0.4222\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 1.8231 - val_accuracy: 0.4222\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 1.8238 - val_accuracy: 0.4222\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.4222\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 1.8329 - val_accuracy: 0.4222\n",
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2.5479 - accuracy: 0.1148 - val_loss: 2.6850 - val_accuracy: 0.1556\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5023 - accuracy: 0.1185 - val_loss: 2.6361 - val_accuracy: 0.1556\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4608 - accuracy: 0.1259 - val_loss: 2.5901 - val_accuracy: 0.1556\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4203 - accuracy: 0.1259 - val_loss: 2.5475 - val_accuracy: 0.1556\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3839 - accuracy: 0.1333 - val_loss: 2.5075 - val_accuracy: 0.1556\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3481 - accuracy: 0.1370 - val_loss: 2.4712 - val_accuracy: 0.1556\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3171 - accuracy: 0.1481 - val_loss: 2.4347 - val_accuracy: 0.1556\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2849 - accuracy: 0.1519 - val_loss: 2.4014 - val_accuracy: 0.1556\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2559 - accuracy: 0.1593 - val_loss: 2.3695 - val_accuracy: 0.1556\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2268 - accuracy: 0.1741 - val_loss: 2.3401 - val_accuracy: 0.2000\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2012 - accuracy: 0.1815 - val_loss: 2.3120 - val_accuracy: 0.2000\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1766 - accuracy: 0.2000 - val_loss: 2.2862 - val_accuracy: 0.2111\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1530 - accuracy: 0.2148 - val_loss: 2.2621 - val_accuracy: 0.2556\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1315 - accuracy: 0.2222 - val_loss: 2.2378 - val_accuracy: 0.2556\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1104 - accuracy: 0.2296 - val_loss: 2.2148 - val_accuracy: 0.3000\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0895 - accuracy: 0.2407 - val_loss: 2.1939 - val_accuracy: 0.3111\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0712 - accuracy: 0.2370 - val_loss: 2.1747 - val_accuracy: 0.3111\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0530 - accuracy: 0.2481 - val_loss: 2.1563 - val_accuracy: 0.3111\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0359 - accuracy: 0.2667 - val_loss: 2.1388 - val_accuracy: 0.3000\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0199 - accuracy: 0.2704 - val_loss: 2.1224 - val_accuracy: 0.3000\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0039 - accuracy: 0.2778 - val_loss: 2.1076 - val_accuracy: 0.3000\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.9892 - accuracy: 0.2852 - val_loss: 2.0929 - val_accuracy: 0.3000\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9747 - accuracy: 0.2926 - val_loss: 2.0785 - val_accuracy: 0.3000\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9613 - accuracy: 0.2926 - val_loss: 2.0649 - val_accuracy: 0.3000\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.9479 - accuracy: 0.2926 - val_loss: 2.0523 - val_accuracy: 0.3000\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9349 - accuracy: 0.3037 - val_loss: 2.0399 - val_accuracy: 0.3000\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9225 - accuracy: 0.3037 - val_loss: 2.0281 - val_accuracy: 0.3000\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9105 - accuracy: 0.3037 - val_loss: 2.0172 - val_accuracy: 0.3000\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8989 - accuracy: 0.3037 - val_loss: 2.0073 - val_accuracy: 0.3000\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.8878 - accuracy: 0.3074 - val_loss: 1.9965 - val_accuracy: 0.3000\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.8762 - accuracy: 0.3074 - val_loss: 1.9866 - val_accuracy: 0.3111\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.8654 - accuracy: 0.3074 - val_loss: 1.9762 - val_accuracy: 0.3111\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 1.8545 - accuracy: 0.3111 - val_loss: 1.9662 - val_accuracy: 0.3111\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8439 - accuracy: 0.3148 - val_loss: 1.9576 - val_accuracy: 0.3111\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.8342 - accuracy: 0.3148 - val_loss: 1.9482 - val_accuracy: 0.3111\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8243 - accuracy: 0.3148 - val_loss: 1.9397 - val_accuracy: 0.3111\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8145 - accuracy: 0.3111 - val_loss: 1.9312 - val_accuracy: 0.3111\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8051 - accuracy: 0.3111 - val_loss: 1.9240 - val_accuracy: 0.3111\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7965 - accuracy: 0.3111 - val_loss: 1.9162 - val_accuracy: 0.3111\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7875 - accuracy: 0.3111 - val_loss: 1.9084 - val_accuracy: 0.3111\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.7786 - accuracy: 0.3148 - val_loss: 1.9012 - val_accuracy: 0.3111\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7701 - accuracy: 0.3148 - val_loss: 1.8942 - val_accuracy: 0.3000\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.7613 - accuracy: 0.3148 - val_loss: 1.8875 - val_accuracy: 0.3000\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7534 - accuracy: 0.3222 - val_loss: 1.8804 - val_accuracy: 0.3000\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7450 - accuracy: 0.3296 - val_loss: 1.8746 - val_accuracy: 0.3000\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.7373 - accuracy: 0.3296 - val_loss: 1.8685 - val_accuracy: 0.3000\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.7297 - accuracy: 0.3296 - val_loss: 1.8627 - val_accuracy: 0.3000\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7226 - accuracy: 0.3370 - val_loss: 1.8570 - val_accuracy: 0.3000\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7153 - accuracy: 0.3370 - val_loss: 1.8512 - val_accuracy: 0.3111\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.7083 - accuracy: 0.3407 - val_loss: 1.8463 - val_accuracy: 0.3111\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.7014 - accuracy: 0.3407 - val_loss: 1.8416 - val_accuracy: 0.3111\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6945 - accuracy: 0.3407 - val_loss: 1.8374 - val_accuracy: 0.3222\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.6880 - accuracy: 0.3444 - val_loss: 1.8327 - val_accuracy: 0.3222\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6815 - accuracy: 0.3481 - val_loss: 1.8279 - val_accuracy: 0.3222\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6750 - accuracy: 0.3519 - val_loss: 1.8244 - val_accuracy: 0.3222\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6688 - accuracy: 0.3481 - val_loss: 1.8207 - val_accuracy: 0.3222\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.6632 - accuracy: 0.3481 - val_loss: 1.8171 - val_accuracy: 0.3222\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6575 - accuracy: 0.3519 - val_loss: 1.8128 - val_accuracy: 0.3222\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6513 - accuracy: 0.3519 - val_loss: 1.8103 - val_accuracy: 0.3222\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.6455 - accuracy: 0.3556 - val_loss: 1.8073 - val_accuracy: 0.3222\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6400 - accuracy: 0.3556 - val_loss: 1.8049 - val_accuracy: 0.3222\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6349 - accuracy: 0.3556 - val_loss: 1.8021 - val_accuracy: 0.3222\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.6293 - accuracy: 0.3556 - val_loss: 1.7989 - val_accuracy: 0.3222\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6241 - accuracy: 0.3556 - val_loss: 1.7954 - val_accuracy: 0.3222\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6186 - accuracy: 0.3519 - val_loss: 1.7932 - val_accuracy: 0.3222\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6137 - accuracy: 0.3556 - val_loss: 1.7906 - val_accuracy: 0.3222\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6084 - accuracy: 0.3630 - val_loss: 1.7877 - val_accuracy: 0.3222\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.6033 - accuracy: 0.3667 - val_loss: 1.7857 - val_accuracy: 0.3222\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5981 - accuracy: 0.3704 - val_loss: 1.7837 - val_accuracy: 0.3222\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5934 - accuracy: 0.3778 - val_loss: 1.7812 - val_accuracy: 0.3222\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.5882 - accuracy: 0.3778 - val_loss: 1.7788 - val_accuracy: 0.3222\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5837 - accuracy: 0.3815 - val_loss: 1.7772 - val_accuracy: 0.3444\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5790 - accuracy: 0.3815 - val_loss: 1.7752 - val_accuracy: 0.3444\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5743 - accuracy: 0.3815 - val_loss: 1.7737 - val_accuracy: 0.3444\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5696 - accuracy: 0.3815 - val_loss: 1.7716 - val_accuracy: 0.3444\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.5650 - accuracy: 0.3815 - val_loss: 1.7702 - val_accuracy: 0.3444\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5605 - accuracy: 0.3815 - val_loss: 1.7690 - val_accuracy: 0.3444\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5559 - accuracy: 0.3852 - val_loss: 1.7669 - val_accuracy: 0.3333\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5514 - accuracy: 0.3852 - val_loss: 1.7650 - val_accuracy: 0.3333\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5470 - accuracy: 0.3889 - val_loss: 1.7637 - val_accuracy: 0.3333\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5426 - accuracy: 0.3889 - val_loss: 1.7625 - val_accuracy: 0.3444\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.5379 - accuracy: 0.3852 - val_loss: 1.7610 - val_accuracy: 0.3444\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5337 - accuracy: 0.3852 - val_loss: 1.7600 - val_accuracy: 0.3556\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5293 - accuracy: 0.3852 - val_loss: 1.7586 - val_accuracy: 0.3556\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5249 - accuracy: 0.3852 - val_loss: 1.7574 - val_accuracy: 0.3556\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5206 - accuracy: 0.3852 - val_loss: 1.7564 - val_accuracy: 0.3556\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5162 - accuracy: 0.3852 - val_loss: 1.7552 - val_accuracy: 0.3556\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5122 - accuracy: 0.3852 - val_loss: 1.7537 - val_accuracy: 0.3556\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.5080 - accuracy: 0.3852 - val_loss: 1.7523 - val_accuracy: 0.3556\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.5037 - accuracy: 0.3852 - val_loss: 1.7511 - val_accuracy: 0.3556\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4994 - accuracy: 0.3889 - val_loss: 1.7503 - val_accuracy: 0.3556\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4953 - accuracy: 0.3889 - val_loss: 1.7498 - val_accuracy: 0.3556\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4914 - accuracy: 0.3889 - val_loss: 1.7482 - val_accuracy: 0.3444\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4870 - accuracy: 0.3926 - val_loss: 1.7474 - val_accuracy: 0.3444\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4830 - accuracy: 0.4000 - val_loss: 1.7472 - val_accuracy: 0.3444\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4790 - accuracy: 0.4037 - val_loss: 1.7466 - val_accuracy: 0.3556\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4749 - accuracy: 0.4074 - val_loss: 1.7452 - val_accuracy: 0.3556\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4711 - accuracy: 0.4074 - val_loss: 1.7440 - val_accuracy: 0.3556\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4670 - accuracy: 0.4074 - val_loss: 1.7431 - val_accuracy: 0.3556\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4632 - accuracy: 0.4074 - val_loss: 1.7419 - val_accuracy: 0.3556\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4593 - accuracy: 0.4074 - val_loss: 1.7410 - val_accuracy: 0.3556\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4553 - accuracy: 0.4111 - val_loss: 1.7404 - val_accuracy: 0.3556\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4516 - accuracy: 0.4111 - val_loss: 1.7395 - val_accuracy: 0.3556\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.4477 - accuracy: 0.4111 - val_loss: 1.7394 - val_accuracy: 0.3556\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4439 - accuracy: 0.4185 - val_loss: 1.7386 - val_accuracy: 0.3556\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4401 - accuracy: 0.4185 - val_loss: 1.7386 - val_accuracy: 0.3556\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.4362 - accuracy: 0.4222 - val_loss: 1.7375 - val_accuracy: 0.3556\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4324 - accuracy: 0.4222 - val_loss: 1.7365 - val_accuracy: 0.3556\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.4285 - accuracy: 0.4259 - val_loss: 1.7356 - val_accuracy: 0.3556\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4246 - accuracy: 0.4296 - val_loss: 1.7345 - val_accuracy: 0.3556\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.4208 - accuracy: 0.4296 - val_loss: 1.7341 - val_accuracy: 0.3556\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4170 - accuracy: 0.4296 - val_loss: 1.7337 - val_accuracy: 0.3556\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4132 - accuracy: 0.4296 - val_loss: 1.7326 - val_accuracy: 0.3556\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4094 - accuracy: 0.4333 - val_loss: 1.7322 - val_accuracy: 0.3556\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.4055 - accuracy: 0.4370 - val_loss: 1.7313 - val_accuracy: 0.3556\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.4020 - accuracy: 0.4370 - val_loss: 1.7301 - val_accuracy: 0.3556\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3981 - accuracy: 0.4370 - val_loss: 1.7297 - val_accuracy: 0.3556\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3948 - accuracy: 0.4407 - val_loss: 1.7288 - val_accuracy: 0.3556\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3906 - accuracy: 0.4444 - val_loss: 1.7280 - val_accuracy: 0.3556\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3872 - accuracy: 0.4481 - val_loss: 1.7273 - val_accuracy: 0.3556\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3836 - accuracy: 0.4519 - val_loss: 1.7266 - val_accuracy: 0.3556\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3798 - accuracy: 0.4519 - val_loss: 1.7260 - val_accuracy: 0.3556\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3763 - accuracy: 0.4519 - val_loss: 1.7251 - val_accuracy: 0.3556\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3727 - accuracy: 0.4556 - val_loss: 1.7244 - val_accuracy: 0.3556\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3691 - accuracy: 0.4593 - val_loss: 1.7239 - val_accuracy: 0.3556\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3656 - accuracy: 0.4593 - val_loss: 1.7235 - val_accuracy: 0.3556\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3620 - accuracy: 0.4630 - val_loss: 1.7228 - val_accuracy: 0.3556\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3587 - accuracy: 0.4630 - val_loss: 1.7223 - val_accuracy: 0.3556\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3550 - accuracy: 0.4630 - val_loss: 1.7215 - val_accuracy: 0.3556\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3516 - accuracy: 0.4630 - val_loss: 1.7211 - val_accuracy: 0.3556\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3481 - accuracy: 0.4667 - val_loss: 1.7209 - val_accuracy: 0.3667\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3445 - accuracy: 0.4741 - val_loss: 1.7203 - val_accuracy: 0.3667\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3410 - accuracy: 0.4704 - val_loss: 1.7195 - val_accuracy: 0.3667\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3378 - accuracy: 0.4704 - val_loss: 1.7192 - val_accuracy: 0.3667\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3341 - accuracy: 0.4741 - val_loss: 1.7184 - val_accuracy: 0.3667\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3307 - accuracy: 0.4741 - val_loss: 1.7177 - val_accuracy: 0.3667\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3270 - accuracy: 0.4741 - val_loss: 1.7168 - val_accuracy: 0.3667\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3236 - accuracy: 0.4778 - val_loss: 1.7160 - val_accuracy: 0.3667\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3202 - accuracy: 0.4852 - val_loss: 1.7156 - val_accuracy: 0.3667\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3168 - accuracy: 0.4852 - val_loss: 1.7150 - val_accuracy: 0.3667\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3135 - accuracy: 0.4889 - val_loss: 1.7145 - val_accuracy: 0.3667\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.3101 - accuracy: 0.4889 - val_loss: 1.7140 - val_accuracy: 0.3667\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3067 - accuracy: 0.4889 - val_loss: 1.7136 - val_accuracy: 0.3667\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3036 - accuracy: 0.4889 - val_loss: 1.7129 - val_accuracy: 0.3667\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.3001 - accuracy: 0.4889 - val_loss: 1.7121 - val_accuracy: 0.3667\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2966 - accuracy: 0.4889 - val_loss: 1.7119 - val_accuracy: 0.3667\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2934 - accuracy: 0.4889 - val_loss: 1.7120 - val_accuracy: 0.3667\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2901 - accuracy: 0.4889 - val_loss: 1.7113 - val_accuracy: 0.3667\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2869 - accuracy: 0.4889 - val_loss: 1.7109 - val_accuracy: 0.3667\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2835 - accuracy: 0.4889 - val_loss: 1.7099 - val_accuracy: 0.3667\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.2804 - accuracy: 0.4889 - val_loss: 1.7091 - val_accuracy: 0.3667\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2772 - accuracy: 0.4926 - val_loss: 1.7087 - val_accuracy: 0.3667\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.2739 - accuracy: 0.4963 - val_loss: 1.7080 - val_accuracy: 0.3667\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2707 - accuracy: 0.5000 - val_loss: 1.7073 - val_accuracy: 0.3667\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2675 - accuracy: 0.5000 - val_loss: 1.7070 - val_accuracy: 0.3667\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2643 - accuracy: 0.5037 - val_loss: 1.7064 - val_accuracy: 0.3667\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2612 - accuracy: 0.5037 - val_loss: 1.7058 - val_accuracy: 0.3667\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2580 - accuracy: 0.5111 - val_loss: 1.7053 - val_accuracy: 0.3667\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2550 - accuracy: 0.5111 - val_loss: 1.7049 - val_accuracy: 0.3667\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.2517 - accuracy: 0.5148 - val_loss: 1.7040 - val_accuracy: 0.3667\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.2486 - accuracy: 0.5148 - val_loss: 1.7035 - val_accuracy: 0.3667\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2456 - accuracy: 0.5148 - val_loss: 1.7029 - val_accuracy: 0.3778\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2424 - accuracy: 0.5148 - val_loss: 1.7019 - val_accuracy: 0.3778\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2395 - accuracy: 0.5222 - val_loss: 1.7016 - val_accuracy: 0.3778\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2363 - accuracy: 0.5259 - val_loss: 1.7012 - val_accuracy: 0.3778\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2332 - accuracy: 0.5259 - val_loss: 1.7007 - val_accuracy: 0.3778\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2301 - accuracy: 0.5259 - val_loss: 1.7000 - val_accuracy: 0.3778\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2270 - accuracy: 0.5296 - val_loss: 1.6993 - val_accuracy: 0.3778\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2239 - accuracy: 0.5296 - val_loss: 1.6989 - val_accuracy: 0.3778\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2211 - accuracy: 0.5296 - val_loss: 1.6982 - val_accuracy: 0.3778\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2179 - accuracy: 0.5333 - val_loss: 1.6977 - val_accuracy: 0.3778\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2153 - accuracy: 0.5333 - val_loss: 1.6976 - val_accuracy: 0.3778\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2119 - accuracy: 0.5370 - val_loss: 1.6973 - val_accuracy: 0.3778\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2090 - accuracy: 0.5444 - val_loss: 1.6976 - val_accuracy: 0.3778\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2059 - accuracy: 0.5481 - val_loss: 1.6967 - val_accuracy: 0.3778\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2030 - accuracy: 0.5444 - val_loss: 1.6964 - val_accuracy: 0.3778\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.2000 - accuracy: 0.5444 - val_loss: 1.6953 - val_accuracy: 0.3778\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1971 - accuracy: 0.5519 - val_loss: 1.6944 - val_accuracy: 0.3778\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1941 - accuracy: 0.5556 - val_loss: 1.6941 - val_accuracy: 0.3778\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1912 - accuracy: 0.5593 - val_loss: 1.6941 - val_accuracy: 0.3778\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1883 - accuracy: 0.5630 - val_loss: 1.6935 - val_accuracy: 0.3778\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1853 - accuracy: 0.5667 - val_loss: 1.6931 - val_accuracy: 0.3778\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1826 - accuracy: 0.5704 - val_loss: 1.6924 - val_accuracy: 0.3778\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1796 - accuracy: 0.5741 - val_loss: 1.6916 - val_accuracy: 0.3778\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1768 - accuracy: 0.5741 - val_loss: 1.6913 - val_accuracy: 0.3778\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1739 - accuracy: 0.5741 - val_loss: 1.6907 - val_accuracy: 0.3778\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1713 - accuracy: 0.5741 - val_loss: 1.6900 - val_accuracy: 0.3778\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1680 - accuracy: 0.5704 - val_loss: 1.6896 - val_accuracy: 0.3778\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1651 - accuracy: 0.5741 - val_loss: 1.6889 - val_accuracy: 0.3778\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1623 - accuracy: 0.5778 - val_loss: 1.6886 - val_accuracy: 0.3778\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1595 - accuracy: 0.5778 - val_loss: 1.6878 - val_accuracy: 0.3778\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1566 - accuracy: 0.5778 - val_loss: 1.6876 - val_accuracy: 0.3778\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1538 - accuracy: 0.5778 - val_loss: 1.6875 - val_accuracy: 0.3778\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1509 - accuracy: 0.5815 - val_loss: 1.6869 - val_accuracy: 0.3778\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1481 - accuracy: 0.5815 - val_loss: 1.6864 - val_accuracy: 0.3778\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1453 - accuracy: 0.5852 - val_loss: 1.6855 - val_accuracy: 0.3778\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1425 - accuracy: 0.5852 - val_loss: 1.6848 - val_accuracy: 0.3778\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1397 - accuracy: 0.5852 - val_loss: 1.6852 - val_accuracy: 0.3778\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.1369 - accuracy: 0.5852 - val_loss: 1.6849 - val_accuracy: 0.3778\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1.1344 - accuracy: 0.5889 - val_loss: 1.6851 - val_accuracy: 0.3778\n",
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 2.5629 - accuracy: 0.1000 - val_loss: 2.7038 - val_accuracy: 0.1111\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5587 - accuracy: 0.1000 - val_loss: 2.6992 - val_accuracy: 0.1111\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5546 - accuracy: 0.1000 - val_loss: 2.6945 - val_accuracy: 0.1111\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5505 - accuracy: 0.1000 - val_loss: 2.6899 - val_accuracy: 0.1111\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5466 - accuracy: 0.1000 - val_loss: 2.6854 - val_accuracy: 0.1111\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5424 - accuracy: 0.1000 - val_loss: 2.6810 - val_accuracy: 0.1111\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5384 - accuracy: 0.1000 - val_loss: 2.6765 - val_accuracy: 0.1111\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5344 - accuracy: 0.1000 - val_loss: 2.6720 - val_accuracy: 0.1111\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5303 - accuracy: 0.1000 - val_loss: 2.6675 - val_accuracy: 0.1111\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5265 - accuracy: 0.1037 - val_loss: 2.6632 - val_accuracy: 0.1111\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5226 - accuracy: 0.1074 - val_loss: 2.6588 - val_accuracy: 0.1111\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5186 - accuracy: 0.1037 - val_loss: 2.6545 - val_accuracy: 0.1111\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5148 - accuracy: 0.1037 - val_loss: 2.6504 - val_accuracy: 0.1111\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5111 - accuracy: 0.1037 - val_loss: 2.6461 - val_accuracy: 0.1111\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5074 - accuracy: 0.1037 - val_loss: 2.6419 - val_accuracy: 0.1111\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5036 - accuracy: 0.1037 - val_loss: 2.6379 - val_accuracy: 0.1111\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5000 - accuracy: 0.1037 - val_loss: 2.6337 - val_accuracy: 0.1111\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4963 - accuracy: 0.1037 - val_loss: 2.6297 - val_accuracy: 0.1111\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4926 - accuracy: 0.1037 - val_loss: 2.6256 - val_accuracy: 0.1111\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4890 - accuracy: 0.1037 - val_loss: 2.6215 - val_accuracy: 0.1111\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4853 - accuracy: 0.1074 - val_loss: 2.6174 - val_accuracy: 0.1111\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4816 - accuracy: 0.1074 - val_loss: 2.6134 - val_accuracy: 0.1111\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4781 - accuracy: 0.1074 - val_loss: 2.6093 - val_accuracy: 0.1111\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4745 - accuracy: 0.1074 - val_loss: 2.6054 - val_accuracy: 0.1111\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4709 - accuracy: 0.1074 - val_loss: 2.6016 - val_accuracy: 0.1111\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4675 - accuracy: 0.1074 - val_loss: 2.5977 - val_accuracy: 0.1111\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4640 - accuracy: 0.1074 - val_loss: 2.5939 - val_accuracy: 0.1111\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4607 - accuracy: 0.1074 - val_loss: 2.5899 - val_accuracy: 0.1111\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4572 - accuracy: 0.1074 - val_loss: 2.5861 - val_accuracy: 0.1111\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4538 - accuracy: 0.1074 - val_loss: 2.5823 - val_accuracy: 0.1111\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4504 - accuracy: 0.1074 - val_loss: 2.5786 - val_accuracy: 0.1111\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4471 - accuracy: 0.1111 - val_loss: 2.5749 - val_accuracy: 0.1111\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.4437 - accuracy: 0.1111 - val_loss: 2.5712 - val_accuracy: 0.1111\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4404 - accuracy: 0.1111 - val_loss: 2.5674 - val_accuracy: 0.1111\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4370 - accuracy: 0.1111 - val_loss: 2.5637 - val_accuracy: 0.1111\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4337 - accuracy: 0.1111 - val_loss: 2.5601 - val_accuracy: 0.1111\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4304 - accuracy: 0.1111 - val_loss: 2.5564 - val_accuracy: 0.1111\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4271 - accuracy: 0.1111 - val_loss: 2.5527 - val_accuracy: 0.1111\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4239 - accuracy: 0.1111 - val_loss: 2.5491 - val_accuracy: 0.1111\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4207 - accuracy: 0.1148 - val_loss: 2.5457 - val_accuracy: 0.1111\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.4176 - accuracy: 0.1148 - val_loss: 2.5423 - val_accuracy: 0.1111\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.4144 - accuracy: 0.1148 - val_loss: 2.5389 - val_accuracy: 0.1111\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4115 - accuracy: 0.1148 - val_loss: 2.5354 - val_accuracy: 0.1111\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.4083 - accuracy: 0.1148 - val_loss: 2.5321 - val_accuracy: 0.1111\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4053 - accuracy: 0.1148 - val_loss: 2.5287 - val_accuracy: 0.1111\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4023 - accuracy: 0.1148 - val_loss: 2.5254 - val_accuracy: 0.1111\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3994 - accuracy: 0.1185 - val_loss: 2.5222 - val_accuracy: 0.1111\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3964 - accuracy: 0.1222 - val_loss: 2.5191 - val_accuracy: 0.1111\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3936 - accuracy: 0.1222 - val_loss: 2.5158 - val_accuracy: 0.1222\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3906 - accuracy: 0.1259 - val_loss: 2.5126 - val_accuracy: 0.1222\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3877 - accuracy: 0.1296 - val_loss: 2.5095 - val_accuracy: 0.1333\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3848 - accuracy: 0.1296 - val_loss: 2.5064 - val_accuracy: 0.1333\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3819 - accuracy: 0.1333 - val_loss: 2.5032 - val_accuracy: 0.1333\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.3792 - accuracy: 0.1333 - val_loss: 2.5000 - val_accuracy: 0.1333\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3763 - accuracy: 0.1333 - val_loss: 2.4971 - val_accuracy: 0.1333\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3736 - accuracy: 0.1333 - val_loss: 2.4941 - val_accuracy: 0.1333\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.3709 - accuracy: 0.1333 - val_loss: 2.4910 - val_accuracy: 0.1444\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3682 - accuracy: 0.1333 - val_loss: 2.4880 - val_accuracy: 0.1444\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.3652 - accuracy: 0.1333 - val_loss: 2.4852 - val_accuracy: 0.1444\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3626 - accuracy: 0.1333 - val_loss: 2.4822 - val_accuracy: 0.1444\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3601 - accuracy: 0.1333 - val_loss: 2.4791 - val_accuracy: 0.1444\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3573 - accuracy: 0.1333 - val_loss: 2.4763 - val_accuracy: 0.1556\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3547 - accuracy: 0.1333 - val_loss: 2.4735 - val_accuracy: 0.1667\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3520 - accuracy: 0.1333 - val_loss: 2.4707 - val_accuracy: 0.1667\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3494 - accuracy: 0.1407 - val_loss: 2.4678 - val_accuracy: 0.1667\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3468 - accuracy: 0.1407 - val_loss: 2.4651 - val_accuracy: 0.1667\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3443 - accuracy: 0.1407 - val_loss: 2.4623 - val_accuracy: 0.1667\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3417 - accuracy: 0.1444 - val_loss: 2.4596 - val_accuracy: 0.1778\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3391 - accuracy: 0.1444 - val_loss: 2.4571 - val_accuracy: 0.1778\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3368 - accuracy: 0.1444 - val_loss: 2.4543 - val_accuracy: 0.1778\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3342 - accuracy: 0.1481 - val_loss: 2.4517 - val_accuracy: 0.1778\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3318 - accuracy: 0.1519 - val_loss: 2.4491 - val_accuracy: 0.1778\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3293 - accuracy: 0.1519 - val_loss: 2.4466 - val_accuracy: 0.1778\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3269 - accuracy: 0.1556 - val_loss: 2.4441 - val_accuracy: 0.1778\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3244 - accuracy: 0.1593 - val_loss: 2.4415 - val_accuracy: 0.1778\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3221 - accuracy: 0.1593 - val_loss: 2.4390 - val_accuracy: 0.1778\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3197 - accuracy: 0.1593 - val_loss: 2.4364 - val_accuracy: 0.1778\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3173 - accuracy: 0.1593 - val_loss: 2.4340 - val_accuracy: 0.1778\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3149 - accuracy: 0.1630 - val_loss: 2.4316 - val_accuracy: 0.1778\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3126 - accuracy: 0.1630 - val_loss: 2.4291 - val_accuracy: 0.1778\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3102 - accuracy: 0.1630 - val_loss: 2.4266 - val_accuracy: 0.1778\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3079 - accuracy: 0.1630 - val_loss: 2.4241 - val_accuracy: 0.1778\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.3056 - accuracy: 0.1667 - val_loss: 2.4217 - val_accuracy: 0.1778\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.3033 - accuracy: 0.1704 - val_loss: 2.4192 - val_accuracy: 0.1778\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.3010 - accuracy: 0.1704 - val_loss: 2.4168 - val_accuracy: 0.1778\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2987 - accuracy: 0.1704 - val_loss: 2.4145 - val_accuracy: 0.1778\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2965 - accuracy: 0.1741 - val_loss: 2.4123 - val_accuracy: 0.2000\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2944 - accuracy: 0.1778 - val_loss: 2.4100 - val_accuracy: 0.2111\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2921 - accuracy: 0.1778 - val_loss: 2.4077 - val_accuracy: 0.2111\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2899 - accuracy: 0.1778 - val_loss: 2.4054 - val_accuracy: 0.2111\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2878 - accuracy: 0.1778 - val_loss: 2.4031 - val_accuracy: 0.2111\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2856 - accuracy: 0.1815 - val_loss: 2.4009 - val_accuracy: 0.2222\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2835 - accuracy: 0.1815 - val_loss: 2.3988 - val_accuracy: 0.2222\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2814 - accuracy: 0.1815 - val_loss: 2.3966 - val_accuracy: 0.2333\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2793 - accuracy: 0.1815 - val_loss: 2.3945 - val_accuracy: 0.2333\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2771 - accuracy: 0.1852 - val_loss: 2.3923 - val_accuracy: 0.2333\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2750 - accuracy: 0.1852 - val_loss: 2.3901 - val_accuracy: 0.2333\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2729 - accuracy: 0.1889 - val_loss: 2.3879 - val_accuracy: 0.2333\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2709 - accuracy: 0.1889 - val_loss: 2.3858 - val_accuracy: 0.2333\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2688 - accuracy: 0.1889 - val_loss: 2.3837 - val_accuracy: 0.2333\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2668 - accuracy: 0.1889 - val_loss: 2.3815 - val_accuracy: 0.2333\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2647 - accuracy: 0.1889 - val_loss: 2.3795 - val_accuracy: 0.2333\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2627 - accuracy: 0.1963 - val_loss: 2.3774 - val_accuracy: 0.2333\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2607 - accuracy: 0.2037 - val_loss: 2.3754 - val_accuracy: 0.2333\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2586 - accuracy: 0.2037 - val_loss: 2.3734 - val_accuracy: 0.2333\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2567 - accuracy: 0.2074 - val_loss: 2.3713 - val_accuracy: 0.2444\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2547 - accuracy: 0.2111 - val_loss: 2.3694 - val_accuracy: 0.2444\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2528 - accuracy: 0.2148 - val_loss: 2.3673 - val_accuracy: 0.2444\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2508 - accuracy: 0.2148 - val_loss: 2.3654 - val_accuracy: 0.2556\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2489 - accuracy: 0.2148 - val_loss: 2.3636 - val_accuracy: 0.2556\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2471 - accuracy: 0.2148 - val_loss: 2.3616 - val_accuracy: 0.2556\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2452 - accuracy: 0.2148 - val_loss: 2.3597 - val_accuracy: 0.2556\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2433 - accuracy: 0.2148 - val_loss: 2.3579 - val_accuracy: 0.2556\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2415 - accuracy: 0.2222 - val_loss: 2.3561 - val_accuracy: 0.2556\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2397 - accuracy: 0.2222 - val_loss: 2.3542 - val_accuracy: 0.2556\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2378 - accuracy: 0.2222 - val_loss: 2.3523 - val_accuracy: 0.2556\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2359 - accuracy: 0.2222 - val_loss: 2.3506 - val_accuracy: 0.2556\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2341 - accuracy: 0.2296 - val_loss: 2.3487 - val_accuracy: 0.2556\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2323 - accuracy: 0.2296 - val_loss: 2.3469 - val_accuracy: 0.2556\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2305 - accuracy: 0.2296 - val_loss: 2.3451 - val_accuracy: 0.2556\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2287 - accuracy: 0.2296 - val_loss: 2.3433 - val_accuracy: 0.2556\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2269 - accuracy: 0.2259 - val_loss: 2.3415 - val_accuracy: 0.2556\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2251 - accuracy: 0.2296 - val_loss: 2.3398 - val_accuracy: 0.2556\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2233 - accuracy: 0.2296 - val_loss: 2.3379 - val_accuracy: 0.2556\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2215 - accuracy: 0.2296 - val_loss: 2.3363 - val_accuracy: 0.2556\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2198 - accuracy: 0.2296 - val_loss: 2.3345 - val_accuracy: 0.2556\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2181 - accuracy: 0.2296 - val_loss: 2.3328 - val_accuracy: 0.2556\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2164 - accuracy: 0.2296 - val_loss: 2.3311 - val_accuracy: 0.2556\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2147 - accuracy: 0.2296 - val_loss: 2.3293 - val_accuracy: 0.2556\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2130 - accuracy: 0.2296 - val_loss: 2.3278 - val_accuracy: 0.2556\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2113 - accuracy: 0.2296 - val_loss: 2.3261 - val_accuracy: 0.2556\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2097 - accuracy: 0.2296 - val_loss: 2.3246 - val_accuracy: 0.2556\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2080 - accuracy: 0.2296 - val_loss: 2.3229 - val_accuracy: 0.2444\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.2064 - accuracy: 0.2296 - val_loss: 2.3212 - val_accuracy: 0.2444\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2047 - accuracy: 0.2333 - val_loss: 2.3196 - val_accuracy: 0.2444\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2031 - accuracy: 0.2370 - val_loss: 2.3181 - val_accuracy: 0.2444\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2014 - accuracy: 0.2407 - val_loss: 2.3165 - val_accuracy: 0.2444\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1999 - accuracy: 0.2407 - val_loss: 2.3149 - val_accuracy: 0.2444\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1983 - accuracy: 0.2407 - val_loss: 2.3134 - val_accuracy: 0.2444\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1967 - accuracy: 0.2407 - val_loss: 2.3118 - val_accuracy: 0.2444\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.2481 - val_loss: 2.3104 - val_accuracy: 0.2444\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1935 - accuracy: 0.2481 - val_loss: 2.3088 - val_accuracy: 0.2444\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1919 - accuracy: 0.2519 - val_loss: 2.3073 - val_accuracy: 0.2556\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1904 - accuracy: 0.2519 - val_loss: 2.3058 - val_accuracy: 0.2667\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1888 - accuracy: 0.2519 - val_loss: 2.3043 - val_accuracy: 0.2778\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1873 - accuracy: 0.2519 - val_loss: 2.3029 - val_accuracy: 0.2778\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1858 - accuracy: 0.2519 - val_loss: 2.3015 - val_accuracy: 0.2778\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1843 - accuracy: 0.2519 - val_loss: 2.3000 - val_accuracy: 0.2889\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1828 - accuracy: 0.2519 - val_loss: 2.2986 - val_accuracy: 0.2889\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1813 - accuracy: 0.2519 - val_loss: 2.2972 - val_accuracy: 0.2889\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1798 - accuracy: 0.2519 - val_loss: 2.2958 - val_accuracy: 0.2778\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1783 - accuracy: 0.2519 - val_loss: 2.2944 - val_accuracy: 0.2778\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1768 - accuracy: 0.2519 - val_loss: 2.2929 - val_accuracy: 0.2778\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1753 - accuracy: 0.2556 - val_loss: 2.2915 - val_accuracy: 0.2778\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1738 - accuracy: 0.2556 - val_loss: 2.2902 - val_accuracy: 0.2778\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1724 - accuracy: 0.2556 - val_loss: 2.2888 - val_accuracy: 0.2778\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1710 - accuracy: 0.2556 - val_loss: 2.2875 - val_accuracy: 0.2778\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1695 - accuracy: 0.2556 - val_loss: 2.2861 - val_accuracy: 0.2778\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1680 - accuracy: 0.2556 - val_loss: 2.2846 - val_accuracy: 0.2889\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1665 - accuracy: 0.2556 - val_loss: 2.2832 - val_accuracy: 0.2889\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1651 - accuracy: 0.2556 - val_loss: 2.2819 - val_accuracy: 0.2889\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1637 - accuracy: 0.2593 - val_loss: 2.2806 - val_accuracy: 0.2889\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1623 - accuracy: 0.2630 - val_loss: 2.2792 - val_accuracy: 0.2889\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1608 - accuracy: 0.2630 - val_loss: 2.2779 - val_accuracy: 0.2889\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1595 - accuracy: 0.2667 - val_loss: 2.2766 - val_accuracy: 0.2889\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1581 - accuracy: 0.2667 - val_loss: 2.2753 - val_accuracy: 0.2889\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1567 - accuracy: 0.2667 - val_loss: 2.2740 - val_accuracy: 0.2889\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1554 - accuracy: 0.2667 - val_loss: 2.2728 - val_accuracy: 0.2889\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1540 - accuracy: 0.2667 - val_loss: 2.2715 - val_accuracy: 0.2889\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1526 - accuracy: 0.2667 - val_loss: 2.2702 - val_accuracy: 0.2889\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1512 - accuracy: 0.2704 - val_loss: 2.2689 - val_accuracy: 0.2889\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1498 - accuracy: 0.2704 - val_loss: 2.2676 - val_accuracy: 0.2889\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1485 - accuracy: 0.2704 - val_loss: 2.2663 - val_accuracy: 0.2889\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1471 - accuracy: 0.2704 - val_loss: 2.2650 - val_accuracy: 0.2889\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1458 - accuracy: 0.2704 - val_loss: 2.2638 - val_accuracy: 0.2889\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1444 - accuracy: 0.2704 - val_loss: 2.2626 - val_accuracy: 0.2889\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1431 - accuracy: 0.2704 - val_loss: 2.2615 - val_accuracy: 0.2889\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1418 - accuracy: 0.2704 - val_loss: 2.2603 - val_accuracy: 0.2889\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1405 - accuracy: 0.2704 - val_loss: 2.2590 - val_accuracy: 0.2889\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1392 - accuracy: 0.2741 - val_loss: 2.2578 - val_accuracy: 0.2889\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1379 - accuracy: 0.2741 - val_loss: 2.2567 - val_accuracy: 0.2889\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1366 - accuracy: 0.2741 - val_loss: 2.2555 - val_accuracy: 0.2889\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1354 - accuracy: 0.2741 - val_loss: 2.2544 - val_accuracy: 0.2889\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1341 - accuracy: 0.2741 - val_loss: 2.2533 - val_accuracy: 0.2889\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1329 - accuracy: 0.2741 - val_loss: 2.2522 - val_accuracy: 0.2889\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1316 - accuracy: 0.2741 - val_loss: 2.2511 - val_accuracy: 0.2889\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1303 - accuracy: 0.2741 - val_loss: 2.2500 - val_accuracy: 0.2889\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1291 - accuracy: 0.2741 - val_loss: 2.2489 - val_accuracy: 0.2889\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1278 - accuracy: 0.2741 - val_loss: 2.2478 - val_accuracy: 0.2889\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1266 - accuracy: 0.2741 - val_loss: 2.2467 - val_accuracy: 0.2889\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1253 - accuracy: 0.2741 - val_loss: 2.2456 - val_accuracy: 0.2889\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1241 - accuracy: 0.2741 - val_loss: 2.2444 - val_accuracy: 0.2889\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1229 - accuracy: 0.2741 - val_loss: 2.2433 - val_accuracy: 0.2889\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1216 - accuracy: 0.2741 - val_loss: 2.2422 - val_accuracy: 0.2889\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1204 - accuracy: 0.2741 - val_loss: 2.2412 - val_accuracy: 0.2889\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1192 - accuracy: 0.2741 - val_loss: 2.2401 - val_accuracy: 0.2889\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1180 - accuracy: 0.2741 - val_loss: 2.2391 - val_accuracy: 0.2889\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1169 - accuracy: 0.2741 - val_loss: 2.2380 - val_accuracy: 0.2889\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.1156 - accuracy: 0.2741 - val_loss: 2.2371 - val_accuracy: 0.2889\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.1145 - accuracy: 0.2778 - val_loss: 2.2360 - val_accuracy: 0.2889\n",
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 2.0686 - accuracy: 0.2185 - val_loss: 2.1814 - val_accuracy: 0.2222\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0683 - accuracy: 0.2185 - val_loss: 2.1810 - val_accuracy: 0.2222\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0679 - accuracy: 0.2185 - val_loss: 2.1806 - val_accuracy: 0.2222\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0676 - accuracy: 0.2185 - val_loss: 2.1803 - val_accuracy: 0.2222\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0672 - accuracy: 0.2185 - val_loss: 2.1799 - val_accuracy: 0.2222\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0669 - accuracy: 0.2185 - val_loss: 2.1795 - val_accuracy: 0.2222\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0665 - accuracy: 0.2185 - val_loss: 2.1791 - val_accuracy: 0.2222\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0662 - accuracy: 0.2185 - val_loss: 2.1788 - val_accuracy: 0.2222\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0659 - accuracy: 0.2185 - val_loss: 2.1784 - val_accuracy: 0.2222\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0655 - accuracy: 0.2185 - val_loss: 2.1780 - val_accuracy: 0.2222\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0652 - accuracy: 0.2185 - val_loss: 2.1777 - val_accuracy: 0.2222\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0649 - accuracy: 0.2185 - val_loss: 2.1773 - val_accuracy: 0.2222\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0645 - accuracy: 0.2185 - val_loss: 2.1769 - val_accuracy: 0.2222\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0642 - accuracy: 0.2185 - val_loss: 2.1766 - val_accuracy: 0.2222\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0639 - accuracy: 0.2185 - val_loss: 2.1762 - val_accuracy: 0.2222\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0635 - accuracy: 0.2185 - val_loss: 2.1758 - val_accuracy: 0.2222\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0632 - accuracy: 0.2185 - val_loss: 2.1755 - val_accuracy: 0.2222\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0628 - accuracy: 0.2185 - val_loss: 2.1751 - val_accuracy: 0.2222\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0625 - accuracy: 0.2185 - val_loss: 2.1747 - val_accuracy: 0.2111\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0622 - accuracy: 0.2185 - val_loss: 2.1744 - val_accuracy: 0.2111\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0618 - accuracy: 0.2185 - val_loss: 2.1740 - val_accuracy: 0.2111\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0615 - accuracy: 0.2185 - val_loss: 2.1736 - val_accuracy: 0.2111\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0612 - accuracy: 0.2185 - val_loss: 2.1733 - val_accuracy: 0.2111\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0608 - accuracy: 0.2185 - val_loss: 2.1729 - val_accuracy: 0.2111\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0605 - accuracy: 0.2185 - val_loss: 2.1726 - val_accuracy: 0.2111\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0602 - accuracy: 0.2185 - val_loss: 2.1722 - val_accuracy: 0.2111\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0598 - accuracy: 0.2185 - val_loss: 2.1718 - val_accuracy: 0.2111\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0595 - accuracy: 0.2185 - val_loss: 2.1715 - val_accuracy: 0.2111\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0592 - accuracy: 0.2185 - val_loss: 2.1711 - val_accuracy: 0.2111\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0588 - accuracy: 0.2185 - val_loss: 2.1708 - val_accuracy: 0.2111\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0585 - accuracy: 0.2185 - val_loss: 2.1704 - val_accuracy: 0.2111\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0582 - accuracy: 0.2185 - val_loss: 2.1700 - val_accuracy: 0.2222\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0578 - accuracy: 0.2185 - val_loss: 2.1697 - val_accuracy: 0.2222\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0575 - accuracy: 0.2185 - val_loss: 2.1693 - val_accuracy: 0.2222\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0572 - accuracy: 0.2185 - val_loss: 2.1689 - val_accuracy: 0.2222\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0568 - accuracy: 0.2185 - val_loss: 2.1686 - val_accuracy: 0.2222\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0565 - accuracy: 0.2185 - val_loss: 2.1682 - val_accuracy: 0.2222\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0562 - accuracy: 0.2185 - val_loss: 2.1679 - val_accuracy: 0.2222\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0559 - accuracy: 0.2185 - val_loss: 2.1675 - val_accuracy: 0.2222\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0556 - accuracy: 0.2185 - val_loss: 2.1672 - val_accuracy: 0.2222\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0552 - accuracy: 0.2185 - val_loss: 2.1668 - val_accuracy: 0.2222\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0549 - accuracy: 0.2185 - val_loss: 2.1664 - val_accuracy: 0.2222\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0546 - accuracy: 0.2185 - val_loss: 2.1661 - val_accuracy: 0.2222\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0542 - accuracy: 0.2185 - val_loss: 2.1657 - val_accuracy: 0.2222\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0539 - accuracy: 0.2185 - val_loss: 2.1653 - val_accuracy: 0.2222\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0536 - accuracy: 0.2185 - val_loss: 2.1650 - val_accuracy: 0.2222\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0532 - accuracy: 0.2222 - val_loss: 2.1646 - val_accuracy: 0.2222\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0529 - accuracy: 0.2222 - val_loss: 2.1643 - val_accuracy: 0.2222\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0526 - accuracy: 0.2222 - val_loss: 2.1639 - val_accuracy: 0.2222\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0523 - accuracy: 0.2222 - val_loss: 2.1635 - val_accuracy: 0.2222\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0519 - accuracy: 0.2222 - val_loss: 2.1632 - val_accuracy: 0.2222\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0516 - accuracy: 0.2222 - val_loss: 2.1628 - val_accuracy: 0.2222\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0513 - accuracy: 0.2222 - val_loss: 2.1625 - val_accuracy: 0.2222\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0510 - accuracy: 0.2222 - val_loss: 2.1621 - val_accuracy: 0.2222\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0506 - accuracy: 0.2222 - val_loss: 2.1617 - val_accuracy: 0.2222\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0503 - accuracy: 0.2222 - val_loss: 2.1614 - val_accuracy: 0.2222\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0500 - accuracy: 0.2222 - val_loss: 2.1610 - val_accuracy: 0.2222\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0497 - accuracy: 0.2222 - val_loss: 2.1607 - val_accuracy: 0.2222\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0493 - accuracy: 0.2222 - val_loss: 2.1603 - val_accuracy: 0.2222\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0490 - accuracy: 0.2222 - val_loss: 2.1600 - val_accuracy: 0.2222\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0487 - accuracy: 0.2222 - val_loss: 2.1596 - val_accuracy: 0.2222\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0484 - accuracy: 0.2222 - val_loss: 2.1592 - val_accuracy: 0.2333\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0480 - accuracy: 0.2222 - val_loss: 2.1589 - val_accuracy: 0.2333\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0477 - accuracy: 0.2222 - val_loss: 2.1586 - val_accuracy: 0.2333\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0474 - accuracy: 0.2222 - val_loss: 2.1582 - val_accuracy: 0.2333\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0471 - accuracy: 0.2222 - val_loss: 2.1579 - val_accuracy: 0.2333\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0468 - accuracy: 0.2222 - val_loss: 2.1575 - val_accuracy: 0.2333\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0465 - accuracy: 0.2222 - val_loss: 2.1572 - val_accuracy: 0.2333\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0461 - accuracy: 0.2222 - val_loss: 2.1568 - val_accuracy: 0.2333\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0458 - accuracy: 0.2222 - val_loss: 2.1565 - val_accuracy: 0.2333\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0455 - accuracy: 0.2222 - val_loss: 2.1561 - val_accuracy: 0.2333\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0452 - accuracy: 0.2222 - val_loss: 2.1558 - val_accuracy: 0.2333\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0449 - accuracy: 0.2222 - val_loss: 2.1554 - val_accuracy: 0.2333\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0446 - accuracy: 0.2222 - val_loss: 2.1551 - val_accuracy: 0.2333\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0442 - accuracy: 0.2222 - val_loss: 2.1547 - val_accuracy: 0.2333\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0439 - accuracy: 0.2222 - val_loss: 2.1544 - val_accuracy: 0.2333\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0436 - accuracy: 0.2222 - val_loss: 2.1540 - val_accuracy: 0.2444\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0433 - accuracy: 0.2185 - val_loss: 2.1537 - val_accuracy: 0.2444\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0430 - accuracy: 0.2222 - val_loss: 2.1534 - val_accuracy: 0.2444\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0427 - accuracy: 0.2222 - val_loss: 2.1530 - val_accuracy: 0.2444\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0424 - accuracy: 0.2222 - val_loss: 2.1527 - val_accuracy: 0.2444\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0420 - accuracy: 0.2222 - val_loss: 2.1523 - val_accuracy: 0.2444\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0417 - accuracy: 0.2222 - val_loss: 2.1520 - val_accuracy: 0.2444\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0414 - accuracy: 0.2222 - val_loss: 2.1516 - val_accuracy: 0.2444\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0411 - accuracy: 0.2222 - val_loss: 2.1513 - val_accuracy: 0.2444\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0408 - accuracy: 0.2222 - val_loss: 2.1509 - val_accuracy: 0.2444\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0405 - accuracy: 0.2222 - val_loss: 2.1506 - val_accuracy: 0.2444\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0401 - accuracy: 0.2222 - val_loss: 2.1502 - val_accuracy: 0.2444\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0398 - accuracy: 0.2222 - val_loss: 2.1499 - val_accuracy: 0.2444\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0395 - accuracy: 0.2222 - val_loss: 2.1495 - val_accuracy: 0.2444\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0392 - accuracy: 0.2222 - val_loss: 2.1492 - val_accuracy: 0.2556\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0389 - accuracy: 0.2222 - val_loss: 2.1488 - val_accuracy: 0.2556\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0386 - accuracy: 0.2222 - val_loss: 2.1485 - val_accuracy: 0.2556\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0382 - accuracy: 0.2222 - val_loss: 2.1482 - val_accuracy: 0.2556\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0379 - accuracy: 0.2222 - val_loss: 2.1478 - val_accuracy: 0.2556\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0376 - accuracy: 0.2259 - val_loss: 2.1475 - val_accuracy: 0.2556\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0373 - accuracy: 0.2259 - val_loss: 2.1471 - val_accuracy: 0.2556\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0370 - accuracy: 0.2259 - val_loss: 2.1468 - val_accuracy: 0.2556\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0367 - accuracy: 0.2259 - val_loss: 2.1464 - val_accuracy: 0.2556\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0364 - accuracy: 0.2259 - val_loss: 2.1461 - val_accuracy: 0.2556\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0361 - accuracy: 0.2259 - val_loss: 2.1457 - val_accuracy: 0.2556\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0358 - accuracy: 0.2259 - val_loss: 2.1454 - val_accuracy: 0.2556\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0354 - accuracy: 0.2259 - val_loss: 2.1451 - val_accuracy: 0.2556\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0351 - accuracy: 0.2259 - val_loss: 2.1447 - val_accuracy: 0.2667\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0348 - accuracy: 0.2259 - val_loss: 2.1444 - val_accuracy: 0.2667\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0345 - accuracy: 0.2259 - val_loss: 2.1440 - val_accuracy: 0.2667\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0342 - accuracy: 0.2259 - val_loss: 2.1437 - val_accuracy: 0.2667\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0339 - accuracy: 0.2259 - val_loss: 2.1434 - val_accuracy: 0.2667\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0336 - accuracy: 0.2259 - val_loss: 2.1430 - val_accuracy: 0.2667\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0333 - accuracy: 0.2259 - val_loss: 2.1427 - val_accuracy: 0.2667\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0330 - accuracy: 0.2259 - val_loss: 2.1424 - val_accuracy: 0.2667\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0327 - accuracy: 0.2259 - val_loss: 2.1420 - val_accuracy: 0.2667\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0324 - accuracy: 0.2259 - val_loss: 2.1417 - val_accuracy: 0.2667\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0321 - accuracy: 0.2259 - val_loss: 2.1413 - val_accuracy: 0.2667\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0318 - accuracy: 0.2259 - val_loss: 2.1410 - val_accuracy: 0.2667\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0315 - accuracy: 0.2259 - val_loss: 2.1407 - val_accuracy: 0.2667\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0312 - accuracy: 0.2259 - val_loss: 2.1404 - val_accuracy: 0.2667\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0309 - accuracy: 0.2259 - val_loss: 2.1400 - val_accuracy: 0.2667\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0306 - accuracy: 0.2259 - val_loss: 2.1397 - val_accuracy: 0.2667\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0303 - accuracy: 0.2296 - val_loss: 2.1394 - val_accuracy: 0.2667\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0300 - accuracy: 0.2296 - val_loss: 2.1391 - val_accuracy: 0.2667\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0297 - accuracy: 0.2296 - val_loss: 2.1387 - val_accuracy: 0.2667\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0294 - accuracy: 0.2296 - val_loss: 2.1384 - val_accuracy: 0.2667\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0291 - accuracy: 0.2296 - val_loss: 2.1381 - val_accuracy: 0.2778\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0288 - accuracy: 0.2296 - val_loss: 2.1377 - val_accuracy: 0.2778\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0285 - accuracy: 0.2296 - val_loss: 2.1374 - val_accuracy: 0.2778\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0282 - accuracy: 0.2296 - val_loss: 2.1371 - val_accuracy: 0.2778\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0279 - accuracy: 0.2296 - val_loss: 2.1367 - val_accuracy: 0.2778\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0276 - accuracy: 0.2296 - val_loss: 2.1364 - val_accuracy: 0.2778\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0273 - accuracy: 0.2296 - val_loss: 2.1361 - val_accuracy: 0.2778\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0270 - accuracy: 0.2296 - val_loss: 2.1357 - val_accuracy: 0.2778\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0267 - accuracy: 0.2296 - val_loss: 2.1354 - val_accuracy: 0.2778\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0264 - accuracy: 0.2296 - val_loss: 2.1350 - val_accuracy: 0.2778\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0261 - accuracy: 0.2296 - val_loss: 2.1347 - val_accuracy: 0.2778\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0258 - accuracy: 0.2296 - val_loss: 2.1344 - val_accuracy: 0.2778\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0255 - accuracy: 0.2296 - val_loss: 2.1341 - val_accuracy: 0.2778\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0252 - accuracy: 0.2296 - val_loss: 2.1337 - val_accuracy: 0.2778\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0249 - accuracy: 0.2296 - val_loss: 2.1334 - val_accuracy: 0.2778\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0246 - accuracy: 0.2296 - val_loss: 2.1331 - val_accuracy: 0.2778\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0243 - accuracy: 0.2296 - val_loss: 2.1328 - val_accuracy: 0.2778\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0240 - accuracy: 0.2296 - val_loss: 2.1324 - val_accuracy: 0.2778\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0237 - accuracy: 0.2296 - val_loss: 2.1321 - val_accuracy: 0.2778\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0234 - accuracy: 0.2296 - val_loss: 2.1318 - val_accuracy: 0.2778\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0231 - accuracy: 0.2296 - val_loss: 2.1314 - val_accuracy: 0.2778\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0228 - accuracy: 0.2296 - val_loss: 2.1311 - val_accuracy: 0.2889\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0225 - accuracy: 0.2296 - val_loss: 2.1308 - val_accuracy: 0.2889\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0222 - accuracy: 0.2296 - val_loss: 2.1305 - val_accuracy: 0.2889\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0220 - accuracy: 0.2296 - val_loss: 2.1302 - val_accuracy: 0.2889\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0217 - accuracy: 0.2296 - val_loss: 2.1298 - val_accuracy: 0.2889\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0214 - accuracy: 0.2296 - val_loss: 2.1295 - val_accuracy: 0.2889\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0211 - accuracy: 0.2296 - val_loss: 2.1292 - val_accuracy: 0.2889\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0208 - accuracy: 0.2296 - val_loss: 2.1289 - val_accuracy: 0.2889\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0205 - accuracy: 0.2296 - val_loss: 2.1286 - val_accuracy: 0.2889\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0202 - accuracy: 0.2296 - val_loss: 2.1282 - val_accuracy: 0.2889\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0199 - accuracy: 0.2296 - val_loss: 2.1279 - val_accuracy: 0.2889\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0196 - accuracy: 0.2296 - val_loss: 2.1276 - val_accuracy: 0.2889\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0193 - accuracy: 0.2296 - val_loss: 2.1273 - val_accuracy: 0.2889\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0190 - accuracy: 0.2333 - val_loss: 2.1269 - val_accuracy: 0.2889\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0188 - accuracy: 0.2333 - val_loss: 2.1266 - val_accuracy: 0.2889\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0185 - accuracy: 0.2333 - val_loss: 2.1263 - val_accuracy: 0.2889\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0182 - accuracy: 0.2333 - val_loss: 2.1260 - val_accuracy: 0.2889\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0179 - accuracy: 0.2333 - val_loss: 2.1257 - val_accuracy: 0.2889\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0176 - accuracy: 0.2333 - val_loss: 2.1254 - val_accuracy: 0.2889\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0173 - accuracy: 0.2333 - val_loss: 2.1250 - val_accuracy: 0.2889\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0170 - accuracy: 0.2333 - val_loss: 2.1247 - val_accuracy: 0.2889\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0167 - accuracy: 0.2333 - val_loss: 2.1244 - val_accuracy: 0.2889\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0165 - accuracy: 0.2333 - val_loss: 2.1241 - val_accuracy: 0.2889\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0162 - accuracy: 0.2333 - val_loss: 2.1238 - val_accuracy: 0.2889\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0159 - accuracy: 0.2333 - val_loss: 2.1234 - val_accuracy: 0.2889\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0156 - accuracy: 0.2333 - val_loss: 2.1231 - val_accuracy: 0.2889\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0153 - accuracy: 0.2333 - val_loss: 2.1228 - val_accuracy: 0.2889\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0150 - accuracy: 0.2333 - val_loss: 2.1224 - val_accuracy: 0.2889\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0147 - accuracy: 0.2333 - val_loss: 2.1221 - val_accuracy: 0.2889\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0144 - accuracy: 0.2333 - val_loss: 2.1218 - val_accuracy: 0.2889\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0141 - accuracy: 0.2333 - val_loss: 2.1215 - val_accuracy: 0.2889\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0138 - accuracy: 0.2333 - val_loss: 2.1212 - val_accuracy: 0.2889\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0136 - accuracy: 0.2333 - val_loss: 2.1209 - val_accuracy: 0.2889\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0133 - accuracy: 0.2333 - val_loss: 2.1205 - val_accuracy: 0.2889\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0130 - accuracy: 0.2333 - val_loss: 2.1202 - val_accuracy: 0.2889\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0127 - accuracy: 0.2333 - val_loss: 2.1199 - val_accuracy: 0.2889\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0124 - accuracy: 0.2333 - val_loss: 2.1196 - val_accuracy: 0.2889\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0121 - accuracy: 0.2333 - val_loss: 2.1193 - val_accuracy: 0.2889\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0118 - accuracy: 0.2370 - val_loss: 2.1189 - val_accuracy: 0.2889\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0116 - accuracy: 0.2370 - val_loss: 2.1186 - val_accuracy: 0.3000\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0113 - accuracy: 0.2370 - val_loss: 2.1183 - val_accuracy: 0.3000\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0110 - accuracy: 0.2370 - val_loss: 2.1180 - val_accuracy: 0.3000\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0107 - accuracy: 0.2370 - val_loss: 2.1177 - val_accuracy: 0.3000\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0104 - accuracy: 0.2370 - val_loss: 2.1174 - val_accuracy: 0.3000\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0101 - accuracy: 0.2370 - val_loss: 2.1171 - val_accuracy: 0.3000\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0099 - accuracy: 0.2370 - val_loss: 2.1168 - val_accuracy: 0.3000\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0096 - accuracy: 0.2370 - val_loss: 2.1165 - val_accuracy: 0.3000\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0093 - accuracy: 0.2370 - val_loss: 2.1162 - val_accuracy: 0.3000\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0090 - accuracy: 0.2370 - val_loss: 2.1158 - val_accuracy: 0.3000\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0088 - accuracy: 0.2370 - val_loss: 2.1155 - val_accuracy: 0.3000\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0085 - accuracy: 0.2370 - val_loss: 2.1152 - val_accuracy: 0.3000\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0082 - accuracy: 0.2370 - val_loss: 2.1149 - val_accuracy: 0.3000\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0079 - accuracy: 0.2370 - val_loss: 2.1146 - val_accuracy: 0.3000\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0076 - accuracy: 0.2370 - val_loss: 2.1143 - val_accuracy: 0.3000\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0074 - accuracy: 0.2370 - val_loss: 2.1140 - val_accuracy: 0.3000\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.0071 - accuracy: 0.2370 - val_loss: 2.1137 - val_accuracy: 0.3000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------------------------LEARNING CURVE FOR NEURAL NETWORK ONLY-----------------------------------------------#\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def fit_model(trainX, trainy, testX, testy, lrate):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(120, input_dim=40000, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(6, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=lrate)\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1)\n",
    "\t# plot learning curves\n",
    "\tpyplot.plot(history.history['accuracy'], label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], label='test')\n",
    "\tpyplot.title('lrate='+str(lrate), pad=-50)\n",
    "\n",
    "# create learning curves for different learning rates\n",
    "learning_rates = [1E-6, 1E-7,1E-8,1E-9]\n",
    "for i in range(len(learning_rates)):\n",
    "\t# determine the plot number\n",
    "\tplot_no = 420 + (i+1)\n",
    "\tpyplot.subplot(plot_no)\n",
    "\t# fit model and plot learning curves for a learning rate\n",
    "\tfit_model(X_train, y_train, X_test, y_test, learning_rates[i])\n",
    "# show learning curves\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4074846356453029 {'C': 0.1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#-------------------REGRESSION LOGISTIQUE WITH SCIKIT LEARN ---------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=4)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "#score\n",
    "best_parameters = logreg_cv.best_params_\n",
    "best_accuracy = logreg_cv.best_score_\n",
    "print(best_accuracy,best_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5592592592592592 {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#-------------------RANDOM FOREST WITH SCIKIT LEARN ---------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [50,100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "#score\n",
    "best_parameters = CV_rfc.best_params_\n",
    "best_accuracy = CV_rfc.best_score_\n",
    "print(best_accuracy,best_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5962962962962963 {'C': 1000.0, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "#-------------------SVM WITH SCIKIT LEARN ---------------------\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "param_grid = {'C': [1e3, 1e5],\n",
    "              'gamma': [0.0001, 0.1], }\n",
    "clf = GridSearchCV(\n",
    "    svm.SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
    ")\n",
    "clf = clf.fit(X_train, y_train)\n",
    "#score\n",
    "best_parameters = clf.best_params_\n",
    "best_accuracy = clf.best_score_\n",
    "print(best_accuracy,best_parameters)\n",
    "#scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# Use score method to get accuracy of model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPJ1qExlv6BQ"
   },
   "source": [
    "**<ins>Question</ins>: Évaluer les modèles appris en décrivant votre méthode**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNAFZTFvv6BS"
   },
   "source": [
    "Pour chaques modèle on entraîne sur le jeu de donnée puis on test. \n",
    "Pour ce qui est des méthodes d'optimisation des hyper-paramètres, il y a deux méthodes:\n",
    "-Learning/validation curve \n",
    "elle permet de voir l'évolution de la qualité du modèle en fonction de l'entraînement. \n",
    "Très utile pour detecter le surentraînement et autre spécificités du modèle.\n",
    "\n",
    "-Grid search CV \n",
    "Permet de croiser tout les hyper-paramètres spécifiés et ressort le modèle avec les meilleurs hyper-paramètres.\n",
    "\n",
    "# Pour le réseau de neurones:\n",
    "J'ai utilisé les deux méthodes \n",
    "Le réseau permet d'obtenir une accuracy de 46% sur les données d'entraînement et de 43% sur les données de test.\n",
    "\n",
    "# Regression logistique:\n",
    "j'utilise Grid search CV \n",
    "\n",
    "hyper-paramètres: Learning rate\n",
    "\n",
    "J'obtiens un score de 41%\n",
    "\n",
    "# Random forest:\n",
    "j'utilise Grid search CV \n",
    "\n",
    "hyper-paramètres: Profondeur de l'arbre, nombre d'arbres dans la forêt \n",
    "\n",
    "J'obtiens un score de 35%\n",
    "\n",
    "# SVM:\n",
    "j'utilise Grid search CV \n",
    "\n",
    "hyper-paramètres: C paramètre de régularisation, gamma \n",
    "\n",
    "J'obtiens un score de 71%\n",
    "\n",
    "Le modèle SVM est donc le grand gagnant pour cette classification. \n",
    "Ce qui est prévisible car étant donné le jeu de données, c'est celui qui est recommandé par la SKlearn map que l'on peut retrouver sur l'API de la bibliothèque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w4tk5JUv6BS"
   },
   "source": [
    "_Your code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dp4dnNeVv6BS",
    "outputId": "ce6c23ed-e68f-4f49-86c1-b93b80abdc9e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Xw7bbYtv6BX"
   },
   "source": [
    "**<ins>Question</ins>: Réalisez un diagramme fonctionnel décrivant le flux des données tout au long de l'approche supervisée. Ce diagramme devra faire apparaître au minimum: les trois ensembles d'images, les descripteurs, les différents algorithmes d'apprentissage, l'évaluation (mettre une image dans le répertoire courant et dans la cellule ci-dessous remplacer par le nom du fichier)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDclLV6xv6BX"
   },
   "source": [
    "_Your image here_ <img src=\"fichierDiagramme.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNgbxS-Fv6BY"
   },
   "source": [
    "# Partie 2: Approche supervisée sur descripteurs issus du scattering operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYGGoa--v6BZ"
   },
   "source": [
    "**<ins>Question</ins>: Chargez les données du fichier matlab imdb_200x200_SmallSonarTex_db_6classes_scatValOnly.mat**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LmzGnm9v6BZ"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0w4sdmcCv6Bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpnR5ECxv6Bf"
   },
   "source": [
    "**<ins>Question</ins>: Y-a-t-il besoin de normaliser les descripteurs? Si oui, que faut-il conserver comme information et pourquoi?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1kxf9u-v6Bf"
   },
   "source": [
    "_votre réponse ici:_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LmzGnm9v6BZ"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKfZD5Ymv6Bg"
   },
   "source": [
    "<strong><ins>Question</ins>: Séparer en deux ensembles de données et réalisez l'apprentissage successifs des modèles:\n",
    "* régression logistique, réseaux de neurones, svm et random forest en utilisant les fonctions du package scikit-learn\n",
    "</strong>\n",
    "\n",
    "<span style='color:red'> **Pas de code à développer ici, réutiliser celui de la partie 1**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iuzu7p9bv6Bh"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixer les hyper paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01PQN1yev6Bl"
   },
   "source": [
    "**<ins>Question</ins>: Déterminez les hyper-paramètres (paramètre uniquement lié à l'algorithme d'apprentissage) de chaque algorithme. Comment allez vous les fixer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxHG8upGv6BO"
   },
   "source": [
    "_votre réponse ici:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPTVxU1Av6Bt"
   },
   "source": [
    "**<ins>Question</ins>:\n",
    "Lisez le [tutoriel suivant](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html\\#sphx-glr-auto-examples-applications-plot-face-recognition-py) en faisant particulièrement attention à la façon dont est gérée la détermination des hyperparamètres et l'évaluation des performances. Reproduisez cette méthodologie en testant différents nombres de plis (fold).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2imQo5dcv6Bu"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXG85EQLv6Bn"
   },
   "source": [
    "**<ins>Question</ins>: Évaluer les résultats et donner la valeur des paramètres optimaux**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rpSf449v6Bt"
   },
   "source": [
    "_votre réponse ici:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2imQo5dcv6Bu"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rthsnlIvv6Bu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprendre le modèle final pour chaque classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rpSf449v6Bt"
   },
   "source": [
    "_votre réponse ici:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2imQo5dcv6Bu"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluer chaque classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rpSf449v6Bt"
   },
   "source": [
    "_votre réponse ici:_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2imQo5dcv6Bu"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnMpegufv6By"
   },
   "source": [
    "## Partie 4 Analyse finale des résultats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew9r6cPgv6By"
   },
   "source": [
    "**<ins>Question</ins>: Réalisez un diagramme fonctionnel décrivant le flux des données tout au long de l'approche supervisée. Ce diagramme devra faire apparaître au minimum: les trois ensembles d'images, les descripteurs, les différents algorithmes d'apprentissage, l'évaluation, les différents blocs de traitements.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL6sMZpDv6B0"
   },
   "source": [
    "_votre réponse ici:_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3pwYHoZv6B1"
   },
   "source": [
    "_Your Code below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k91uEbZGv6B1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVqpga1vv6B5"
   },
   "source": [
    "**<ins>Question</ins>: Faites une synthèse des résultats obtenus. Dresser en particulier des conclusions en fonction des descripteurs utilisés, des algorithmes utilisés et des prétraitements effectués.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUF82_f1v6B5"
   },
   "source": [
    "_votre réponse ici:_"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seafloorClassification_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
